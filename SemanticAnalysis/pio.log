2015-04-08 15:07:35,709 INFO  io.prediction.tools.console.Console$ [main] - Using command '/Users/Marco/PredictionIO/sbt/sbt' at the current working directory to build.
2015-04-08 15:07:35,710 INFO  io.prediction.tools.console.Console$ [main] - If the path above is incorrect, this process will fail.
2015-04-08 15:07:35,711 INFO  io.prediction.tools.console.Console$ [main] - Uber JAR disabled. Making sure lib/pio-assembly-0.9.1.jar is absent.
2015-04-08 15:07:35,711 INFO  io.prediction.tools.console.Console$ [main] - Going to run: /Users/Marco/PredictionIO/sbt/sbt  package assemblyPackageDependency
2015-04-08 15:08:04,668 INFO  io.prediction.tools.console.Console$ [main] - Build finished successfully.
2015-04-08 15:08:04,669 INFO  io.prediction.tools.console.Console$ [main] - Looking for an engine...
2015-04-08 15:08:04,677 INFO  io.prediction.tools.console.Console$ [main] - Found SemanticAnalysis-assembly-1.0-deps.jar
2015-04-08 15:08:04,677 INFO  io.prediction.tools.console.Console$ [main] - Found semanticanalysis_2.10-1.0.jar
2015-04-08 15:08:04,685 INFO  io.prediction.tools.console.Console$ [main] - HADOOP_CONF_DIR is not set. Assuming HDFS is unavailable.
2015-04-08 15:08:06,549 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-08 15:08:06,681 INFO  io.prediction.tools.RegisterEngine$ [main] - Copying file:/Users/Marco/SemanticAnalysisRepo/SemanticAnalysis/target/scala-2.10/SemanticAnalysis-assembly-1.0-deps.jar to file:/Users/Marco/.pio_store/engines/IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I/1601d4b44276e463819ccf16bcea2e968082ad77/SemanticAnalysis-assembly-1.0-deps.jar
2015-04-08 15:08:06,790 INFO  io.prediction.tools.RegisterEngine$ [main] - Copying file:/Users/Marco/SemanticAnalysisRepo/SemanticAnalysis/target/scala-2.10/semanticanalysis_2.10-1.0.jar to file:/Users/Marco/.pio_store/engines/IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I/1601d4b44276e463819ccf16bcea2e968082ad77/semanticanalysis_2.10-1.0.jar
2015-04-08 15:08:06,803 INFO  io.prediction.tools.RegisterEngine$ [main] - Registering engine IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I 1601d4b44276e463819ccf16bcea2e968082ad77
2015-04-08 15:09:39,320 INFO  io.prediction.tools.console.Console$ [main] - Using existing engine manifest JSON at /Users/Marco/SemanticAnalysisRepo/SemanticAnalysis/manifest.json
2015-04-08 15:09:40,540 ERROR io.prediction.data.storage.elasticsearch.ESEngineManifests [main] - None of the configured nodes are available: []
2015-04-08 15:09:40,541 ERROR io.prediction.tools.console.Console$ [main] - Engine IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I 1601d4b44276e463819ccf16bcea2e968082ad77 cannot be found in the system.
2015-04-08 15:09:40,541 ERROR io.prediction.tools.console.Console$ [main] - Possible reasons:
2015-04-08 15:09:40,542 ERROR io.prediction.tools.console.Console$ [main] - - the engine is not yet built by the 'build' command;
2015-04-08 15:09:40,542 ERROR io.prediction.tools.console.Console$ [main] - - the meta data store is offline.
2015-04-08 15:11:22,564 INFO  io.prediction.tools.console.Console$ [main] - Using existing engine manifest JSON at /Users/Marco/SemanticAnalysisRepo/SemanticAnalysis/manifest.json
2015-04-08 15:11:23,904 ERROR io.prediction.data.storage.elasticsearch.ESEngineManifests [main] - None of the configured nodes are available: []
2015-04-08 15:11:23,905 ERROR io.prediction.tools.console.Console$ [main] - Engine IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I 1601d4b44276e463819ccf16bcea2e968082ad77 cannot be found in the system.
2015-04-08 15:11:23,906 ERROR io.prediction.tools.console.Console$ [main] - Possible reasons:
2015-04-08 15:11:23,906 ERROR io.prediction.tools.console.Console$ [main] - - the engine is not yet built by the 'build' command;
2015-04-08 15:11:23,906 ERROR io.prediction.tools.console.Console$ [main] - - the meta data store is offline.
2015-04-08 15:16:33,826 INFO  io.prediction.tools.console.Console$ [main] - Creating Event Server at 0.0.0.0:7070
2015-04-08 15:16:35,162 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-08 15:16:43,848 INFO  spray.can.server.HttpListener [EventServerSystem-akka.actor.default-dispatcher-4] - Bound to /0.0.0.0:7070
2015-04-08 15:16:43,849 INFO  io.prediction.data.api.EventServerActor [EventServerSystem-akka.actor.default-dispatcher-4] - Bound received. EventServer is ready.
2015-04-08 15:17:20,026 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-08 15:17:31,222 INFO  io.prediction.data.storage.hbase.HBLEvents [main] - The table predictionio_eventdata:events_1 doesn't exist yet. Creating now...
2015-04-08 15:17:31,571 INFO  io.prediction.tools.console.App$ [main] - Initialized Event Store for this app ID: 1.
2015-04-08 15:17:31,591 INFO  io.prediction.tools.console.App$ [main] - Created new app:
2015-04-08 15:17:31,592 INFO  io.prediction.tools.console.App$ [main] -       Name: SemAnalysisApp-Marco
2015-04-08 15:17:31,592 INFO  io.prediction.tools.console.App$ [main] -         ID: 1
2015-04-08 15:17:31,593 INFO  io.prediction.tools.console.App$ [main] - Access Key: Hw8uK9u8j3C3Tuvu9Ce1YNIjhggQnXXUyPzxdqyqKPgaiT2Dz444hrNrcz4Bg8qM
2015-04-08 15:46:46,200 INFO  io.prediction.tools.console.Console$ [main] - Using existing engine manifest JSON at /Users/Marco/SemanticAnalysisRepo/SemanticAnalysis/manifest.json
2015-04-08 15:46:46,248 INFO  io.prediction.tools.console.Console$ [main] - Using command '/Users/Marco/PredictionIO/sbt/sbt' at the current working directory to build.
2015-04-08 15:46:46,249 INFO  io.prediction.tools.console.Console$ [main] - If the path above is incorrect, this process will fail.
2015-04-08 15:46:46,250 INFO  io.prediction.tools.console.Console$ [main] - Uber JAR disabled. Making sure lib/pio-assembly-0.9.1.jar is absent.
2015-04-08 15:46:46,250 INFO  io.prediction.tools.console.Console$ [main] - Going to run: /Users/Marco/PredictionIO/sbt/sbt  package assemblyPackageDependency
2015-04-08 15:46:55,577 INFO  io.prediction.tools.console.Console$ [main] - Build finished successfully.
2015-04-08 15:46:55,577 INFO  io.prediction.tools.console.Console$ [main] - Looking for an engine...
2015-04-08 15:46:55,585 INFO  io.prediction.tools.console.Console$ [main] - Found SemanticAnalysis-assembly-1.0-deps.jar
2015-04-08 15:46:55,585 INFO  io.prediction.tools.console.Console$ [main] - Found semanticanalysis_2.10-1.0.jar
2015-04-08 15:46:55,592 INFO  io.prediction.tools.console.Console$ [main] - HADOOP_CONF_DIR is not set. Assuming HDFS is unavailable.
2015-04-08 15:46:57,182 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-08 15:46:57,283 INFO  io.prediction.tools.RegisterEngine$ [main] - Copying file:/Users/Marco/SemanticAnalysisRepo/SemanticAnalysis/target/scala-2.10/SemanticAnalysis-assembly-1.0-deps.jar to file:/Users/Marco/.pio_store/engines/IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I/1601d4b44276e463819ccf16bcea2e968082ad77/SemanticAnalysis-assembly-1.0-deps.jar
2015-04-08 15:46:57,377 INFO  io.prediction.tools.RegisterEngine$ [main] - Copying file:/Users/Marco/SemanticAnalysisRepo/SemanticAnalysis/target/scala-2.10/semanticanalysis_2.10-1.0.jar to file:/Users/Marco/.pio_store/engines/IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I/1601d4b44276e463819ccf16bcea2e968082ad77/semanticanalysis_2.10-1.0.jar
2015-04-08 15:46:57,403 INFO  io.prediction.tools.RegisterEngine$ [main] - Registering engine IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I 1601d4b44276e463819ccf16bcea2e968082ad77
2015-04-08 15:46:57,439 INFO  io.prediction.tools.console.Console$ [main] - Your engine is ready for training.
2015-04-08 15:47:04,212 INFO  io.prediction.tools.console.Console$ [main] - Using existing engine manifest JSON at /Users/Marco/SemanticAnalysisRepo/SemanticAnalysis/manifest.json
2015-04-08 15:47:05,862 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-08 15:47:05,992 INFO  io.prediction.tools.RunWorkflow$ [main] - Submission command: /Users/Marco/PredictionIO/vendors/spark-1.2.1/bin/spark-submit --class io.prediction.workflow.CreateWorkflow --name PredictionIO Training: IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I 1601d4b44276e463819ccf16bcea2e968082ad77 () --jars file:/Users/Marco/.pio_store/engines/IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I/1601d4b44276e463819ccf16bcea2e968082ad77/semanticanalysis_2.10-1.0.jar,file:/Users/Marco/.pio_store/engines/IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I/1601d4b44276e463819ccf16bcea2e968082ad77/SemanticAnalysis-assembly-1.0-deps.jar --files /Users/Marco/PredictionIO/conf/log4j.properties,/Users/Marco/PredictionIO/vendors/hbase-0.98.11/conf/hbase-site.xml --driver-class-path /Users/Marco/PredictionIO/conf:/Users/Marco/PredictionIO/vendors/hbase-0.98.11/conf /Users/Marco/PredictionIO/lib/pio-assembly-0.9.1.jar --env PIO_STORAGE_SOURCES_HBASE_TYPE=hbase,PIO_ENV_LOADED=1,PIO_STORAGE_SOURCES_HBASE_HOSTS=0,PIO_STORAGE_REPOSITORIES_METADATA_NAME=predictionio_metadata,PIO_FS_BASEDIR=/Users/Marco/.pio_store,PIO_STORAGE_SOURCES_ELASTICSEARCH_HOSTS=localhost,PIO_STORAGE_SOURCES_HBASE_HOME=/Users/Marco/PredictionIO/vendors/hbase-0.98.11,PIO_HOME=/Users/Marco/PredictionIO,PIO_FS_ENGINESDIR=/Users/Marco/.pio_store/engines,PIO_STORAGE_SOURCES_HBASE_PORTS=0,PIO_STORAGE_SOURCES_ELASTICSEARCH_TYPE=elasticsearch,PIO_STORAGE_REPOSITORIES_METADATA_SOURCE=ELASTICSEARCH,PIO_STORAGE_REPOSITORIES_MODELDATA_SOURCE=LOCALFS,PIO_STORAGE_REPOSITORIES_EVENTDATA_NAME=predictionio_eventdata,PIO_STORAGE_SOURCES_ELASTICSEARCH_HOME=/Users/Marco/PredictionIO/vendors/elasticsearch-1.4.4,PIO_FS_TMPDIR=/Users/Marco/.pio_store/tmp,PIO_STORAGE_REPOSITORIES_MODELDATA_NAME=pio_,PIO_STORAGE_SOURCES_LOCALFS_HOSTS=/Users/Marco/.pio_store/models,PIO_STORAGE_REPOSITORIES_EVENTDATA_SOURCE=HBASE,PIO_CONF_DIR=/Users/Marco/PredictionIO/conf,PIO_STORAGE_SOURCES_LOCALFS_PORTS=0,PIO_STORAGE_SOURCES_ELASTICSEARCH_PORTS=9300,PIO_STORAGE_SOURCES_LOCALFS_TYPE=localfs --engine-id IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I --engine-version 1601d4b44276e463819ccf16bcea2e968082ad77 --engine-variant /Users/Marco/SemanticAnalysisRepo/SemanticAnalysis/engine.json --verbosity 0
2015-04-08 15:47:08,025 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-08 15:47:09,009 INFO  io.prediction.controller.Engine [main] - Extracting datasource params...
2015-04-08 15:47:09,114 INFO  io.prediction.workflow.WorkflowUtils$ [main] - No 'name' is found. Default empty String will be used.
2015-04-08 15:47:09,127 INFO  io.prediction.controller.Engine [main] - Datasource params: (,DataSourceParams(1))
2015-04-08 15:47:09,128 INFO  io.prediction.controller.Engine [main] - Extracting preparator params...
2015-04-08 15:47:09,129 INFO  io.prediction.controller.Engine [main] - Preparator params: (,Empty)
2015-04-08 15:47:09,135 INFO  io.prediction.controller.Engine [main] - Extracting serving params...
2015-04-08 15:47:09,136 INFO  io.prediction.controller.Engine [main] - Serving params: (,Empty)
2015-04-08 15:47:10,919 INFO  Remoting [sparkDriver-akka.actor.default-dispatcher-3] - Starting remoting
2015-04-08 15:47:11,151 INFO  Remoting [sparkDriver-akka.actor.default-dispatcher-4] - Remoting started; listening on addresses :[akka.tcp://sparkDriver@10.0.22.139:55592]
2015-04-08 15:47:12,628 INFO  io.prediction.controller.Engine$ [main] - EngineWorkflow.train
2015-04-08 15:47:12,628 INFO  io.prediction.controller.Engine$ [main] - DataSource: SemanticAnalysis.DataSource@78307a56
2015-04-08 15:47:12,629 INFO  io.prediction.controller.Engine$ [main] - Preparator: SemanticAnalysis.Preparator@1983b48a
2015-04-08 15:47:12,629 INFO  io.prediction.controller.Engine$ [main] - AlgorithmList: List(SemanticAnalysis.Algorithm@4391a2d8)
2015-04-08 15:47:12,629 INFO  io.prediction.controller.Engine$ [main] - Data santiy check is on.
2015-04-08 15:47:23,981 INFO  io.prediction.controller.Engine$ [main] - SemanticAnalysis.TrainingData does not support data sanity check. Skipping check.
2015-04-08 15:47:23,982 INFO  io.prediction.controller.Engine$ [main] - SemanticAnalysis.PreparedData does not support data sanity check. Skipping check.
2015-04-08 15:47:29,198 WARN  org.apache.hadoop.hbase.mapreduce.TableInputFormatBase [main] - Cannot resolve the host name for /10.0.22.139 because of javax.naming.NameNotFoundException: DNS name not found [response code 3]; remaining name '139.22.0.10.in-addr.arpa'
2015-04-08 15:47:36,869 ERROR org.apache.spark.executor.Executor [Executor task launch worker-0] - Exception in task 0.0 in stage 0.0 (TID 0)
java.lang.IllegalArgumentException: tokens must not be empty
	at opennlp.tools.util.StringList.<init>(StringList.java:61)
	at SemanticAnalysis.NGramMachine.extract(NGramMachine.java:18)
	at SemanticAnalysis.Algorithm$$anonfun$1.apply(Algorithm.scala:29)
	at SemanticAnalysis.Algorithm$$anonfun$1.apply(Algorithm.scala:28)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:328)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:48)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:103)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:47)
	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:273)
	at scala.collection.AbstractIterator.to(Iterator.scala:1157)
	at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:265)
	at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1157)
	at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:252)
	at scala.collection.AbstractIterator.toArray(Iterator.scala:1157)
	at org.apache.spark.rdd.RDD$$anonfun$org$apache$spark$rdd$RDD$$collectPartition$1$1.apply(RDD.scala:808)
	at org.apache.spark.rdd.RDD$$anonfun$org$apache$spark$rdd$RDD$$collectPartition$1$1.apply(RDD.scala:808)
	at org.apache.spark.SparkContext$$anonfun$runJob$4.apply(SparkContext.scala:1353)
	at org.apache.spark.SparkContext$$anonfun$runJob$4.apply(SparkContext.scala:1353)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:61)
	at org.apache.spark.scheduler.Task.run(Task.scala:56)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:200)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-04-08 15:47:36,889 WARN  org.apache.spark.scheduler.TaskSetManager [task-result-getter-0] - Lost task 0.0 in stage 0.0 (TID 0, localhost): java.lang.IllegalArgumentException: tokens must not be empty
	at opennlp.tools.util.StringList.<init>(StringList.java:61)
	at SemanticAnalysis.NGramMachine.extract(NGramMachine.java:18)
	at SemanticAnalysis.Algorithm$$anonfun$1.apply(Algorithm.scala:29)
	at SemanticAnalysis.Algorithm$$anonfun$1.apply(Algorithm.scala:28)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:328)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:48)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:103)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:47)
	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:273)
	at scala.collection.AbstractIterator.to(Iterator.scala:1157)
	at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:265)
	at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1157)
	at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:252)
	at scala.collection.AbstractIterator.toArray(Iterator.scala:1157)
	at org.apache.spark.rdd.RDD$$anonfun$org$apache$spark$rdd$RDD$$collectPartition$1$1.apply(RDD.scala:808)
	at org.apache.spark.rdd.RDD$$anonfun$org$apache$spark$rdd$RDD$$collectPartition$1$1.apply(RDD.scala:808)
	at org.apache.spark.SparkContext$$anonfun$runJob$4.apply(SparkContext.scala:1353)
	at org.apache.spark.SparkContext$$anonfun$runJob$4.apply(SparkContext.scala:1353)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:61)
	at org.apache.spark.scheduler.Task.run(Task.scala:56)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:200)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

2015-04-08 15:47:36,893 ERROR org.apache.spark.scheduler.TaskSetManager [task-result-getter-0] - Task 0 in stage 0.0 failed 1 times; aborting job
2015-04-08 15:57:26,689 INFO  io.prediction.tools.console.Console$ [main] - Using existing engine manifest JSON at /Users/Marco/SemanticAnalysisRepo/SemanticAnalysis/manifest.json
2015-04-08 15:57:26,736 INFO  io.prediction.tools.console.Console$ [main] - Using command '/Users/Marco/PredictionIO/sbt/sbt' at the current working directory to build.
2015-04-08 15:57:26,737 INFO  io.prediction.tools.console.Console$ [main] - If the path above is incorrect, this process will fail.
2015-04-08 15:57:26,738 INFO  io.prediction.tools.console.Console$ [main] - Uber JAR disabled. Making sure lib/pio-assembly-0.9.1.jar is absent.
2015-04-08 15:57:26,738 INFO  io.prediction.tools.console.Console$ [main] - Going to run: /Users/Marco/PredictionIO/sbt/sbt  package assemblyPackageDependency
2015-04-08 15:57:35,576 ERROR io.prediction.tools.console.Console$ [Thread-2] - [0m[[31merror[0m] [0m/Users/Marco/SemanticAnalysisRepo/SemanticAnalysis/src/main/java/SemanticAnalysis/NGramMachine.java:30: error: missing return statement[0m
2015-04-08 15:57:35,576 ERROR io.prediction.tools.console.Console$ [Thread-2] - [0m[[31merror[0m] [0m    }[0m
2015-04-08 15:57:35,577 ERROR io.prediction.tools.console.Console$ [Thread-2] - [0m[[31merror[0m] [0m    ^[0m
2015-04-08 15:57:35,577 ERROR io.prediction.tools.console.Console$ [Thread-2] - [0m[[31merror[0m] [0m1 error[0m
2015-04-08 15:57:35,609 ERROR io.prediction.tools.console.Console$ [Thread-2] - [0m[[31merror[0m] [0m(compile:[31mcompile[0m) javac returned nonzero exit code[0m
2015-04-08 15:57:35,622 ERROR io.prediction.tools.console.Console$ [Thread-2] - [0m[[31merror[0m] [0mTotal time: 2 s, completed Apr 8, 2015 3:57:35 PM[0m
2015-04-08 15:57:35,701 ERROR io.prediction.tools.console.Console$ [main] - Return code of previous step is 1. Aborting.
2015-04-08 16:02:55,718 INFO  io.prediction.tools.console.Console$ [main] - Using existing engine manifest JSON at /Users/Marco/SemanticAnalysisRepo/SemanticAnalysis/manifest.json
2015-04-08 16:02:55,768 INFO  io.prediction.tools.console.Console$ [main] - Using command '/Users/Marco/PredictionIO/sbt/sbt' at the current working directory to build.
2015-04-08 16:02:55,768 INFO  io.prediction.tools.console.Console$ [main] - If the path above is incorrect, this process will fail.
2015-04-08 16:02:55,769 INFO  io.prediction.tools.console.Console$ [main] - Uber JAR disabled. Making sure lib/pio-assembly-0.9.1.jar is absent.
2015-04-08 16:02:55,770 INFO  io.prediction.tools.console.Console$ [main] - Going to run: /Users/Marco/PredictionIO/sbt/sbt  package assemblyPackageDependency
2015-04-08 16:03:11,498 INFO  io.prediction.tools.console.Console$ [main] - Build finished successfully.
2015-04-08 16:03:11,499 INFO  io.prediction.tools.console.Console$ [main] - Looking for an engine...
2015-04-08 16:03:11,507 INFO  io.prediction.tools.console.Console$ [main] - Found SemanticAnalysis-assembly-1.0-deps.jar
2015-04-08 16:03:11,507 INFO  io.prediction.tools.console.Console$ [main] - Found semanticanalysis_2.10-1.0.jar
2015-04-08 16:03:11,514 INFO  io.prediction.tools.console.Console$ [main] - HADOOP_CONF_DIR is not set. Assuming HDFS is unavailable.
2015-04-08 16:03:13,239 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-08 16:03:13,347 INFO  io.prediction.tools.RegisterEngine$ [main] - Copying file:/Users/Marco/SemanticAnalysisRepo/SemanticAnalysis/target/scala-2.10/SemanticAnalysis-assembly-1.0-deps.jar to file:/Users/Marco/.pio_store/engines/IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I/1601d4b44276e463819ccf16bcea2e968082ad77/SemanticAnalysis-assembly-1.0-deps.jar
2015-04-08 16:03:13,427 INFO  io.prediction.tools.RegisterEngine$ [main] - Copying file:/Users/Marco/SemanticAnalysisRepo/SemanticAnalysis/target/scala-2.10/semanticanalysis_2.10-1.0.jar to file:/Users/Marco/.pio_store/engines/IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I/1601d4b44276e463819ccf16bcea2e968082ad77/semanticanalysis_2.10-1.0.jar
2015-04-08 16:03:13,439 INFO  io.prediction.tools.RegisterEngine$ [main] - Registering engine IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I 1601d4b44276e463819ccf16bcea2e968082ad77
2015-04-08 16:03:13,463 INFO  io.prediction.tools.console.Console$ [main] - Your engine is ready for training.
2015-04-08 16:03:17,155 INFO  io.prediction.tools.console.Console$ [main] - Using existing engine manifest JSON at /Users/Marco/SemanticAnalysisRepo/SemanticAnalysis/manifest.json
2015-04-08 16:03:18,784 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-08 16:03:18,889 INFO  io.prediction.tools.RunWorkflow$ [main] - Submission command: /Users/Marco/PredictionIO/vendors/spark-1.2.1/bin/spark-submit --class io.prediction.workflow.CreateWorkflow --name PredictionIO Training: IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I 1601d4b44276e463819ccf16bcea2e968082ad77 () --jars file:/Users/Marco/.pio_store/engines/IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I/1601d4b44276e463819ccf16bcea2e968082ad77/semanticanalysis_2.10-1.0.jar,file:/Users/Marco/.pio_store/engines/IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I/1601d4b44276e463819ccf16bcea2e968082ad77/SemanticAnalysis-assembly-1.0-deps.jar --files /Users/Marco/PredictionIO/conf/log4j.properties,/Users/Marco/PredictionIO/vendors/hbase-0.98.11/conf/hbase-site.xml --driver-class-path /Users/Marco/PredictionIO/conf:/Users/Marco/PredictionIO/vendors/hbase-0.98.11/conf /Users/Marco/PredictionIO/lib/pio-assembly-0.9.1.jar --env PIO_STORAGE_SOURCES_HBASE_TYPE=hbase,PIO_ENV_LOADED=1,PIO_STORAGE_SOURCES_HBASE_HOSTS=0,PIO_STORAGE_REPOSITORIES_METADATA_NAME=predictionio_metadata,PIO_FS_BASEDIR=/Users/Marco/.pio_store,PIO_STORAGE_SOURCES_ELASTICSEARCH_HOSTS=localhost,PIO_STORAGE_SOURCES_HBASE_HOME=/Users/Marco/PredictionIO/vendors/hbase-0.98.11,PIO_HOME=/Users/Marco/PredictionIO,PIO_FS_ENGINESDIR=/Users/Marco/.pio_store/engines,PIO_STORAGE_SOURCES_HBASE_PORTS=0,PIO_STORAGE_SOURCES_ELASTICSEARCH_TYPE=elasticsearch,PIO_STORAGE_REPOSITORIES_METADATA_SOURCE=ELASTICSEARCH,PIO_STORAGE_REPOSITORIES_MODELDATA_SOURCE=LOCALFS,PIO_STORAGE_REPOSITORIES_EVENTDATA_NAME=predictionio_eventdata,PIO_STORAGE_SOURCES_ELASTICSEARCH_HOME=/Users/Marco/PredictionIO/vendors/elasticsearch-1.4.4,PIO_FS_TMPDIR=/Users/Marco/.pio_store/tmp,PIO_STORAGE_REPOSITORIES_MODELDATA_NAME=pio_,PIO_STORAGE_SOURCES_LOCALFS_HOSTS=/Users/Marco/.pio_store/models,PIO_STORAGE_REPOSITORIES_EVENTDATA_SOURCE=HBASE,PIO_CONF_DIR=/Users/Marco/PredictionIO/conf,PIO_STORAGE_SOURCES_LOCALFS_PORTS=0,PIO_STORAGE_SOURCES_ELASTICSEARCH_PORTS=9300,PIO_STORAGE_SOURCES_LOCALFS_TYPE=localfs --engine-id IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I --engine-version 1601d4b44276e463819ccf16bcea2e968082ad77 --engine-variant /Users/Marco/SemanticAnalysisRepo/SemanticAnalysis/engine.json --verbosity 0
2015-04-08 16:03:20,885 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-08 16:03:21,907 INFO  io.prediction.controller.Engine [main] - Extracting datasource params...
2015-04-08 16:03:22,002 INFO  io.prediction.workflow.WorkflowUtils$ [main] - No 'name' is found. Default empty String will be used.
2015-04-08 16:03:22,019 INFO  io.prediction.controller.Engine [main] - Datasource params: (,DataSourceParams(1))
2015-04-08 16:03:22,020 INFO  io.prediction.controller.Engine [main] - Extracting preparator params...
2015-04-08 16:03:22,022 INFO  io.prediction.controller.Engine [main] - Preparator params: (,Empty)
2015-04-08 16:03:22,032 INFO  io.prediction.controller.Engine [main] - Extracting serving params...
2015-04-08 16:03:22,033 INFO  io.prediction.controller.Engine [main] - Serving params: (,Empty)
2015-04-08 16:03:23,849 INFO  Remoting [sparkDriver-akka.actor.default-dispatcher-3] - Starting remoting
2015-04-08 16:03:24,071 INFO  Remoting [sparkDriver-akka.actor.default-dispatcher-2] - Remoting started; listening on addresses :[akka.tcp://sparkDriver@10.0.22.139:55864]
2015-04-08 16:03:25,251 INFO  io.prediction.controller.Engine$ [main] - EngineWorkflow.train
2015-04-08 16:03:25,252 INFO  io.prediction.controller.Engine$ [main] - DataSource: SemanticAnalysis.DataSource@43f03c23
2015-04-08 16:03:25,253 INFO  io.prediction.controller.Engine$ [main] - Preparator: SemanticAnalysis.Preparator@3d40a3b4
2015-04-08 16:03:25,253 INFO  io.prediction.controller.Engine$ [main] - AlgorithmList: List(SemanticAnalysis.Algorithm@78307a56)
2015-04-08 16:03:25,254 INFO  io.prediction.controller.Engine$ [main] - Data santiy check is on.
2015-04-08 16:03:36,648 INFO  io.prediction.controller.Engine$ [main] - SemanticAnalysis.TrainingData does not support data sanity check. Skipping check.
2015-04-08 16:03:36,649 INFO  io.prediction.controller.Engine$ [main] - SemanticAnalysis.PreparedData does not support data sanity check. Skipping check.
2015-04-08 16:03:36,843 WARN  org.apache.hadoop.hbase.mapreduce.TableInputFormatBase [main] - Cannot resolve the host name for /10.0.22.139 because of javax.naming.NameNotFoundException: DNS name not found [response code 3]; remaining name '139.22.0.10.in-addr.arpa'
2015-04-08 16:03:43,858 ERROR org.apache.spark.executor.Executor [Executor task launch worker-0] - Exception in task 0.0 in stage 0.0 (TID 0)
java.lang.IllegalArgumentException: tokens must not be empty
	at opennlp.tools.util.StringList.<init>(StringList.java:61)
	at SemanticAnalysis.NGramMachine.extract(NGramMachine.java:18)
	at SemanticAnalysis.Algorithm$$anonfun$1.apply(Algorithm.scala:29)
	at SemanticAnalysis.Algorithm$$anonfun$1.apply(Algorithm.scala:28)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:328)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:48)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:103)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:47)
	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:273)
	at scala.collection.AbstractIterator.to(Iterator.scala:1157)
	at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:265)
	at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1157)
	at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:252)
	at scala.collection.AbstractIterator.toArray(Iterator.scala:1157)
	at org.apache.spark.rdd.RDD$$anonfun$org$apache$spark$rdd$RDD$$collectPartition$1$1.apply(RDD.scala:808)
	at org.apache.spark.rdd.RDD$$anonfun$org$apache$spark$rdd$RDD$$collectPartition$1$1.apply(RDD.scala:808)
	at org.apache.spark.SparkContext$$anonfun$runJob$4.apply(SparkContext.scala:1353)
	at org.apache.spark.SparkContext$$anonfun$runJob$4.apply(SparkContext.scala:1353)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:61)
	at org.apache.spark.scheduler.Task.run(Task.scala:56)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:200)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-04-08 16:03:43,875 WARN  org.apache.spark.scheduler.TaskSetManager [task-result-getter-0] - Lost task 0.0 in stage 0.0 (TID 0, localhost): java.lang.IllegalArgumentException: tokens must not be empty
	at opennlp.tools.util.StringList.<init>(StringList.java:61)
	at SemanticAnalysis.NGramMachine.extract(NGramMachine.java:18)
	at SemanticAnalysis.Algorithm$$anonfun$1.apply(Algorithm.scala:29)
	at SemanticAnalysis.Algorithm$$anonfun$1.apply(Algorithm.scala:28)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:328)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:48)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:103)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:47)
	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:273)
	at scala.collection.AbstractIterator.to(Iterator.scala:1157)
	at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:265)
	at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1157)
	at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:252)
	at scala.collection.AbstractIterator.toArray(Iterator.scala:1157)
	at org.apache.spark.rdd.RDD$$anonfun$org$apache$spark$rdd$RDD$$collectPartition$1$1.apply(RDD.scala:808)
	at org.apache.spark.rdd.RDD$$anonfun$org$apache$spark$rdd$RDD$$collectPartition$1$1.apply(RDD.scala:808)
	at org.apache.spark.SparkContext$$anonfun$runJob$4.apply(SparkContext.scala:1353)
	at org.apache.spark.SparkContext$$anonfun$runJob$4.apply(SparkContext.scala:1353)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:61)
	at org.apache.spark.scheduler.Task.run(Task.scala:56)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:200)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

2015-04-08 16:03:43,877 ERROR org.apache.spark.scheduler.TaskSetManager [task-result-getter-0] - Task 0 in stage 0.0 failed 1 times; aborting job
2015-04-08 16:07:39,777 INFO  io.prediction.tools.console.Console$ [main] - Using existing engine manifest JSON at /Users/Marco/SemanticAnalysisRepo/SemanticAnalysis/manifest.json
2015-04-08 16:07:39,826 INFO  io.prediction.tools.console.Console$ [main] - Using command '/Users/Marco/PredictionIO/sbt/sbt' at the current working directory to build.
2015-04-08 16:07:39,826 INFO  io.prediction.tools.console.Console$ [main] - If the path above is incorrect, this process will fail.
2015-04-08 16:07:39,827 INFO  io.prediction.tools.console.Console$ [main] - Uber JAR disabled. Making sure lib/pio-assembly-0.9.1.jar is absent.
2015-04-08 16:07:39,828 INFO  io.prediction.tools.console.Console$ [main] - Going to run: /Users/Marco/PredictionIO/sbt/sbt  package assemblyPackageDependency
2015-04-08 16:07:52,766 INFO  io.prediction.tools.console.Console$ [main] - Build finished successfully.
2015-04-08 16:07:52,767 INFO  io.prediction.tools.console.Console$ [main] - Looking for an engine...
2015-04-08 16:07:52,776 INFO  io.prediction.tools.console.Console$ [main] - Found SemanticAnalysis-assembly-1.0-deps.jar
2015-04-08 16:07:52,776 INFO  io.prediction.tools.console.Console$ [main] - Found semanticanalysis_2.10-1.0.jar
2015-04-08 16:07:52,787 INFO  io.prediction.tools.console.Console$ [main] - HADOOP_CONF_DIR is not set. Assuming HDFS is unavailable.
2015-04-08 16:07:54,535 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-08 16:07:54,647 INFO  io.prediction.tools.RegisterEngine$ [main] - Copying file:/Users/Marco/SemanticAnalysisRepo/SemanticAnalysis/target/scala-2.10/SemanticAnalysis-assembly-1.0-deps.jar to file:/Users/Marco/.pio_store/engines/IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I/1601d4b44276e463819ccf16bcea2e968082ad77/SemanticAnalysis-assembly-1.0-deps.jar
2015-04-08 16:07:54,726 INFO  io.prediction.tools.RegisterEngine$ [main] - Copying file:/Users/Marco/SemanticAnalysisRepo/SemanticAnalysis/target/scala-2.10/semanticanalysis_2.10-1.0.jar to file:/Users/Marco/.pio_store/engines/IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I/1601d4b44276e463819ccf16bcea2e968082ad77/semanticanalysis_2.10-1.0.jar
2015-04-08 16:07:54,741 INFO  io.prediction.tools.RegisterEngine$ [main] - Registering engine IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I 1601d4b44276e463819ccf16bcea2e968082ad77
2015-04-08 16:07:54,770 INFO  io.prediction.tools.console.Console$ [main] - Your engine is ready for training.
2015-04-08 16:07:58,492 INFO  io.prediction.tools.console.Console$ [main] - Using existing engine manifest JSON at /Users/Marco/SemanticAnalysisRepo/SemanticAnalysis/manifest.json
2015-04-08 16:08:00,119 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-08 16:08:00,225 INFO  io.prediction.tools.RunWorkflow$ [main] - Submission command: /Users/Marco/PredictionIO/vendors/spark-1.2.1/bin/spark-submit --class io.prediction.workflow.CreateWorkflow --name PredictionIO Training: IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I 1601d4b44276e463819ccf16bcea2e968082ad77 () --jars file:/Users/Marco/.pio_store/engines/IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I/1601d4b44276e463819ccf16bcea2e968082ad77/semanticanalysis_2.10-1.0.jar,file:/Users/Marco/.pio_store/engines/IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I/1601d4b44276e463819ccf16bcea2e968082ad77/SemanticAnalysis-assembly-1.0-deps.jar --files /Users/Marco/PredictionIO/conf/log4j.properties,/Users/Marco/PredictionIO/vendors/hbase-0.98.11/conf/hbase-site.xml --driver-class-path /Users/Marco/PredictionIO/conf:/Users/Marco/PredictionIO/vendors/hbase-0.98.11/conf /Users/Marco/PredictionIO/lib/pio-assembly-0.9.1.jar --env PIO_STORAGE_SOURCES_HBASE_TYPE=hbase,PIO_ENV_LOADED=1,PIO_STORAGE_SOURCES_HBASE_HOSTS=0,PIO_STORAGE_REPOSITORIES_METADATA_NAME=predictionio_metadata,PIO_FS_BASEDIR=/Users/Marco/.pio_store,PIO_STORAGE_SOURCES_ELASTICSEARCH_HOSTS=localhost,PIO_STORAGE_SOURCES_HBASE_HOME=/Users/Marco/PredictionIO/vendors/hbase-0.98.11,PIO_HOME=/Users/Marco/PredictionIO,PIO_FS_ENGINESDIR=/Users/Marco/.pio_store/engines,PIO_STORAGE_SOURCES_HBASE_PORTS=0,PIO_STORAGE_SOURCES_ELASTICSEARCH_TYPE=elasticsearch,PIO_STORAGE_REPOSITORIES_METADATA_SOURCE=ELASTICSEARCH,PIO_STORAGE_REPOSITORIES_MODELDATA_SOURCE=LOCALFS,PIO_STORAGE_REPOSITORIES_EVENTDATA_NAME=predictionio_eventdata,PIO_STORAGE_SOURCES_ELASTICSEARCH_HOME=/Users/Marco/PredictionIO/vendors/elasticsearch-1.4.4,PIO_FS_TMPDIR=/Users/Marco/.pio_store/tmp,PIO_STORAGE_REPOSITORIES_MODELDATA_NAME=pio_,PIO_STORAGE_SOURCES_LOCALFS_HOSTS=/Users/Marco/.pio_store/models,PIO_STORAGE_REPOSITORIES_EVENTDATA_SOURCE=HBASE,PIO_CONF_DIR=/Users/Marco/PredictionIO/conf,PIO_STORAGE_SOURCES_LOCALFS_PORTS=0,PIO_STORAGE_SOURCES_ELASTICSEARCH_PORTS=9300,PIO_STORAGE_SOURCES_LOCALFS_TYPE=localfs --engine-id IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I --engine-version 1601d4b44276e463819ccf16bcea2e968082ad77 --engine-variant /Users/Marco/SemanticAnalysisRepo/SemanticAnalysis/engine.json --verbosity 0
2015-04-08 16:08:01,987 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-08 16:08:02,832 INFO  io.prediction.controller.Engine [main] - Extracting datasource params...
2015-04-08 16:08:02,909 INFO  io.prediction.workflow.WorkflowUtils$ [main] - No 'name' is found. Default empty String will be used.
2015-04-08 16:08:02,919 INFO  io.prediction.controller.Engine [main] - Datasource params: (,DataSourceParams(1))
2015-04-08 16:08:02,920 INFO  io.prediction.controller.Engine [main] - Extracting preparator params...
2015-04-08 16:08:02,922 INFO  io.prediction.controller.Engine [main] - Preparator params: (,Empty)
2015-04-08 16:08:02,927 INFO  io.prediction.controller.Engine [main] - Extracting serving params...
2015-04-08 16:08:02,928 INFO  io.prediction.controller.Engine [main] - Serving params: (,Empty)
2015-04-08 16:08:04,576 INFO  Remoting [sparkDriver-akka.actor.default-dispatcher-2] - Starting remoting
2015-04-08 16:08:04,749 INFO  Remoting [sparkDriver-akka.actor.default-dispatcher-2] - Remoting started; listening on addresses :[akka.tcp://sparkDriver@10.0.22.139:55948]
2015-04-08 16:08:05,740 INFO  io.prediction.controller.Engine$ [main] - EngineWorkflow.train
2015-04-08 16:08:05,741 INFO  io.prediction.controller.Engine$ [main] - DataSource: SemanticAnalysis.DataSource@78307a56
2015-04-08 16:08:05,742 INFO  io.prediction.controller.Engine$ [main] - Preparator: SemanticAnalysis.Preparator@1983b48a
2015-04-08 16:08:05,743 INFO  io.prediction.controller.Engine$ [main] - AlgorithmList: List(SemanticAnalysis.Algorithm@4391a2d8)
2015-04-08 16:08:05,743 INFO  io.prediction.controller.Engine$ [main] - Data santiy check is on.
2015-04-08 16:08:11,988 INFO  io.prediction.controller.Engine$ [main] - SemanticAnalysis.TrainingData does not support data sanity check. Skipping check.
2015-04-08 16:08:11,989 INFO  io.prediction.controller.Engine$ [main] - SemanticAnalysis.PreparedData does not support data sanity check. Skipping check.
2015-04-08 16:08:12,123 WARN  org.apache.hadoop.hbase.mapreduce.TableInputFormatBase [main] - Cannot resolve the host name for /10.0.22.139 because of javax.naming.NameNotFoundException: DNS name not found [response code 3]; remaining name '139.22.0.10.in-addr.arpa'
2015-04-08 16:08:19,238 ERROR org.apache.spark.executor.Executor [Executor task launch worker-0] - Exception in task 0.0 in stage 0.0 (TID 0)
java.lang.IllegalArgumentException: tokens must not be empty
	at opennlp.tools.util.StringList.<init>(StringList.java:61)
	at SemanticAnalysis.NGramMachine.extract(NGramMachine.java:18)
	at SemanticAnalysis.Algorithm$$anonfun$1.apply(Algorithm.scala:29)
	at SemanticAnalysis.Algorithm$$anonfun$1.apply(Algorithm.scala:28)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:328)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:48)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:103)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:47)
	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:273)
	at scala.collection.AbstractIterator.to(Iterator.scala:1157)
	at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:265)
	at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1157)
	at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:252)
	at scala.collection.AbstractIterator.toArray(Iterator.scala:1157)
	at org.apache.spark.rdd.RDD$$anonfun$org$apache$spark$rdd$RDD$$collectPartition$1$1.apply(RDD.scala:808)
	at org.apache.spark.rdd.RDD$$anonfun$org$apache$spark$rdd$RDD$$collectPartition$1$1.apply(RDD.scala:808)
	at org.apache.spark.SparkContext$$anonfun$runJob$4.apply(SparkContext.scala:1353)
	at org.apache.spark.SparkContext$$anonfun$runJob$4.apply(SparkContext.scala:1353)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:61)
	at org.apache.spark.scheduler.Task.run(Task.scala:56)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:200)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-04-08 16:08:19,248 WARN  org.apache.spark.scheduler.TaskSetManager [task-result-getter-0] - Lost task 0.0 in stage 0.0 (TID 0, localhost): java.lang.IllegalArgumentException: tokens must not be empty
	at opennlp.tools.util.StringList.<init>(StringList.java:61)
	at SemanticAnalysis.NGramMachine.extract(NGramMachine.java:18)
	at SemanticAnalysis.Algorithm$$anonfun$1.apply(Algorithm.scala:29)
	at SemanticAnalysis.Algorithm$$anonfun$1.apply(Algorithm.scala:28)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:328)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:48)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:103)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:47)
	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:273)
	at scala.collection.AbstractIterator.to(Iterator.scala:1157)
	at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:265)
	at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1157)
	at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:252)
	at scala.collection.AbstractIterator.toArray(Iterator.scala:1157)
	at org.apache.spark.rdd.RDD$$anonfun$org$apache$spark$rdd$RDD$$collectPartition$1$1.apply(RDD.scala:808)
	at org.apache.spark.rdd.RDD$$anonfun$org$apache$spark$rdd$RDD$$collectPartition$1$1.apply(RDD.scala:808)
	at org.apache.spark.SparkContext$$anonfun$runJob$4.apply(SparkContext.scala:1353)
	at org.apache.spark.SparkContext$$anonfun$runJob$4.apply(SparkContext.scala:1353)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:61)
	at org.apache.spark.scheduler.Task.run(Task.scala:56)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:200)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

2015-04-08 16:08:19,250 ERROR org.apache.spark.scheduler.TaskSetManager [task-result-getter-0] - Task 0 in stage 0.0 failed 1 times; aborting job
2015-04-08 16:09:30,168 INFO  io.prediction.tools.console.Console$ [main] - Using existing engine manifest JSON at /Users/Marco/SemanticAnalysisRepo/SemanticAnalysis/manifest.json
2015-04-08 16:09:30,220 INFO  io.prediction.tools.console.Console$ [main] - Using command '/Users/Marco/PredictionIO/sbt/sbt' at the current working directory to build.
2015-04-08 16:09:30,220 INFO  io.prediction.tools.console.Console$ [main] - If the path above is incorrect, this process will fail.
2015-04-08 16:09:30,222 INFO  io.prediction.tools.console.Console$ [main] - Uber JAR disabled. Making sure lib/pio-assembly-0.9.1.jar is absent.
2015-04-08 16:09:30,223 INFO  io.prediction.tools.console.Console$ [main] - Going to run: /Users/Marco/PredictionIO/sbt/sbt  package assemblyPackageDependency
2015-04-08 16:09:40,457 INFO  io.prediction.tools.console.Console$ [main] - Build finished successfully.
2015-04-08 16:09:40,458 INFO  io.prediction.tools.console.Console$ [main] - Looking for an engine...
2015-04-08 16:09:40,467 INFO  io.prediction.tools.console.Console$ [main] - Found SemanticAnalysis-assembly-1.0-deps.jar
2015-04-08 16:09:40,467 INFO  io.prediction.tools.console.Console$ [main] - Found semanticanalysis_2.10-1.0.jar
2015-04-08 16:09:40,476 INFO  io.prediction.tools.console.Console$ [main] - HADOOP_CONF_DIR is not set. Assuming HDFS is unavailable.
2015-04-08 16:09:42,248 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-08 16:09:42,355 INFO  io.prediction.tools.RegisterEngine$ [main] - Copying file:/Users/Marco/SemanticAnalysisRepo/SemanticAnalysis/target/scala-2.10/SemanticAnalysis-assembly-1.0-deps.jar to file:/Users/Marco/.pio_store/engines/IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I/1601d4b44276e463819ccf16bcea2e968082ad77/SemanticAnalysis-assembly-1.0-deps.jar
2015-04-08 16:09:42,437 INFO  io.prediction.tools.RegisterEngine$ [main] - Copying file:/Users/Marco/SemanticAnalysisRepo/SemanticAnalysis/target/scala-2.10/semanticanalysis_2.10-1.0.jar to file:/Users/Marco/.pio_store/engines/IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I/1601d4b44276e463819ccf16bcea2e968082ad77/semanticanalysis_2.10-1.0.jar
2015-04-08 16:09:42,454 INFO  io.prediction.tools.RegisterEngine$ [main] - Registering engine IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I 1601d4b44276e463819ccf16bcea2e968082ad77
2015-04-08 16:09:42,479 INFO  io.prediction.tools.console.Console$ [main] - Your engine is ready for training.
2015-04-08 16:09:45,935 INFO  io.prediction.tools.console.Console$ [main] - Using existing engine manifest JSON at /Users/Marco/SemanticAnalysisRepo/SemanticAnalysis/manifest.json
2015-04-08 16:09:47,699 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-08 16:09:47,800 INFO  io.prediction.tools.RunWorkflow$ [main] - Submission command: /Users/Marco/PredictionIO/vendors/spark-1.2.1/bin/spark-submit --class io.prediction.workflow.CreateWorkflow --name PredictionIO Training: IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I 1601d4b44276e463819ccf16bcea2e968082ad77 () --jars file:/Users/Marco/.pio_store/engines/IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I/1601d4b44276e463819ccf16bcea2e968082ad77/semanticanalysis_2.10-1.0.jar,file:/Users/Marco/.pio_store/engines/IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I/1601d4b44276e463819ccf16bcea2e968082ad77/SemanticAnalysis-assembly-1.0-deps.jar --files /Users/Marco/PredictionIO/conf/log4j.properties,/Users/Marco/PredictionIO/vendors/hbase-0.98.11/conf/hbase-site.xml --driver-class-path /Users/Marco/PredictionIO/conf:/Users/Marco/PredictionIO/vendors/hbase-0.98.11/conf /Users/Marco/PredictionIO/lib/pio-assembly-0.9.1.jar --env PIO_STORAGE_SOURCES_HBASE_TYPE=hbase,PIO_ENV_LOADED=1,PIO_STORAGE_SOURCES_HBASE_HOSTS=0,PIO_STORAGE_REPOSITORIES_METADATA_NAME=predictionio_metadata,PIO_FS_BASEDIR=/Users/Marco/.pio_store,PIO_STORAGE_SOURCES_ELASTICSEARCH_HOSTS=localhost,PIO_STORAGE_SOURCES_HBASE_HOME=/Users/Marco/PredictionIO/vendors/hbase-0.98.11,PIO_HOME=/Users/Marco/PredictionIO,PIO_FS_ENGINESDIR=/Users/Marco/.pio_store/engines,PIO_STORAGE_SOURCES_HBASE_PORTS=0,PIO_STORAGE_SOURCES_ELASTICSEARCH_TYPE=elasticsearch,PIO_STORAGE_REPOSITORIES_METADATA_SOURCE=ELASTICSEARCH,PIO_STORAGE_REPOSITORIES_MODELDATA_SOURCE=LOCALFS,PIO_STORAGE_REPOSITORIES_EVENTDATA_NAME=predictionio_eventdata,PIO_STORAGE_SOURCES_ELASTICSEARCH_HOME=/Users/Marco/PredictionIO/vendors/elasticsearch-1.4.4,PIO_FS_TMPDIR=/Users/Marco/.pio_store/tmp,PIO_STORAGE_REPOSITORIES_MODELDATA_NAME=pio_,PIO_STORAGE_SOURCES_LOCALFS_HOSTS=/Users/Marco/.pio_store/models,PIO_STORAGE_REPOSITORIES_EVENTDATA_SOURCE=HBASE,PIO_CONF_DIR=/Users/Marco/PredictionIO/conf,PIO_STORAGE_SOURCES_LOCALFS_PORTS=0,PIO_STORAGE_SOURCES_ELASTICSEARCH_PORTS=9300,PIO_STORAGE_SOURCES_LOCALFS_TYPE=localfs --engine-id IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I --engine-version 1601d4b44276e463819ccf16bcea2e968082ad77 --engine-variant /Users/Marco/SemanticAnalysisRepo/SemanticAnalysis/engine.json --verbosity 0
2015-04-08 16:09:49,606 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-08 16:09:50,429 INFO  io.prediction.controller.Engine [main] - Extracting datasource params...
2015-04-08 16:09:50,518 INFO  io.prediction.workflow.WorkflowUtils$ [main] - No 'name' is found. Default empty String will be used.
2015-04-08 16:09:50,529 INFO  io.prediction.controller.Engine [main] - Datasource params: (,DataSourceParams(1))
2015-04-08 16:09:50,529 INFO  io.prediction.controller.Engine [main] - Extracting preparator params...
2015-04-08 16:09:50,530 INFO  io.prediction.controller.Engine [main] - Preparator params: (,Empty)
2015-04-08 16:09:50,535 INFO  io.prediction.controller.Engine [main] - Extracting serving params...
2015-04-08 16:09:50,536 INFO  io.prediction.controller.Engine [main] - Serving params: (,Empty)
2015-04-08 16:09:52,203 INFO  Remoting [sparkDriver-akka.actor.default-dispatcher-3] - Starting remoting
2015-04-08 16:09:52,362 INFO  Remoting [sparkDriver-akka.actor.default-dispatcher-3] - Remoting started; listening on addresses :[akka.tcp://sparkDriver@10.0.22.139:56028]
2015-04-08 16:09:53,295 INFO  io.prediction.controller.Engine$ [main] - EngineWorkflow.train
2015-04-08 16:09:53,295 INFO  io.prediction.controller.Engine$ [main] - DataSource: SemanticAnalysis.DataSource@23ad71bf
2015-04-08 16:09:53,296 INFO  io.prediction.controller.Engine$ [main] - Preparator: SemanticAnalysis.Preparator@b791a81
2015-04-08 16:09:53,297 INFO  io.prediction.controller.Engine$ [main] - AlgorithmList: List(SemanticAnalysis.Algorithm@71e7adbb)
2015-04-08 16:09:53,297 INFO  io.prediction.controller.Engine$ [main] - Data santiy check is on.
2015-04-08 16:10:05,582 INFO  io.prediction.controller.Engine$ [main] - SemanticAnalysis.TrainingData does not support data sanity check. Skipping check.
2015-04-08 16:10:05,583 INFO  io.prediction.controller.Engine$ [main] - SemanticAnalysis.PreparedData does not support data sanity check. Skipping check.
2015-04-08 16:10:05,819 WARN  org.apache.hadoop.hbase.mapreduce.TableInputFormatBase [main] - Cannot resolve the host name for /10.0.22.139 because of javax.naming.NameNotFoundException: DNS name not found [response code 3]; remaining name '139.22.0.10.in-addr.arpa'
2015-04-08 16:10:20,263 ERROR org.apache.spark.executor.Executor [Executor task launch worker-0] - Exception in task 0.0 in stage 0.0 (TID 0)
java.lang.IllegalArgumentException: tokens must not be empty
	at opennlp.tools.util.StringList.<init>(StringList.java:61)
	at SemanticAnalysis.NGramMachine.extract(NGramMachine.java:20)
	at SemanticAnalysis.Algorithm$$anonfun$1.apply(Algorithm.scala:29)
	at SemanticAnalysis.Algorithm$$anonfun$1.apply(Algorithm.scala:28)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:328)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:48)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:103)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:47)
	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:273)
	at scala.collection.AbstractIterator.to(Iterator.scala:1157)
	at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:265)
	at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1157)
	at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:252)
	at scala.collection.AbstractIterator.toArray(Iterator.scala:1157)
	at org.apache.spark.rdd.RDD$$anonfun$org$apache$spark$rdd$RDD$$collectPartition$1$1.apply(RDD.scala:808)
	at org.apache.spark.rdd.RDD$$anonfun$org$apache$spark$rdd$RDD$$collectPartition$1$1.apply(RDD.scala:808)
	at org.apache.spark.SparkContext$$anonfun$runJob$4.apply(SparkContext.scala:1353)
	at org.apache.spark.SparkContext$$anonfun$runJob$4.apply(SparkContext.scala:1353)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:61)
	at org.apache.spark.scheduler.Task.run(Task.scala:56)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:200)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-04-08 16:10:20,281 WARN  org.apache.spark.scheduler.TaskSetManager [task-result-getter-0] - Lost task 0.0 in stage 0.0 (TID 0, localhost): java.lang.IllegalArgumentException: tokens must not be empty
	at opennlp.tools.util.StringList.<init>(StringList.java:61)
	at SemanticAnalysis.NGramMachine.extract(NGramMachine.java:20)
	at SemanticAnalysis.Algorithm$$anonfun$1.apply(Algorithm.scala:29)
	at SemanticAnalysis.Algorithm$$anonfun$1.apply(Algorithm.scala:28)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:328)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:48)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:103)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:47)
	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:273)
	at scala.collection.AbstractIterator.to(Iterator.scala:1157)
	at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:265)
	at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1157)
	at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:252)
	at scala.collection.AbstractIterator.toArray(Iterator.scala:1157)
	at org.apache.spark.rdd.RDD$$anonfun$org$apache$spark$rdd$RDD$$collectPartition$1$1.apply(RDD.scala:808)
	at org.apache.spark.rdd.RDD$$anonfun$org$apache$spark$rdd$RDD$$collectPartition$1$1.apply(RDD.scala:808)
	at org.apache.spark.SparkContext$$anonfun$runJob$4.apply(SparkContext.scala:1353)
	at org.apache.spark.SparkContext$$anonfun$runJob$4.apply(SparkContext.scala:1353)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:61)
	at org.apache.spark.scheduler.Task.run(Task.scala:56)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:200)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

2015-04-08 16:10:20,283 ERROR org.apache.spark.scheduler.TaskSetManager [task-result-getter-0] - Task 0 in stage 0.0 failed 1 times; aborting job
2015-04-08 16:13:33,455 INFO  io.prediction.tools.console.Console$ [main] - Using existing engine manifest JSON at /Users/Marco/SemanticAnalysisRepo/SemanticAnalysis/manifest.json
2015-04-08 16:13:35,140 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-08 16:13:35,250 INFO  io.prediction.tools.RunWorkflow$ [main] - Submission command: /Users/Marco/PredictionIO/vendors/spark-1.2.1/bin/spark-submit --class io.prediction.workflow.CreateWorkflow --name PredictionIO Training: IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I 1601d4b44276e463819ccf16bcea2e968082ad77 () --jars file:/Users/Marco/.pio_store/engines/IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I/1601d4b44276e463819ccf16bcea2e968082ad77/semanticanalysis_2.10-1.0.jar,file:/Users/Marco/.pio_store/engines/IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I/1601d4b44276e463819ccf16bcea2e968082ad77/SemanticAnalysis-assembly-1.0-deps.jar --files /Users/Marco/PredictionIO/conf/log4j.properties,/Users/Marco/PredictionIO/vendors/hbase-0.98.11/conf/hbase-site.xml --driver-class-path /Users/Marco/PredictionIO/conf:/Users/Marco/PredictionIO/vendors/hbase-0.98.11/conf /Users/Marco/PredictionIO/lib/pio-assembly-0.9.1.jar --env PIO_STORAGE_SOURCES_HBASE_TYPE=hbase,PIO_ENV_LOADED=1,PIO_STORAGE_SOURCES_HBASE_HOSTS=0,PIO_STORAGE_REPOSITORIES_METADATA_NAME=predictionio_metadata,PIO_FS_BASEDIR=/Users/Marco/.pio_store,PIO_STORAGE_SOURCES_ELASTICSEARCH_HOSTS=localhost,PIO_STORAGE_SOURCES_HBASE_HOME=/Users/Marco/PredictionIO/vendors/hbase-0.98.11,PIO_HOME=/Users/Marco/PredictionIO,PIO_FS_ENGINESDIR=/Users/Marco/.pio_store/engines,PIO_STORAGE_SOURCES_HBASE_PORTS=0,PIO_STORAGE_SOURCES_ELASTICSEARCH_TYPE=elasticsearch,PIO_STORAGE_REPOSITORIES_METADATA_SOURCE=ELASTICSEARCH,PIO_STORAGE_REPOSITORIES_MODELDATA_SOURCE=LOCALFS,PIO_STORAGE_REPOSITORIES_EVENTDATA_NAME=predictionio_eventdata,PIO_STORAGE_SOURCES_ELASTICSEARCH_HOME=/Users/Marco/PredictionIO/vendors/elasticsearch-1.4.4,PIO_FS_TMPDIR=/Users/Marco/.pio_store/tmp,PIO_STORAGE_REPOSITORIES_MODELDATA_NAME=pio_,PIO_STORAGE_SOURCES_LOCALFS_HOSTS=/Users/Marco/.pio_store/models,PIO_STORAGE_REPOSITORIES_EVENTDATA_SOURCE=HBASE,PIO_CONF_DIR=/Users/Marco/PredictionIO/conf,PIO_STORAGE_SOURCES_LOCALFS_PORTS=0,PIO_STORAGE_SOURCES_ELASTICSEARCH_PORTS=9300,PIO_STORAGE_SOURCES_LOCALFS_TYPE=localfs --engine-id IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I --engine-version 1601d4b44276e463819ccf16bcea2e968082ad77 --engine-variant /Users/Marco/SemanticAnalysisRepo/SemanticAnalysis/engine.json --verbosity 0
2015-04-08 16:13:36,998 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-08 16:13:37,851 INFO  io.prediction.controller.Engine [main] - Extracting datasource params...
2015-04-08 16:13:37,933 INFO  io.prediction.workflow.WorkflowUtils$ [main] - No 'name' is found. Default empty String will be used.
2015-04-08 16:13:37,952 INFO  io.prediction.controller.Engine [main] - Datasource params: (,DataSourceParams(1))
2015-04-08 16:13:37,953 INFO  io.prediction.controller.Engine [main] - Extracting preparator params...
2015-04-08 16:13:37,965 INFO  io.prediction.controller.Engine [main] - Preparator params: (,Empty)
2015-04-08 16:13:37,976 INFO  io.prediction.controller.Engine [main] - Extracting serving params...
2015-04-08 16:13:37,976 INFO  io.prediction.controller.Engine [main] - Serving params: (,Empty)
2015-04-08 16:13:39,617 INFO  Remoting [sparkDriver-akka.actor.default-dispatcher-3] - Starting remoting
2015-04-08 16:13:39,793 INFO  Remoting [sparkDriver-akka.actor.default-dispatcher-3] - Remoting started; listening on addresses :[akka.tcp://sparkDriver@10.0.22.139:56085]
2015-04-08 16:13:40,751 INFO  io.prediction.controller.Engine$ [main] - EngineWorkflow.train
2015-04-08 16:13:40,752 INFO  io.prediction.controller.Engine$ [main] - DataSource: SemanticAnalysis.DataSource@43f03c23
2015-04-08 16:13:40,753 INFO  io.prediction.controller.Engine$ [main] - Preparator: SemanticAnalysis.Preparator@3d40a3b4
2015-04-08 16:13:40,753 INFO  io.prediction.controller.Engine$ [main] - AlgorithmList: List(SemanticAnalysis.Algorithm@78307a56)
2015-04-08 16:13:40,754 INFO  io.prediction.controller.Engine$ [main] - Data santiy check is on.
2015-04-08 16:13:47,021 INFO  io.prediction.controller.Engine$ [main] - SemanticAnalysis.TrainingData does not support data sanity check. Skipping check.
2015-04-08 16:13:47,022 INFO  io.prediction.controller.Engine$ [main] - SemanticAnalysis.PreparedData does not support data sanity check. Skipping check.
2015-04-08 16:13:47,155 WARN  org.apache.hadoop.hbase.mapreduce.TableInputFormatBase [main] - Cannot resolve the host name for /10.0.22.139 because of javax.naming.NameNotFoundException: DNS name not found [response code 3]; remaining name '139.22.0.10.in-addr.arpa'
2015-04-08 16:13:54,215 ERROR org.apache.spark.executor.Executor [Executor task launch worker-0] - Exception in task 0.0 in stage 0.0 (TID 0)
java.lang.IllegalArgumentException: tokens must not be empty
	at opennlp.tools.util.StringList.<init>(StringList.java:61)
	at SemanticAnalysis.NGramMachine.extract(NGramMachine.java:20)
	at SemanticAnalysis.Algorithm$$anonfun$1.apply(Algorithm.scala:29)
	at SemanticAnalysis.Algorithm$$anonfun$1.apply(Algorithm.scala:28)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:328)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:48)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:103)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:47)
	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:273)
	at scala.collection.AbstractIterator.to(Iterator.scala:1157)
	at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:265)
	at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1157)
	at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:252)
	at scala.collection.AbstractIterator.toArray(Iterator.scala:1157)
	at org.apache.spark.rdd.RDD$$anonfun$org$apache$spark$rdd$RDD$$collectPartition$1$1.apply(RDD.scala:808)
	at org.apache.spark.rdd.RDD$$anonfun$org$apache$spark$rdd$RDD$$collectPartition$1$1.apply(RDD.scala:808)
	at org.apache.spark.SparkContext$$anonfun$runJob$4.apply(SparkContext.scala:1353)
	at org.apache.spark.SparkContext$$anonfun$runJob$4.apply(SparkContext.scala:1353)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:61)
	at org.apache.spark.scheduler.Task.run(Task.scala:56)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:200)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-04-08 16:13:54,229 WARN  org.apache.spark.scheduler.TaskSetManager [task-result-getter-0] - Lost task 0.0 in stage 0.0 (TID 0, localhost): java.lang.IllegalArgumentException: tokens must not be empty
	at opennlp.tools.util.StringList.<init>(StringList.java:61)
	at SemanticAnalysis.NGramMachine.extract(NGramMachine.java:20)
	at SemanticAnalysis.Algorithm$$anonfun$1.apply(Algorithm.scala:29)
	at SemanticAnalysis.Algorithm$$anonfun$1.apply(Algorithm.scala:28)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:328)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:48)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:103)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:47)
	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:273)
	at scala.collection.AbstractIterator.to(Iterator.scala:1157)
	at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:265)
	at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1157)
	at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:252)
	at scala.collection.AbstractIterator.toArray(Iterator.scala:1157)
	at org.apache.spark.rdd.RDD$$anonfun$org$apache$spark$rdd$RDD$$collectPartition$1$1.apply(RDD.scala:808)
	at org.apache.spark.rdd.RDD$$anonfun$org$apache$spark$rdd$RDD$$collectPartition$1$1.apply(RDD.scala:808)
	at org.apache.spark.SparkContext$$anonfun$runJob$4.apply(SparkContext.scala:1353)
	at org.apache.spark.SparkContext$$anonfun$runJob$4.apply(SparkContext.scala:1353)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:61)
	at org.apache.spark.scheduler.Task.run(Task.scala:56)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:200)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

2015-04-08 16:13:54,231 ERROR org.apache.spark.scheduler.TaskSetManager [task-result-getter-0] - Task 0 in stage 0.0 failed 1 times; aborting job
2015-04-08 16:21:29,302 INFO  io.prediction.tools.console.Console$ [main] - Using existing engine manifest JSON at /Users/Marco/SemanticAnalysisRepo/SemanticAnalysis/manifest.json
2015-04-08 16:21:30,932 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-08 16:21:31,052 INFO  io.prediction.tools.RunWorkflow$ [main] - Submission command: /Users/Marco/PredictionIO/vendors/spark-1.2.1/bin/spark-submit --class io.prediction.workflow.CreateWorkflow --name PredictionIO Training: IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I 1601d4b44276e463819ccf16bcea2e968082ad77 () --jars file:/Users/Marco/.pio_store/engines/IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I/1601d4b44276e463819ccf16bcea2e968082ad77/semanticanalysis_2.10-1.0.jar,file:/Users/Marco/.pio_store/engines/IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I/1601d4b44276e463819ccf16bcea2e968082ad77/SemanticAnalysis-assembly-1.0-deps.jar --files /Users/Marco/PredictionIO/conf/log4j.properties,/Users/Marco/PredictionIO/vendors/hbase-0.98.11/conf/hbase-site.xml --driver-class-path /Users/Marco/PredictionIO/conf:/Users/Marco/PredictionIO/vendors/hbase-0.98.11/conf /Users/Marco/PredictionIO/lib/pio-assembly-0.9.1.jar --env PIO_STORAGE_SOURCES_HBASE_TYPE=hbase,PIO_ENV_LOADED=1,PIO_STORAGE_SOURCES_HBASE_HOSTS=0,PIO_STORAGE_REPOSITORIES_METADATA_NAME=predictionio_metadata,PIO_FS_BASEDIR=/Users/Marco/.pio_store,PIO_STORAGE_SOURCES_ELASTICSEARCH_HOSTS=localhost,PIO_STORAGE_SOURCES_HBASE_HOME=/Users/Marco/PredictionIO/vendors/hbase-0.98.11,PIO_HOME=/Users/Marco/PredictionIO,PIO_FS_ENGINESDIR=/Users/Marco/.pio_store/engines,PIO_STORAGE_SOURCES_HBASE_PORTS=0,PIO_STORAGE_SOURCES_ELASTICSEARCH_TYPE=elasticsearch,PIO_STORAGE_REPOSITORIES_METADATA_SOURCE=ELASTICSEARCH,PIO_STORAGE_REPOSITORIES_MODELDATA_SOURCE=LOCALFS,PIO_STORAGE_REPOSITORIES_EVENTDATA_NAME=predictionio_eventdata,PIO_STORAGE_SOURCES_ELASTICSEARCH_HOME=/Users/Marco/PredictionIO/vendors/elasticsearch-1.4.4,PIO_FS_TMPDIR=/Users/Marco/.pio_store/tmp,PIO_STORAGE_REPOSITORIES_MODELDATA_NAME=pio_,PIO_STORAGE_SOURCES_LOCALFS_HOSTS=/Users/Marco/.pio_store/models,PIO_STORAGE_REPOSITORIES_EVENTDATA_SOURCE=HBASE,PIO_CONF_DIR=/Users/Marco/PredictionIO/conf,PIO_STORAGE_SOURCES_LOCALFS_PORTS=0,PIO_STORAGE_SOURCES_ELASTICSEARCH_PORTS=9300,PIO_STORAGE_SOURCES_LOCALFS_TYPE=localfs --engine-id IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I --engine-version 1601d4b44276e463819ccf16bcea2e968082ad77 --engine-variant /Users/Marco/SemanticAnalysisRepo/SemanticAnalysis/engine.json --verbosity 0
2015-04-08 16:21:32,883 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-08 16:21:33,711 INFO  io.prediction.controller.Engine [main] - Extracting datasource params...
2015-04-08 16:21:33,794 INFO  io.prediction.workflow.WorkflowUtils$ [main] - No 'name' is found. Default empty String will be used.
2015-04-08 16:21:33,805 INFO  io.prediction.controller.Engine [main] - Datasource params: (,DataSourceParams(1))
2015-04-08 16:21:33,805 INFO  io.prediction.controller.Engine [main] - Extracting preparator params...
2015-04-08 16:21:33,806 INFO  io.prediction.controller.Engine [main] - Preparator params: (,Empty)
2015-04-08 16:21:33,812 INFO  io.prediction.controller.Engine [main] - Extracting serving params...
2015-04-08 16:21:33,813 INFO  io.prediction.controller.Engine [main] - Serving params: (,Empty)
2015-04-08 16:21:35,402 INFO  Remoting [sparkDriver-akka.actor.default-dispatcher-3] - Starting remoting
2015-04-08 16:21:35,582 INFO  Remoting [sparkDriver-akka.actor.default-dispatcher-3] - Remoting started; listening on addresses :[akka.tcp://sparkDriver@10.0.22.139:56218]
2015-04-08 16:21:36,477 INFO  io.prediction.controller.Engine$ [main] - EngineWorkflow.train
2015-04-08 16:21:36,477 INFO  io.prediction.controller.Engine$ [main] - DataSource: SemanticAnalysis.DataSource@43f03c23
2015-04-08 16:21:36,478 INFO  io.prediction.controller.Engine$ [main] - Preparator: SemanticAnalysis.Preparator@3d40a3b4
2015-04-08 16:21:36,478 INFO  io.prediction.controller.Engine$ [main] - AlgorithmList: List(SemanticAnalysis.Algorithm@78307a56)
2015-04-08 16:21:36,478 INFO  io.prediction.controller.Engine$ [main] - Data santiy check is on.
2015-04-08 16:21:37,707 INFO  io.prediction.controller.Engine$ [main] - SemanticAnalysis.TrainingData does not support data sanity check. Skipping check.
2015-04-08 16:21:37,708 INFO  io.prediction.controller.Engine$ [main] - SemanticAnalysis.PreparedData does not support data sanity check. Skipping check.
2015-04-08 16:21:37,843 WARN  org.apache.hadoop.hbase.mapreduce.TableInputFormatBase [main] - Cannot resolve the host name for /10.0.22.139 because of javax.naming.NameNotFoundException: DNS name not found [response code 3]; remaining name '139.22.0.10.in-addr.arpa'
2015-04-08 16:21:45,093 ERROR org.apache.spark.executor.Executor [Executor task launch worker-0] - Exception in task 0.0 in stage 0.0 (TID 0)
java.lang.IllegalArgumentException: tokens must not be empty
	at opennlp.tools.util.StringList.<init>(StringList.java:61)
	at SemanticAnalysis.NGramMachine.extract(NGramMachine.java:20)
	at SemanticAnalysis.Algorithm$$anonfun$1.apply(Algorithm.scala:29)
	at SemanticAnalysis.Algorithm$$anonfun$1.apply(Algorithm.scala:28)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:328)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:48)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:103)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:47)
	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:273)
	at scala.collection.AbstractIterator.to(Iterator.scala:1157)
	at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:265)
	at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1157)
	at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:252)
	at scala.collection.AbstractIterator.toArray(Iterator.scala:1157)
	at org.apache.spark.rdd.RDD$$anonfun$org$apache$spark$rdd$RDD$$collectPartition$1$1.apply(RDD.scala:808)
	at org.apache.spark.rdd.RDD$$anonfun$org$apache$spark$rdd$RDD$$collectPartition$1$1.apply(RDD.scala:808)
	at org.apache.spark.SparkContext$$anonfun$runJob$4.apply(SparkContext.scala:1353)
	at org.apache.spark.SparkContext$$anonfun$runJob$4.apply(SparkContext.scala:1353)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:61)
	at org.apache.spark.scheduler.Task.run(Task.scala:56)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:200)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-04-08 16:21:45,103 WARN  org.apache.spark.scheduler.TaskSetManager [task-result-getter-0] - Lost task 0.0 in stage 0.0 (TID 0, localhost): java.lang.IllegalArgumentException: tokens must not be empty
	at opennlp.tools.util.StringList.<init>(StringList.java:61)
	at SemanticAnalysis.NGramMachine.extract(NGramMachine.java:20)
	at SemanticAnalysis.Algorithm$$anonfun$1.apply(Algorithm.scala:29)
	at SemanticAnalysis.Algorithm$$anonfun$1.apply(Algorithm.scala:28)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:328)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:48)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:103)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:47)
	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:273)
	at scala.collection.AbstractIterator.to(Iterator.scala:1157)
	at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:265)
	at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1157)
	at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:252)
	at scala.collection.AbstractIterator.toArray(Iterator.scala:1157)
	at org.apache.spark.rdd.RDD$$anonfun$org$apache$spark$rdd$RDD$$collectPartition$1$1.apply(RDD.scala:808)
	at org.apache.spark.rdd.RDD$$anonfun$org$apache$spark$rdd$RDD$$collectPartition$1$1.apply(RDD.scala:808)
	at org.apache.spark.SparkContext$$anonfun$runJob$4.apply(SparkContext.scala:1353)
	at org.apache.spark.SparkContext$$anonfun$runJob$4.apply(SparkContext.scala:1353)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:61)
	at org.apache.spark.scheduler.Task.run(Task.scala:56)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:200)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

2015-04-08 16:21:45,105 ERROR org.apache.spark.scheduler.TaskSetManager [task-result-getter-0] - Task 0 in stage 0.0 failed 1 times; aborting job
2015-04-08 16:30:16,845 INFO  io.prediction.tools.console.Console$ [main] - Using existing engine manifest JSON at /Users/Marco/SemanticAnalysisRepo/SemanticAnalysis/manifest.json
2015-04-08 16:30:16,895 INFO  io.prediction.tools.console.Console$ [main] - Using command '/Users/Marco/PredictionIO/sbt/sbt' at the current working directory to build.
2015-04-08 16:30:16,896 INFO  io.prediction.tools.console.Console$ [main] - If the path above is incorrect, this process will fail.
2015-04-08 16:30:16,897 INFO  io.prediction.tools.console.Console$ [main] - Uber JAR disabled. Making sure lib/pio-assembly-0.9.1.jar is absent.
2015-04-08 16:30:16,897 INFO  io.prediction.tools.console.Console$ [main] - Going to run: /Users/Marco/PredictionIO/sbt/sbt  package assemblyPackageDependency
2015-04-08 16:30:32,810 INFO  io.prediction.tools.console.Console$ [main] - Build finished successfully.
2015-04-08 16:30:32,811 INFO  io.prediction.tools.console.Console$ [main] - Looking for an engine...
2015-04-08 16:30:32,819 INFO  io.prediction.tools.console.Console$ [main] - Found SemanticAnalysis-assembly-1.0-deps.jar
2015-04-08 16:30:32,819 INFO  io.prediction.tools.console.Console$ [main] - Found semanticanalysis_2.10-1.0.jar
2015-04-08 16:30:32,827 INFO  io.prediction.tools.console.Console$ [main] - HADOOP_CONF_DIR is not set. Assuming HDFS is unavailable.
2015-04-08 16:30:34,554 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-08 16:30:34,673 INFO  io.prediction.tools.RegisterEngine$ [main] - Copying file:/Users/Marco/SemanticAnalysisRepo/SemanticAnalysis/target/scala-2.10/SemanticAnalysis-assembly-1.0-deps.jar to file:/Users/Marco/.pio_store/engines/IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I/1601d4b44276e463819ccf16bcea2e968082ad77/SemanticAnalysis-assembly-1.0-deps.jar
2015-04-08 16:30:34,756 INFO  io.prediction.tools.RegisterEngine$ [main] - Copying file:/Users/Marco/SemanticAnalysisRepo/SemanticAnalysis/target/scala-2.10/semanticanalysis_2.10-1.0.jar to file:/Users/Marco/.pio_store/engines/IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I/1601d4b44276e463819ccf16bcea2e968082ad77/semanticanalysis_2.10-1.0.jar
2015-04-08 16:30:34,769 INFO  io.prediction.tools.RegisterEngine$ [main] - Registering engine IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I 1601d4b44276e463819ccf16bcea2e968082ad77
2015-04-08 16:30:34,806 INFO  io.prediction.tools.console.Console$ [main] - Your engine is ready for training.
2015-04-08 16:30:38,864 INFO  io.prediction.tools.console.Console$ [main] - Using existing engine manifest JSON at /Users/Marco/SemanticAnalysisRepo/SemanticAnalysis/manifest.json
2015-04-08 16:30:40,537 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-08 16:30:40,640 INFO  io.prediction.tools.RunWorkflow$ [main] - Submission command: /Users/Marco/PredictionIO/vendors/spark-1.2.1/bin/spark-submit --class io.prediction.workflow.CreateWorkflow --name PredictionIO Training: IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I 1601d4b44276e463819ccf16bcea2e968082ad77 () --jars file:/Users/Marco/.pio_store/engines/IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I/1601d4b44276e463819ccf16bcea2e968082ad77/semanticanalysis_2.10-1.0.jar,file:/Users/Marco/.pio_store/engines/IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I/1601d4b44276e463819ccf16bcea2e968082ad77/SemanticAnalysis-assembly-1.0-deps.jar --files /Users/Marco/PredictionIO/conf/log4j.properties,/Users/Marco/PredictionIO/vendors/hbase-0.98.11/conf/hbase-site.xml --driver-class-path /Users/Marco/PredictionIO/conf:/Users/Marco/PredictionIO/vendors/hbase-0.98.11/conf /Users/Marco/PredictionIO/lib/pio-assembly-0.9.1.jar --env PIO_STORAGE_SOURCES_HBASE_TYPE=hbase,PIO_ENV_LOADED=1,PIO_STORAGE_SOURCES_HBASE_HOSTS=0,PIO_STORAGE_REPOSITORIES_METADATA_NAME=predictionio_metadata,PIO_FS_BASEDIR=/Users/Marco/.pio_store,PIO_STORAGE_SOURCES_ELASTICSEARCH_HOSTS=localhost,PIO_STORAGE_SOURCES_HBASE_HOME=/Users/Marco/PredictionIO/vendors/hbase-0.98.11,PIO_HOME=/Users/Marco/PredictionIO,PIO_FS_ENGINESDIR=/Users/Marco/.pio_store/engines,PIO_STORAGE_SOURCES_HBASE_PORTS=0,PIO_STORAGE_SOURCES_ELASTICSEARCH_TYPE=elasticsearch,PIO_STORAGE_REPOSITORIES_METADATA_SOURCE=ELASTICSEARCH,PIO_STORAGE_REPOSITORIES_MODELDATA_SOURCE=LOCALFS,PIO_STORAGE_REPOSITORIES_EVENTDATA_NAME=predictionio_eventdata,PIO_STORAGE_SOURCES_ELASTICSEARCH_HOME=/Users/Marco/PredictionIO/vendors/elasticsearch-1.4.4,PIO_FS_TMPDIR=/Users/Marco/.pio_store/tmp,PIO_STORAGE_REPOSITORIES_MODELDATA_NAME=pio_,PIO_STORAGE_SOURCES_LOCALFS_HOSTS=/Users/Marco/.pio_store/models,PIO_STORAGE_REPOSITORIES_EVENTDATA_SOURCE=HBASE,PIO_CONF_DIR=/Users/Marco/PredictionIO/conf,PIO_STORAGE_SOURCES_LOCALFS_PORTS=0,PIO_STORAGE_SOURCES_ELASTICSEARCH_PORTS=9300,PIO_STORAGE_SOURCES_LOCALFS_TYPE=localfs --engine-id IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I --engine-version 1601d4b44276e463819ccf16bcea2e968082ad77 --engine-variant /Users/Marco/SemanticAnalysisRepo/SemanticAnalysis/engine.json --verbosity 0
2015-04-08 16:30:42,418 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-08 16:30:43,304 INFO  io.prediction.controller.Engine [main] - Extracting datasource params...
2015-04-08 16:30:43,382 INFO  io.prediction.workflow.WorkflowUtils$ [main] - No 'name' is found. Default empty String will be used.
2015-04-08 16:30:43,394 INFO  io.prediction.controller.Engine [main] - Datasource params: (,DataSourceParams(1))
2015-04-08 16:30:43,395 INFO  io.prediction.controller.Engine [main] - Extracting preparator params...
2015-04-08 16:30:43,396 INFO  io.prediction.controller.Engine [main] - Preparator params: (,Empty)
2015-04-08 16:30:43,402 INFO  io.prediction.controller.Engine [main] - Extracting serving params...
2015-04-08 16:30:43,402 INFO  io.prediction.controller.Engine [main] - Serving params: (,Empty)
2015-04-08 16:30:45,112 INFO  Remoting [sparkDriver-akka.actor.default-dispatcher-3] - Starting remoting
2015-04-08 16:30:45,284 INFO  Remoting [sparkDriver-akka.actor.default-dispatcher-3] - Remoting started; listening on addresses :[akka.tcp://sparkDriver@10.0.22.139:56303]
2015-04-08 16:30:46,243 INFO  io.prediction.controller.Engine$ [main] - EngineWorkflow.train
2015-04-08 16:30:46,244 INFO  io.prediction.controller.Engine$ [main] - DataSource: SemanticAnalysis.DataSource@78307a56
2015-04-08 16:30:46,244 INFO  io.prediction.controller.Engine$ [main] - Preparator: SemanticAnalysis.Preparator@1983b48a
2015-04-08 16:30:46,245 INFO  io.prediction.controller.Engine$ [main] - AlgorithmList: List(SemanticAnalysis.Algorithm@4391a2d8)
2015-04-08 16:30:46,245 INFO  io.prediction.controller.Engine$ [main] - Data santiy check is on.
2015-04-08 16:30:57,504 INFO  io.prediction.controller.Engine$ [main] - SemanticAnalysis.TrainingData does not support data sanity check. Skipping check.
2015-04-08 16:30:57,506 INFO  io.prediction.controller.Engine$ [main] - SemanticAnalysis.PreparedData does not support data sanity check. Skipping check.
2015-04-08 16:30:57,642 WARN  org.apache.hadoop.hbase.mapreduce.TableInputFormatBase [main] - Cannot resolve the host name for /10.0.22.139 because of javax.naming.NameNotFoundException: DNS name not found [response code 3]; remaining name '139.22.0.10.in-addr.arpa'
2015-04-08 16:31:04,903 ERROR org.apache.spark.executor.Executor [Executor task launch worker-0] - Exception in task 0.0 in stage 0.0 (TID 0)
java.lang.IllegalArgumentException: tokens must not be empty
	at opennlp.tools.util.StringList.<init>(StringList.java:61)
	at SemanticAnalysis.NGramMachine.extract(NGramMachine.java:19)
	at SemanticAnalysis.Algorithm$$anonfun$2.apply(Algorithm.scala:29)
	at SemanticAnalysis.Algorithm$$anonfun$2.apply(Algorithm.scala:28)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:328)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:48)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:103)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:47)
	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:273)
	at scala.collection.AbstractIterator.to(Iterator.scala:1157)
	at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:265)
	at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1157)
	at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:252)
	at scala.collection.AbstractIterator.toArray(Iterator.scala:1157)
	at org.apache.spark.rdd.RDD$$anonfun$org$apache$spark$rdd$RDD$$collectPartition$1$1.apply(RDD.scala:808)
	at org.apache.spark.rdd.RDD$$anonfun$org$apache$spark$rdd$RDD$$collectPartition$1$1.apply(RDD.scala:808)
	at org.apache.spark.SparkContext$$anonfun$runJob$4.apply(SparkContext.scala:1353)
	at org.apache.spark.SparkContext$$anonfun$runJob$4.apply(SparkContext.scala:1353)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:61)
	at org.apache.spark.scheduler.Task.run(Task.scala:56)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:200)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-04-08 16:31:04,913 WARN  org.apache.spark.scheduler.TaskSetManager [task-result-getter-0] - Lost task 0.0 in stage 0.0 (TID 0, localhost): java.lang.IllegalArgumentException: tokens must not be empty
	at opennlp.tools.util.StringList.<init>(StringList.java:61)
	at SemanticAnalysis.NGramMachine.extract(NGramMachine.java:19)
	at SemanticAnalysis.Algorithm$$anonfun$2.apply(Algorithm.scala:29)
	at SemanticAnalysis.Algorithm$$anonfun$2.apply(Algorithm.scala:28)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:328)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:48)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:103)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:47)
	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:273)
	at scala.collection.AbstractIterator.to(Iterator.scala:1157)
	at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:265)
	at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1157)
	at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:252)
	at scala.collection.AbstractIterator.toArray(Iterator.scala:1157)
	at org.apache.spark.rdd.RDD$$anonfun$org$apache$spark$rdd$RDD$$collectPartition$1$1.apply(RDD.scala:808)
	at org.apache.spark.rdd.RDD$$anonfun$org$apache$spark$rdd$RDD$$collectPartition$1$1.apply(RDD.scala:808)
	at org.apache.spark.SparkContext$$anonfun$runJob$4.apply(SparkContext.scala:1353)
	at org.apache.spark.SparkContext$$anonfun$runJob$4.apply(SparkContext.scala:1353)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:61)
	at org.apache.spark.scheduler.Task.run(Task.scala:56)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:200)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

2015-04-08 16:31:04,914 ERROR org.apache.spark.scheduler.TaskSetManager [task-result-getter-0] - Task 0 in stage 0.0 failed 1 times; aborting job
2015-04-08 16:32:07,287 INFO  io.prediction.tools.console.Console$ [main] - Using existing engine manifest JSON at /Users/Marco/SemanticAnalysisRepo/SemanticAnalysis/manifest.json
2015-04-08 16:32:11,234 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-08 16:32:11,471 INFO  io.prediction.tools.RunWorkflow$ [main] - Submission command: /Users/Marco/PredictionIO/vendors/spark-1.2.1/bin/spark-submit --class io.prediction.workflow.CreateWorkflow --name PredictionIO Training: IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I 1601d4b44276e463819ccf16bcea2e968082ad77 () --jars file:/Users/Marco/.pio_store/engines/IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I/1601d4b44276e463819ccf16bcea2e968082ad77/semanticanalysis_2.10-1.0.jar,file:/Users/Marco/.pio_store/engines/IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I/1601d4b44276e463819ccf16bcea2e968082ad77/SemanticAnalysis-assembly-1.0-deps.jar --files /Users/Marco/PredictionIO/conf/log4j.properties,/Users/Marco/PredictionIO/vendors/hbase-0.98.11/conf/hbase-site.xml --driver-class-path /Users/Marco/PredictionIO/conf:/Users/Marco/PredictionIO/vendors/hbase-0.98.11/conf /Users/Marco/PredictionIO/lib/pio-assembly-0.9.1.jar --env PIO_STORAGE_SOURCES_HBASE_TYPE=hbase,PIO_ENV_LOADED=1,PIO_STORAGE_SOURCES_HBASE_HOSTS=0,PIO_STORAGE_REPOSITORIES_METADATA_NAME=predictionio_metadata,PIO_FS_BASEDIR=/Users/Marco/.pio_store,PIO_STORAGE_SOURCES_ELASTICSEARCH_HOSTS=localhost,PIO_STORAGE_SOURCES_HBASE_HOME=/Users/Marco/PredictionIO/vendors/hbase-0.98.11,PIO_HOME=/Users/Marco/PredictionIO,PIO_FS_ENGINESDIR=/Users/Marco/.pio_store/engines,PIO_STORAGE_SOURCES_HBASE_PORTS=0,PIO_STORAGE_SOURCES_ELASTICSEARCH_TYPE=elasticsearch,PIO_STORAGE_REPOSITORIES_METADATA_SOURCE=ELASTICSEARCH,PIO_STORAGE_REPOSITORIES_MODELDATA_SOURCE=LOCALFS,PIO_STORAGE_REPOSITORIES_EVENTDATA_NAME=predictionio_eventdata,PIO_STORAGE_SOURCES_ELASTICSEARCH_HOME=/Users/Marco/PredictionIO/vendors/elasticsearch-1.4.4,PIO_FS_TMPDIR=/Users/Marco/.pio_store/tmp,PIO_STORAGE_REPOSITORIES_MODELDATA_NAME=pio_,PIO_STORAGE_SOURCES_LOCALFS_HOSTS=/Users/Marco/.pio_store/models,PIO_STORAGE_REPOSITORIES_EVENTDATA_SOURCE=HBASE,PIO_CONF_DIR=/Users/Marco/PredictionIO/conf,PIO_STORAGE_SOURCES_LOCALFS_PORTS=0,PIO_STORAGE_SOURCES_ELASTICSEARCH_PORTS=9300,PIO_STORAGE_SOURCES_LOCALFS_TYPE=localfs --engine-id IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I --engine-version 1601d4b44276e463819ccf16bcea2e968082ad77 --engine-variant /Users/Marco/SemanticAnalysisRepo/SemanticAnalysis/engine.json --verbosity 0
2015-04-08 16:32:15,631 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-08 16:32:17,558 INFO  io.prediction.controller.Engine [main] - Extracting datasource params...
2015-04-08 16:32:17,681 INFO  io.prediction.workflow.WorkflowUtils$ [main] - No 'name' is found. Default empty String will be used.
2015-04-08 16:32:17,704 INFO  io.prediction.controller.Engine [main] - Datasource params: (,DataSourceParams(1))
2015-04-08 16:32:17,704 INFO  io.prediction.controller.Engine [main] - Extracting preparator params...
2015-04-08 16:32:17,706 INFO  io.prediction.controller.Engine [main] - Preparator params: (,Empty)
2015-04-08 16:32:17,713 INFO  io.prediction.controller.Engine [main] - Extracting serving params...
2015-04-08 16:32:17,714 INFO  io.prediction.controller.Engine [main] - Serving params: (,Empty)
2015-04-08 16:32:21,748 INFO  Remoting [sparkDriver-akka.actor.default-dispatcher-3] - Starting remoting
2015-04-08 16:32:21,997 INFO  Remoting [sparkDriver-akka.actor.default-dispatcher-3] - Remoting started; listening on addresses :[akka.tcp://sparkDriver@10.0.22.139:56360]
2015-04-08 16:32:23,866 INFO  io.prediction.controller.Engine$ [main] - EngineWorkflow.train
2015-04-08 16:32:23,868 INFO  io.prediction.controller.Engine$ [main] - DataSource: SemanticAnalysis.DataSource@78307a56
2015-04-08 16:32:23,868 INFO  io.prediction.controller.Engine$ [main] - Preparator: SemanticAnalysis.Preparator@1983b48a
2015-04-08 16:32:23,869 INFO  io.prediction.controller.Engine$ [main] - AlgorithmList: List(SemanticAnalysis.Algorithm@4391a2d8)
2015-04-08 16:32:23,869 INFO  io.prediction.controller.Engine$ [main] - Data santiy check is on.
2015-04-08 16:32:35,802 INFO  io.prediction.controller.Engine$ [main] - SemanticAnalysis.TrainingData does not support data sanity check. Skipping check.
2015-04-08 16:32:35,803 INFO  io.prediction.controller.Engine$ [main] - SemanticAnalysis.PreparedData does not support data sanity check. Skipping check.
2015-04-08 16:32:35,937 WARN  org.apache.hadoop.hbase.mapreduce.TableInputFormatBase [main] - Cannot resolve the host name for /10.0.22.139 because of javax.naming.NameNotFoundException: DNS name not found [response code 3]; remaining name '139.22.0.10.in-addr.arpa'
2015-04-08 16:32:43,558 ERROR org.apache.spark.executor.Executor [Executor task launch worker-0] - Exception in task 0.0 in stage 0.0 (TID 0)
java.lang.IllegalArgumentException: tokens must not be empty
	at opennlp.tools.util.StringList.<init>(StringList.java:61)
	at SemanticAnalysis.NGramMachine.extract(NGramMachine.java:19)
	at SemanticAnalysis.Algorithm$$anonfun$2.apply(Algorithm.scala:29)
	at SemanticAnalysis.Algorithm$$anonfun$2.apply(Algorithm.scala:28)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:328)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:48)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:103)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:47)
	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:273)
	at scala.collection.AbstractIterator.to(Iterator.scala:1157)
	at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:265)
	at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1157)
	at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:252)
	at scala.collection.AbstractIterator.toArray(Iterator.scala:1157)
	at org.apache.spark.rdd.RDD$$anonfun$org$apache$spark$rdd$RDD$$collectPartition$1$1.apply(RDD.scala:808)
	at org.apache.spark.rdd.RDD$$anonfun$org$apache$spark$rdd$RDD$$collectPartition$1$1.apply(RDD.scala:808)
	at org.apache.spark.SparkContext$$anonfun$runJob$4.apply(SparkContext.scala:1353)
	at org.apache.spark.SparkContext$$anonfun$runJob$4.apply(SparkContext.scala:1353)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:61)
	at org.apache.spark.scheduler.Task.run(Task.scala:56)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:200)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-04-08 16:32:43,567 WARN  org.apache.spark.scheduler.TaskSetManager [task-result-getter-0] - Lost task 0.0 in stage 0.0 (TID 0, localhost): java.lang.IllegalArgumentException: tokens must not be empty
	at opennlp.tools.util.StringList.<init>(StringList.java:61)
	at SemanticAnalysis.NGramMachine.extract(NGramMachine.java:19)
	at SemanticAnalysis.Algorithm$$anonfun$2.apply(Algorithm.scala:29)
	at SemanticAnalysis.Algorithm$$anonfun$2.apply(Algorithm.scala:28)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:328)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:48)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:103)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:47)
	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:273)
	at scala.collection.AbstractIterator.to(Iterator.scala:1157)
	at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:265)
	at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1157)
	at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:252)
	at scala.collection.AbstractIterator.toArray(Iterator.scala:1157)
	at org.apache.spark.rdd.RDD$$anonfun$org$apache$spark$rdd$RDD$$collectPartition$1$1.apply(RDD.scala:808)
	at org.apache.spark.rdd.RDD$$anonfun$org$apache$spark$rdd$RDD$$collectPartition$1$1.apply(RDD.scala:808)
	at org.apache.spark.SparkContext$$anonfun$runJob$4.apply(SparkContext.scala:1353)
	at org.apache.spark.SparkContext$$anonfun$runJob$4.apply(SparkContext.scala:1353)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:61)
	at org.apache.spark.scheduler.Task.run(Task.scala:56)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:200)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

2015-04-08 16:32:43,569 ERROR org.apache.spark.scheduler.TaskSetManager [task-result-getter-0] - Task 0 in stage 0.0 failed 1 times; aborting job
2015-04-08 16:35:32,509 INFO  io.prediction.tools.console.Console$ [main] - Creating Event Server at 0.0.0.0:7070
2015-04-08 16:35:33,723 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-08 16:35:34,478 ERROR io.prediction.data.storage.hbase.StorageClient [main] - HBase master is not running (ZooKeeper ensemble: localhost). Please make sure that HBase is running properly, and that the configuration is pointing at the correct ZooKeeper ensemble.
2015-04-08 16:35:34,479 ERROR io.prediction.data.storage.Storage$ [main] - Error initializing storage client for source HBASE
2015-04-08 16:35:34,479 ERROR io.prediction.data.storage.Storage$ [main] - com.google.protobuf.ServiceException: org.apache.hadoop.hbase.ipc.RemoteWithExtrasException(org.apache.hadoop.hbase.ipc.ServerNotRunningYetException): org.apache.hadoop.hbase.ipc.ServerNotRunningYetException: Server 10.0.22.139/10.0.22.139:56452 is not running yet
	at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:98)
	at org.apache.hadoop.hbase.ipc.FifoRpcScheduler$1.run(FifoRpcScheduler.java:74)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:439)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:695)

2015-04-08 16:36:03,701 INFO  io.prediction.tools.console.App$ [main] -                 Name |   ID |                                                       Access Key | Allowed Event(s)
2015-04-08 16:36:03,795 INFO  io.prediction.tools.console.App$ [main] - SemAnalysisApp-Marco |    1 | Hw8uK9u8j3C3Tuvu9Ce1YNIjhggQnXXUyPzxdqyqKPgaiT2Dz444hrNrcz4Bg8qM | (all)
2015-04-08 16:36:03,795 INFO  io.prediction.tools.console.App$ [main] - Finished listing 1 app(s).
2015-04-08 16:36:14,776 INFO  io.prediction.tools.console.Console$ [main] - Using existing engine manifest JSON at /Users/Marco/SemanticAnalysisRepo/SemanticAnalysis/manifest.json
2015-04-08 16:36:14,821 INFO  io.prediction.tools.console.Console$ [main] - Using command '/Users/Marco/PredictionIO/sbt/sbt' at the current working directory to build.
2015-04-08 16:36:14,821 INFO  io.prediction.tools.console.Console$ [main] - If the path above is incorrect, this process will fail.
2015-04-08 16:36:14,822 INFO  io.prediction.tools.console.Console$ [main] - Uber JAR disabled. Making sure lib/pio-assembly-0.9.1.jar is absent.
2015-04-08 16:36:14,823 INFO  io.prediction.tools.console.Console$ [main] - Going to run: /Users/Marco/PredictionIO/sbt/sbt  package assemblyPackageDependency
2015-04-08 16:36:29,861 INFO  io.prediction.tools.console.Console$ [main] - Build finished successfully.
2015-04-08 16:36:29,862 INFO  io.prediction.tools.console.Console$ [main] - Looking for an engine...
2015-04-08 16:36:29,871 INFO  io.prediction.tools.console.Console$ [main] - Found SemanticAnalysis-assembly-1.0-deps.jar
2015-04-08 16:36:29,871 INFO  io.prediction.tools.console.Console$ [main] - Found semanticanalysis_2.10-1.0.jar
2015-04-08 16:36:29,881 INFO  io.prediction.tools.console.Console$ [main] - HADOOP_CONF_DIR is not set. Assuming HDFS is unavailable.
2015-04-08 16:36:31,624 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-08 16:36:31,726 INFO  io.prediction.tools.RegisterEngine$ [main] - Copying file:/Users/Marco/SemanticAnalysisRepo/SemanticAnalysis/target/scala-2.10/SemanticAnalysis-assembly-1.0-deps.jar to file:/Users/Marco/.pio_store/engines/IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I/1601d4b44276e463819ccf16bcea2e968082ad77/SemanticAnalysis-assembly-1.0-deps.jar
2015-04-08 16:36:31,805 INFO  io.prediction.tools.RegisterEngine$ [main] - Copying file:/Users/Marco/SemanticAnalysisRepo/SemanticAnalysis/target/scala-2.10/semanticanalysis_2.10-1.0.jar to file:/Users/Marco/.pio_store/engines/IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I/1601d4b44276e463819ccf16bcea2e968082ad77/semanticanalysis_2.10-1.0.jar
2015-04-08 16:36:31,820 INFO  io.prediction.tools.RegisterEngine$ [main] - Registering engine IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I 1601d4b44276e463819ccf16bcea2e968082ad77
2015-04-08 16:36:31,852 INFO  io.prediction.tools.console.Console$ [main] - Your engine is ready for training.
2015-04-08 16:36:36,169 INFO  io.prediction.tools.console.Console$ [main] - Using existing engine manifest JSON at /Users/Marco/SemanticAnalysisRepo/SemanticAnalysis/manifest.json
2015-04-08 16:36:37,842 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-08 16:36:37,954 INFO  io.prediction.tools.RunWorkflow$ [main] - Submission command: /Users/Marco/PredictionIO/vendors/spark-1.2.1/bin/spark-submit --class io.prediction.workflow.CreateWorkflow --name PredictionIO Training: IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I 1601d4b44276e463819ccf16bcea2e968082ad77 () --jars file:/Users/Marco/.pio_store/engines/IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I/1601d4b44276e463819ccf16bcea2e968082ad77/semanticanalysis_2.10-1.0.jar,file:/Users/Marco/.pio_store/engines/IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I/1601d4b44276e463819ccf16bcea2e968082ad77/SemanticAnalysis-assembly-1.0-deps.jar --files /Users/Marco/PredictionIO/conf/log4j.properties,/Users/Marco/PredictionIO/vendors/hbase-0.98.11/conf/hbase-site.xml --driver-class-path /Users/Marco/PredictionIO/conf:/Users/Marco/PredictionIO/vendors/hbase-0.98.11/conf /Users/Marco/PredictionIO/lib/pio-assembly-0.9.1.jar --env PIO_STORAGE_SOURCES_HBASE_TYPE=hbase,PIO_ENV_LOADED=1,PIO_STORAGE_SOURCES_HBASE_HOSTS=0,PIO_STORAGE_REPOSITORIES_METADATA_NAME=predictionio_metadata,PIO_FS_BASEDIR=/Users/Marco/.pio_store,PIO_STORAGE_SOURCES_ELASTICSEARCH_HOSTS=localhost,PIO_STORAGE_SOURCES_HBASE_HOME=/Users/Marco/PredictionIO/vendors/hbase-0.98.11,PIO_HOME=/Users/Marco/PredictionIO,PIO_FS_ENGINESDIR=/Users/Marco/.pio_store/engines,PIO_STORAGE_SOURCES_HBASE_PORTS=0,PIO_STORAGE_SOURCES_ELASTICSEARCH_TYPE=elasticsearch,PIO_STORAGE_REPOSITORIES_METADATA_SOURCE=ELASTICSEARCH,PIO_STORAGE_REPOSITORIES_MODELDATA_SOURCE=LOCALFS,PIO_STORAGE_REPOSITORIES_EVENTDATA_NAME=predictionio_eventdata,PIO_STORAGE_SOURCES_ELASTICSEARCH_HOME=/Users/Marco/PredictionIO/vendors/elasticsearch-1.4.4,PIO_FS_TMPDIR=/Users/Marco/.pio_store/tmp,PIO_STORAGE_REPOSITORIES_MODELDATA_NAME=pio_,PIO_STORAGE_SOURCES_LOCALFS_HOSTS=/Users/Marco/.pio_store/models,PIO_STORAGE_REPOSITORIES_EVENTDATA_SOURCE=HBASE,PIO_CONF_DIR=/Users/Marco/PredictionIO/conf,PIO_STORAGE_SOURCES_LOCALFS_PORTS=0,PIO_STORAGE_SOURCES_ELASTICSEARCH_PORTS=9300,PIO_STORAGE_SOURCES_LOCALFS_TYPE=localfs --engine-id IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I --engine-version 1601d4b44276e463819ccf16bcea2e968082ad77 --engine-variant /Users/Marco/SemanticAnalysisRepo/SemanticAnalysis/engine.json --verbosity 0
2015-04-08 16:36:39,727 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-08 16:36:40,525 INFO  io.prediction.controller.Engine [main] - Extracting datasource params...
2015-04-08 16:36:40,601 INFO  io.prediction.workflow.WorkflowUtils$ [main] - No 'name' is found. Default empty String will be used.
2015-04-08 16:36:40,615 INFO  io.prediction.controller.Engine [main] - Datasource params: (,DataSourceParams(1))
2015-04-08 16:36:40,615 INFO  io.prediction.controller.Engine [main] - Extracting preparator params...
2015-04-08 16:36:40,616 INFO  io.prediction.controller.Engine [main] - Preparator params: (,Empty)
2015-04-08 16:36:40,621 INFO  io.prediction.controller.Engine [main] - Extracting serving params...
2015-04-08 16:36:40,621 INFO  io.prediction.controller.Engine [main] - Serving params: (,Empty)
2015-04-08 16:36:42,210 INFO  Remoting [sparkDriver-akka.actor.default-dispatcher-2] - Starting remoting
2015-04-08 16:36:42,388 INFO  Remoting [sparkDriver-akka.actor.default-dispatcher-2] - Remoting started; listening on addresses :[akka.tcp://sparkDriver@10.0.22.139:56528]
2015-04-08 16:36:43,392 INFO  io.prediction.controller.Engine$ [main] - EngineWorkflow.train
2015-04-08 16:36:43,394 INFO  io.prediction.controller.Engine$ [main] - DataSource: SemanticAnalysis.DataSource@78307a56
2015-04-08 16:36:43,395 INFO  io.prediction.controller.Engine$ [main] - Preparator: SemanticAnalysis.Preparator@1983b48a
2015-04-08 16:36:43,396 INFO  io.prediction.controller.Engine$ [main] - AlgorithmList: List(SemanticAnalysis.Algorithm@4391a2d8)
2015-04-08 16:36:43,396 INFO  io.prediction.controller.Engine$ [main] - Data santiy check is on.
2015-04-08 16:36:54,793 INFO  io.prediction.controller.Engine$ [main] - SemanticAnalysis.TrainingData does not support data sanity check. Skipping check.
2015-04-08 16:36:54,794 INFO  io.prediction.controller.Engine$ [main] - SemanticAnalysis.PreparedData does not support data sanity check. Skipping check.
2015-04-08 16:36:54,953 WARN  org.apache.hadoop.hbase.mapreduce.TableInputFormatBase [main] - Cannot resolve the host name for /10.0.22.139 because of javax.naming.NameNotFoundException: DNS name not found [response code 3]; remaining name '139.22.0.10.in-addr.arpa'
2015-04-08 16:38:02,917 ERROR org.apache.spark.executor.Executor [Executor task launch worker-0] - Exception in task 0.0 in stage 0.0 (TID 0)
java.lang.OutOfMemoryError: Java heap space
	at java.util.Arrays.copyOf(Arrays.java:3236)
	at java.io.ByteArrayOutputStream.grow(ByteArrayOutputStream.java:118)
	at java.io.ByteArrayOutputStream.ensureCapacity(ByteArrayOutputStream.java:93)
	at java.io.ByteArrayOutputStream.write(ByteArrayOutputStream.java:153)
	at java.io.ObjectOutputStream$BlockDataOutputStream.drain(ObjectOutputStream.java:1877)
	at java.io.ObjectOutputStream$BlockDataOutputStream.setBlockDataMode(ObjectOutputStream.java:1786)
	at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1189)
	at java.io.ObjectOutputStream.writeArray(ObjectOutputStream.java:1378)
	at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1174)
	at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:348)
	at org.apache.spark.serializer.JavaSerializationStream.writeObject(JavaSerializer.scala:42)
	at org.apache.spark.serializer.JavaSerializerInstance.serialize(JavaSerializer.scala:73)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:210)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-04-08 16:38:02,935 ERROR org.apache.spark.util.SparkUncaughtExceptionHandler [Executor task launch worker-0] - Uncaught exception in thread Thread[Executor task launch worker-0,5,main]
java.lang.OutOfMemoryError: Java heap space
	at java.util.Arrays.copyOf(Arrays.java:3236)
	at java.io.ByteArrayOutputStream.grow(ByteArrayOutputStream.java:118)
	at java.io.ByteArrayOutputStream.ensureCapacity(ByteArrayOutputStream.java:93)
	at java.io.ByteArrayOutputStream.write(ByteArrayOutputStream.java:153)
	at java.io.ObjectOutputStream$BlockDataOutputStream.drain(ObjectOutputStream.java:1877)
	at java.io.ObjectOutputStream$BlockDataOutputStream.setBlockDataMode(ObjectOutputStream.java:1786)
	at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1189)
	at java.io.ObjectOutputStream.writeArray(ObjectOutputStream.java:1378)
	at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1174)
	at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:348)
	at org.apache.spark.serializer.JavaSerializationStream.writeObject(JavaSerializer.scala:42)
	at org.apache.spark.serializer.JavaSerializerInstance.serialize(JavaSerializer.scala:73)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:210)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-04-08 16:38:02,945 WARN  org.apache.spark.scheduler.TaskSetManager [task-result-getter-0] - Lost task 0.0 in stage 0.0 (TID 0, localhost): java.lang.OutOfMemoryError: Java heap space
	at java.util.Arrays.copyOf(Arrays.java:3236)
	at java.io.ByteArrayOutputStream.grow(ByteArrayOutputStream.java:118)
	at java.io.ByteArrayOutputStream.ensureCapacity(ByteArrayOutputStream.java:93)
	at java.io.ByteArrayOutputStream.write(ByteArrayOutputStream.java:153)
	at java.io.ObjectOutputStream$BlockDataOutputStream.drain(ObjectOutputStream.java:1877)
	at java.io.ObjectOutputStream$BlockDataOutputStream.setBlockDataMode(ObjectOutputStream.java:1786)
	at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1189)
	at java.io.ObjectOutputStream.writeArray(ObjectOutputStream.java:1378)
	at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1174)
	at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:348)
	at org.apache.spark.serializer.JavaSerializationStream.writeObject(JavaSerializer.scala:42)
	at org.apache.spark.serializer.JavaSerializerInstance.serialize(JavaSerializer.scala:73)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:210)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

2015-04-08 16:38:02,960 ERROR org.apache.spark.scheduler.TaskSetManager [task-result-getter-0] - Task 0 in stage 0.0 failed 1 times; aborting job
2015-04-08 17:01:49,760 INFO  io.prediction.tools.console.Console$ [main] - Using existing engine manifest JSON at /Users/Marco/SemanticAnalysisRepo/SemanticAnalysis/manifest.json
2015-04-08 17:01:49,813 INFO  io.prediction.tools.console.Console$ [main] - Using command '/Users/Marco/PredictionIO/sbt/sbt' at the current working directory to build.
2015-04-08 17:01:49,814 INFO  io.prediction.tools.console.Console$ [main] - If the path above is incorrect, this process will fail.
2015-04-08 17:01:49,815 INFO  io.prediction.tools.console.Console$ [main] - Uber JAR disabled. Making sure lib/pio-assembly-0.9.1.jar is absent.
2015-04-08 17:01:49,815 INFO  io.prediction.tools.console.Console$ [main] - Going to run: /Users/Marco/PredictionIO/sbt/sbt  package assemblyPackageDependency
2015-04-08 17:02:04,318 INFO  io.prediction.tools.console.Console$ [main] - Build finished successfully.
2015-04-08 17:02:04,318 INFO  io.prediction.tools.console.Console$ [main] - Looking for an engine...
2015-04-08 17:02:04,328 INFO  io.prediction.tools.console.Console$ [main] - Found SemanticAnalysis-assembly-1.0-deps.jar
2015-04-08 17:02:04,328 INFO  io.prediction.tools.console.Console$ [main] - Found semanticanalysis_2.10-1.0.jar
2015-04-08 17:02:04,336 INFO  io.prediction.tools.console.Console$ [main] - HADOOP_CONF_DIR is not set. Assuming HDFS is unavailable.
2015-04-08 17:02:06,342 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-08 17:02:06,453 INFO  io.prediction.tools.RegisterEngine$ [main] - Copying file:/Users/Marco/SemanticAnalysisRepo/SemanticAnalysis/target/scala-2.10/SemanticAnalysis-assembly-1.0-deps.jar to file:/Users/Marco/.pio_store/engines/IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I/1601d4b44276e463819ccf16bcea2e968082ad77/SemanticAnalysis-assembly-1.0-deps.jar
2015-04-08 17:02:06,526 INFO  io.prediction.tools.RegisterEngine$ [main] - Copying file:/Users/Marco/SemanticAnalysisRepo/SemanticAnalysis/target/scala-2.10/semanticanalysis_2.10-1.0.jar to file:/Users/Marco/.pio_store/engines/IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I/1601d4b44276e463819ccf16bcea2e968082ad77/semanticanalysis_2.10-1.0.jar
2015-04-08 17:02:06,545 INFO  io.prediction.tools.RegisterEngine$ [main] - Registering engine IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I 1601d4b44276e463819ccf16bcea2e968082ad77
2015-04-08 17:02:06,576 INFO  io.prediction.tools.console.Console$ [main] - Your engine is ready for training.
2015-04-08 17:02:47,059 INFO  io.prediction.tools.console.Console$ [main] - Using existing engine manifest JSON at /Users/Marco/SemanticAnalysisRepo/SemanticAnalysis/manifest.json
2015-04-08 17:02:48,743 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-08 17:02:48,857 INFO  io.prediction.tools.RunWorkflow$ [main] - Submission command: /Users/Marco/PredictionIO/vendors/spark-1.2.1/bin/spark-submit --master spark://Marcos-MacBook-Pro.local:7077 --driver-memory 16G --executor-memory 24G --class io.prediction.workflow.CreateWorkflow --name PredictionIO Training: IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I 1601d4b44276e463819ccf16bcea2e968082ad77 () --jars file:/Users/Marco/.pio_store/engines/IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I/1601d4b44276e463819ccf16bcea2e968082ad77/semanticanalysis_2.10-1.0.jar,file:/Users/Marco/.pio_store/engines/IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I/1601d4b44276e463819ccf16bcea2e968082ad77/SemanticAnalysis-assembly-1.0-deps.jar --files /Users/Marco/PredictionIO/conf/log4j.properties,/Users/Marco/PredictionIO/vendors/hbase-0.98.11/conf/hbase-site.xml --driver-class-path /Users/Marco/PredictionIO/conf:/Users/Marco/PredictionIO/vendors/hbase-0.98.11/conf /Users/Marco/PredictionIO/lib/pio-assembly-0.9.1.jar --env PIO_STORAGE_SOURCES_HBASE_TYPE=hbase,PIO_ENV_LOADED=1,PIO_STORAGE_SOURCES_HBASE_HOSTS=0,PIO_STORAGE_REPOSITORIES_METADATA_NAME=predictionio_metadata,PIO_FS_BASEDIR=/Users/Marco/.pio_store,PIO_STORAGE_SOURCES_ELASTICSEARCH_HOSTS=localhost,PIO_STORAGE_SOURCES_HBASE_HOME=/Users/Marco/PredictionIO/vendors/hbase-0.98.11,PIO_HOME=/Users/Marco/PredictionIO,PIO_FS_ENGINESDIR=/Users/Marco/.pio_store/engines,PIO_STORAGE_SOURCES_HBASE_PORTS=0,PIO_STORAGE_SOURCES_ELASTICSEARCH_TYPE=elasticsearch,PIO_STORAGE_REPOSITORIES_METADATA_SOURCE=ELASTICSEARCH,PIO_STORAGE_REPOSITORIES_MODELDATA_SOURCE=LOCALFS,PIO_STORAGE_REPOSITORIES_EVENTDATA_NAME=predictionio_eventdata,PIO_STORAGE_SOURCES_ELASTICSEARCH_HOME=/Users/Marco/PredictionIO/vendors/elasticsearch-1.4.4,PIO_FS_TMPDIR=/Users/Marco/.pio_store/tmp,PIO_STORAGE_REPOSITORIES_MODELDATA_NAME=pio_,PIO_STORAGE_SOURCES_LOCALFS_HOSTS=/Users/Marco/.pio_store/models,PIO_STORAGE_REPOSITORIES_EVENTDATA_SOURCE=HBASE,PIO_CONF_DIR=/Users/Marco/PredictionIO/conf,PIO_STORAGE_SOURCES_LOCALFS_PORTS=0,PIO_STORAGE_SOURCES_ELASTICSEARCH_PORTS=9300,PIO_STORAGE_SOURCES_LOCALFS_TYPE=localfs --engine-id IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I --engine-version 1601d4b44276e463819ccf16bcea2e968082ad77 --engine-variant /Users/Marco/SemanticAnalysisRepo/SemanticAnalysis/engine.json --verbosity 0
2015-04-08 17:02:50,989 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-08 17:02:51,971 INFO  io.prediction.controller.Engine [main] - Extracting datasource params...
2015-04-08 17:02:52,081 INFO  io.prediction.workflow.WorkflowUtils$ [main] - No 'name' is found. Default empty String will be used.
2015-04-08 17:02:52,096 INFO  io.prediction.controller.Engine [main] - Datasource params: (,DataSourceParams(1))
2015-04-08 17:02:52,097 INFO  io.prediction.controller.Engine [main] - Extracting preparator params...
2015-04-08 17:02:52,098 INFO  io.prediction.controller.Engine [main] - Preparator params: (,Empty)
2015-04-08 17:02:52,104 INFO  io.prediction.controller.Engine [main] - Extracting serving params...
2015-04-08 17:02:52,105 INFO  io.prediction.controller.Engine [main] - Serving params: (,Empty)
2015-04-08 17:02:53,867 INFO  Remoting [sparkDriver-akka.actor.default-dispatcher-5] - Starting remoting
2015-04-08 17:02:54,101 INFO  Remoting [sparkDriver-akka.actor.default-dispatcher-5] - Remoting started; listening on addresses :[akka.tcp://sparkDriver@10.0.22.139:56774]
2015-04-08 17:02:55,471 WARN  akka.remote.ReliableDeliverySupervisor [sparkDriver-akka.actor.default-dispatcher-3] - Association with remote system [akka.tcp://sparkMaster@Marcos-MacBook-Pro.local:7077] has failed, address is now gated for [5000] ms. Reason is: [Disassociated].
2015-04-08 17:03:15,258 WARN  akka.remote.ReliableDeliverySupervisor [sparkDriver-akka.actor.default-dispatcher-3] - Association with remote system [akka.tcp://sparkMaster@Marcos-MacBook-Pro.local:7077] has failed, address is now gated for [5000] ms. Reason is: [Disassociated].
2015-04-08 17:03:35,246 WARN  akka.remote.ReliableDeliverySupervisor [sparkDriver-akka.actor.default-dispatcher-3] - Association with remote system [akka.tcp://sparkMaster@Marcos-MacBook-Pro.local:7077] has failed, address is now gated for [5000] ms. Reason is: [Disassociated].
2015-04-08 17:03:55,241 ERROR org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend [sparkDriver-akka.actor.default-dispatcher-3] - Application has been killed. Reason: All masters are unresponsive! Giving up.
2015-04-08 17:03:55,241 WARN  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend [main] - Application ID is not initialized yet.
2015-04-08 17:03:55,242 ERROR org.apache.spark.scheduler.TaskSchedulerImpl [sparkDriver-akka.actor.default-dispatcher-3] - Exiting due to error from cluster scheduler: All masters are unresponsive! Giving up.
2015-04-08 17:07:41,236 INFO  io.prediction.tools.console.Console$ [main] - Using existing engine manifest JSON at /Users/Marco/SemanticAnalysisRepo/SemanticAnalysis/manifest.json
2015-04-08 17:07:42,819 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-08 17:07:42,935 INFO  io.prediction.tools.RunWorkflow$ [main] - Submission command: /Users/Marco/PredictionIO/vendors/spark-1.2.1/bin/spark-submit --master spark://Marcos-MacBook-Pro.local:6066 --driver-memory 16G --executor-memory 24G --class io.prediction.workflow.CreateWorkflow --name PredictionIO Training: IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I 1601d4b44276e463819ccf16bcea2e968082ad77 () --jars file:/Users/Marco/.pio_store/engines/IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I/1601d4b44276e463819ccf16bcea2e968082ad77/semanticanalysis_2.10-1.0.jar,file:/Users/Marco/.pio_store/engines/IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I/1601d4b44276e463819ccf16bcea2e968082ad77/SemanticAnalysis-assembly-1.0-deps.jar --files /Users/Marco/PredictionIO/conf/log4j.properties,/Users/Marco/PredictionIO/vendors/hbase-0.98.11/conf/hbase-site.xml --driver-class-path /Users/Marco/PredictionIO/conf:/Users/Marco/PredictionIO/vendors/hbase-0.98.11/conf /Users/Marco/PredictionIO/lib/pio-assembly-0.9.1.jar --env PIO_STORAGE_SOURCES_HBASE_TYPE=hbase,PIO_ENV_LOADED=1,PIO_STORAGE_SOURCES_HBASE_HOSTS=0,PIO_STORAGE_REPOSITORIES_METADATA_NAME=predictionio_metadata,PIO_FS_BASEDIR=/Users/Marco/.pio_store,PIO_STORAGE_SOURCES_ELASTICSEARCH_HOSTS=localhost,PIO_STORAGE_SOURCES_HBASE_HOME=/Users/Marco/PredictionIO/vendors/hbase-0.98.11,PIO_HOME=/Users/Marco/PredictionIO,PIO_FS_ENGINESDIR=/Users/Marco/.pio_store/engines,PIO_STORAGE_SOURCES_HBASE_PORTS=0,PIO_STORAGE_SOURCES_ELASTICSEARCH_TYPE=elasticsearch,PIO_STORAGE_REPOSITORIES_METADATA_SOURCE=ELASTICSEARCH,PIO_STORAGE_REPOSITORIES_MODELDATA_SOURCE=LOCALFS,PIO_STORAGE_REPOSITORIES_EVENTDATA_NAME=predictionio_eventdata,PIO_STORAGE_SOURCES_ELASTICSEARCH_HOME=/Users/Marco/PredictionIO/vendors/elasticsearch-1.4.4,PIO_FS_TMPDIR=/Users/Marco/.pio_store/tmp,PIO_STORAGE_REPOSITORIES_MODELDATA_NAME=pio_,PIO_STORAGE_SOURCES_LOCALFS_HOSTS=/Users/Marco/.pio_store/models,PIO_STORAGE_REPOSITORIES_EVENTDATA_SOURCE=HBASE,PIO_CONF_DIR=/Users/Marco/PredictionIO/conf,PIO_STORAGE_SOURCES_LOCALFS_PORTS=0,PIO_STORAGE_SOURCES_ELASTICSEARCH_PORTS=9300,PIO_STORAGE_SOURCES_LOCALFS_TYPE=localfs --engine-id IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I --engine-version 1601d4b44276e463819ccf16bcea2e968082ad77 --engine-variant /Users/Marco/SemanticAnalysisRepo/SemanticAnalysis/engine.json --verbosity 0
2015-04-08 17:07:44,861 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-08 17:07:45,724 INFO  io.prediction.controller.Engine [main] - Extracting datasource params...
2015-04-08 17:07:45,798 INFO  io.prediction.workflow.WorkflowUtils$ [main] - No 'name' is found. Default empty String will be used.
2015-04-08 17:07:45,814 INFO  io.prediction.controller.Engine [main] - Datasource params: (,DataSourceParams(1))
2015-04-08 17:07:45,814 INFO  io.prediction.controller.Engine [main] - Extracting preparator params...
2015-04-08 17:07:45,815 INFO  io.prediction.controller.Engine [main] - Preparator params: (,Empty)
2015-04-08 17:07:45,820 INFO  io.prediction.controller.Engine [main] - Extracting serving params...
2015-04-08 17:07:45,820 INFO  io.prediction.controller.Engine [main] - Serving params: (,Empty)
2015-04-08 17:07:47,509 INFO  Remoting [sparkDriver-akka.actor.default-dispatcher-2] - Starting remoting
2015-04-08 17:07:47,700 INFO  Remoting [sparkDriver-akka.actor.default-dispatcher-2] - Remoting started; listening on addresses :[akka.tcp://sparkDriver@10.0.22.139:56856]
2015-04-08 17:07:48,463 WARN  org.apache.spark.deploy.client.AppClient$ClientActor [sparkDriver-akka.actor.default-dispatcher-4] - Could not connect to akka.tcp://sparkMaster@Marcos-MacBook-Pro.local:6066: akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkMaster@Marcos-MacBook-Pro.local:6066]
2015-04-08 17:07:48,467 WARN  akka.remote.ReliableDeliverySupervisor [sparkDriver-akka.actor.default-dispatcher-4] - Association with remote system [akka.tcp://sparkMaster@Marcos-MacBook-Pro.local:6066] has failed, address is now gated for [5000] ms. Reason is: [Association failed with [akka.tcp://sparkMaster@Marcos-MacBook-Pro.local:6066]].
2015-04-08 17:08:08,391 WARN  akka.remote.ReliableDeliverySupervisor [sparkDriver-akka.actor.default-dispatcher-3] - Association with remote system [akka.tcp://sparkMaster@Marcos-MacBook-Pro.local:6066] has failed, address is now gated for [5000] ms. Reason is: [Association failed with [akka.tcp://sparkMaster@Marcos-MacBook-Pro.local:6066]].
2015-04-08 17:08:08,391 WARN  org.apache.spark.deploy.client.AppClient$ClientActor [sparkDriver-akka.actor.default-dispatcher-2] - Could not connect to akka.tcp://sparkMaster@Marcos-MacBook-Pro.local:6066: akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkMaster@Marcos-MacBook-Pro.local:6066]
2015-04-08 17:08:28,393 WARN  akka.remote.ReliableDeliverySupervisor [sparkDriver-akka.actor.default-dispatcher-2] - Association with remote system [akka.tcp://sparkMaster@Marcos-MacBook-Pro.local:6066] has failed, address is now gated for [5000] ms. Reason is: [Association failed with [akka.tcp://sparkMaster@Marcos-MacBook-Pro.local:6066]].
2015-04-08 17:08:28,393 WARN  org.apache.spark.deploy.client.AppClient$ClientActor [sparkDriver-akka.actor.default-dispatcher-3] - Could not connect to akka.tcp://sparkMaster@Marcos-MacBook-Pro.local:6066: akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkMaster@Marcos-MacBook-Pro.local:6066]
2015-04-08 17:08:48,375 ERROR org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend [sparkDriver-akka.actor.default-dispatcher-3] - Application has been killed. Reason: All masters are unresponsive! Giving up.
2015-04-08 17:08:48,375 WARN  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend [main] - Application ID is not initialized yet.
2015-04-08 17:08:48,377 ERROR org.apache.spark.scheduler.TaskSchedulerImpl [sparkDriver-akka.actor.default-dispatcher-3] - Exiting due to error from cluster scheduler: All masters are unresponsive! Giving up.
2015-04-08 17:09:13,079 INFO  io.prediction.tools.console.Console$ [main] - Using existing engine manifest JSON at /Users/Marco/SemanticAnalysisRepo/SemanticAnalysis/manifest.json
2015-04-08 17:09:13,125 INFO  io.prediction.tools.console.Console$ [main] - Using command '/Users/Marco/PredictionIO/sbt/sbt' at the current working directory to build.
2015-04-08 17:09:13,126 INFO  io.prediction.tools.console.Console$ [main] - If the path above is incorrect, this process will fail.
2015-04-08 17:09:13,127 INFO  io.prediction.tools.console.Console$ [main] - Uber JAR disabled. Making sure lib/pio-assembly-0.9.1.jar is absent.
2015-04-08 17:09:13,127 INFO  io.prediction.tools.console.Console$ [main] - Going to run: /Users/Marco/PredictionIO/sbt/sbt  package assemblyPackageDependency
2015-04-08 17:09:19,718 INFO  io.prediction.tools.console.Console$ [main] - Build finished successfully.
2015-04-08 17:09:19,719 INFO  io.prediction.tools.console.Console$ [main] - Looking for an engine...
2015-04-08 17:09:19,726 INFO  io.prediction.tools.console.Console$ [main] - Found SemanticAnalysis-assembly-1.0-deps.jar
2015-04-08 17:09:19,726 INFO  io.prediction.tools.console.Console$ [main] - Found semanticanalysis_2.10-1.0.jar
2015-04-08 17:09:19,732 INFO  io.prediction.tools.console.Console$ [main] - HADOOP_CONF_DIR is not set. Assuming HDFS is unavailable.
2015-04-08 17:09:21,262 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-08 17:09:21,354 INFO  io.prediction.tools.RegisterEngine$ [main] - Copying file:/Users/Marco/SemanticAnalysisRepo/SemanticAnalysis/target/scala-2.10/SemanticAnalysis-assembly-1.0-deps.jar to file:/Users/Marco/.pio_store/engines/IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I/1601d4b44276e463819ccf16bcea2e968082ad77/SemanticAnalysis-assembly-1.0-deps.jar
2015-04-08 17:09:21,430 INFO  io.prediction.tools.RegisterEngine$ [main] - Copying file:/Users/Marco/SemanticAnalysisRepo/SemanticAnalysis/target/scala-2.10/semanticanalysis_2.10-1.0.jar to file:/Users/Marco/.pio_store/engines/IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I/1601d4b44276e463819ccf16bcea2e968082ad77/semanticanalysis_2.10-1.0.jar
2015-04-08 17:09:21,443 INFO  io.prediction.tools.RegisterEngine$ [main] - Registering engine IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I 1601d4b44276e463819ccf16bcea2e968082ad77
2015-04-08 17:09:21,470 INFO  io.prediction.tools.console.Console$ [main] - Your engine is ready for training.
2015-04-08 17:10:03,621 INFO  io.prediction.tools.console.Console$ [main] - Using existing engine manifest JSON at /Users/Marco/SemanticAnalysisRepo/SemanticAnalysis/manifest.json
2015-04-08 17:10:05,230 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-08 17:10:05,330 INFO  io.prediction.tools.RunWorkflow$ [main] - Submission command: /Users/Marco/PredictionIO/vendors/spark-1.2.1/bin/spark-submit --master spark://Marcos-MacBook-Pro.local:7077 --driver-memory 16G --executor-memory 24G --class io.prediction.workflow.CreateWorkflow --name PredictionIO Training: IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I 1601d4b44276e463819ccf16bcea2e968082ad77 () --jars file:/Users/Marco/.pio_store/engines/IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I/1601d4b44276e463819ccf16bcea2e968082ad77/semanticanalysis_2.10-1.0.jar,file:/Users/Marco/.pio_store/engines/IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I/1601d4b44276e463819ccf16bcea2e968082ad77/SemanticAnalysis-assembly-1.0-deps.jar --files /Users/Marco/PredictionIO/conf/log4j.properties,/Users/Marco/PredictionIO/vendors/hbase-0.98.11/conf/hbase-site.xml --driver-class-path /Users/Marco/PredictionIO/conf:/Users/Marco/PredictionIO/vendors/hbase-0.98.11/conf /Users/Marco/PredictionIO/lib/pio-assembly-0.9.1.jar --env PIO_STORAGE_SOURCES_HBASE_TYPE=hbase,PIO_ENV_LOADED=1,PIO_STORAGE_SOURCES_HBASE_HOSTS=0,PIO_STORAGE_REPOSITORIES_METADATA_NAME=predictionio_metadata,PIO_FS_BASEDIR=/Users/Marco/.pio_store,PIO_STORAGE_SOURCES_ELASTICSEARCH_HOSTS=localhost,PIO_STORAGE_SOURCES_HBASE_HOME=/Users/Marco/PredictionIO/vendors/hbase-0.98.11,PIO_HOME=/Users/Marco/PredictionIO,PIO_FS_ENGINESDIR=/Users/Marco/.pio_store/engines,PIO_STORAGE_SOURCES_HBASE_PORTS=0,PIO_STORAGE_SOURCES_ELASTICSEARCH_TYPE=elasticsearch,PIO_STORAGE_REPOSITORIES_METADATA_SOURCE=ELASTICSEARCH,PIO_STORAGE_REPOSITORIES_MODELDATA_SOURCE=LOCALFS,PIO_STORAGE_REPOSITORIES_EVENTDATA_NAME=predictionio_eventdata,PIO_STORAGE_SOURCES_ELASTICSEARCH_HOME=/Users/Marco/PredictionIO/vendors/elasticsearch-1.4.4,PIO_FS_TMPDIR=/Users/Marco/.pio_store/tmp,PIO_STORAGE_REPOSITORIES_MODELDATA_NAME=pio_,PIO_STORAGE_SOURCES_LOCALFS_HOSTS=/Users/Marco/.pio_store/models,PIO_STORAGE_REPOSITORIES_EVENTDATA_SOURCE=HBASE,PIO_CONF_DIR=/Users/Marco/PredictionIO/conf,PIO_STORAGE_SOURCES_LOCALFS_PORTS=0,PIO_STORAGE_SOURCES_ELASTICSEARCH_PORTS=9300,PIO_STORAGE_SOURCES_LOCALFS_TYPE=localfs --engine-id IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I --engine-version 1601d4b44276e463819ccf16bcea2e968082ad77 --engine-variant /Users/Marco/SemanticAnalysisRepo/SemanticAnalysis/engine.json --verbosity 0
2015-04-08 17:10:07,208 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-08 17:10:08,005 INFO  io.prediction.controller.Engine [main] - Extracting datasource params...
2015-04-08 17:10:08,081 INFO  io.prediction.workflow.WorkflowUtils$ [main] - No 'name' is found. Default empty String will be used.
2015-04-08 17:10:08,101 INFO  io.prediction.controller.Engine [main] - Datasource params: (,DataSourceParams(1))
2015-04-08 17:10:08,101 INFO  io.prediction.controller.Engine [main] - Extracting preparator params...
2015-04-08 17:10:08,102 INFO  io.prediction.controller.Engine [main] - Preparator params: (,Empty)
2015-04-08 17:10:08,107 INFO  io.prediction.controller.Engine [main] - Extracting serving params...
2015-04-08 17:10:08,107 INFO  io.prediction.controller.Engine [main] - Serving params: (,Empty)
2015-04-08 17:10:09,676 INFO  Remoting [sparkDriver-akka.actor.default-dispatcher-2] - Starting remoting
2015-04-08 17:10:09,855 INFO  Remoting [sparkDriver-akka.actor.default-dispatcher-2] - Remoting started; listening on addresses :[akka.tcp://sparkDriver@10.0.22.139:56905]
2015-04-08 17:10:10,731 WARN  akka.remote.ReliableDeliverySupervisor [sparkDriver-akka.actor.default-dispatcher-2] - Association with remote system [akka.tcp://sparkMaster@Marcos-MacBook-Pro.local:7077] has failed, address is now gated for [5000] ms. Reason is: [Disassociated].
2015-04-08 17:10:30,570 WARN  akka.remote.ReliableDeliverySupervisor [sparkDriver-akka.actor.default-dispatcher-3] - Association with remote system [akka.tcp://sparkMaster@Marcos-MacBook-Pro.local:7077] has failed, address is now gated for [5000] ms. Reason is: [Disassociated].
2015-04-08 17:10:50,585 WARN  akka.remote.ReliableDeliverySupervisor [sparkDriver-akka.actor.default-dispatcher-3] - Association with remote system [akka.tcp://sparkMaster@Marcos-MacBook-Pro.local:7077] has failed, address is now gated for [5000] ms. Reason is: [Disassociated].
2015-04-08 17:11:10,553 ERROR org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend [sparkDriver-akka.actor.default-dispatcher-4] - Application has been killed. Reason: All masters are unresponsive! Giving up.
2015-04-08 17:11:10,553 WARN  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend [main] - Application ID is not initialized yet.
2015-04-08 17:11:10,554 ERROR org.apache.spark.scheduler.TaskSchedulerImpl [sparkDriver-akka.actor.default-dispatcher-4] - Exiting due to error from cluster scheduler: All masters are unresponsive! Giving up.
2015-04-08 17:20:35,215 INFO  io.prediction.tools.console.Console$ [main] - Using existing engine manifest JSON at /Users/Marco/SemanticAnalysisRepo/SemanticAnalysis/manifest.json
2015-04-08 17:20:36,831 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-08 17:20:36,943 INFO  io.prediction.tools.RunWorkflow$ [main] - Submission command: /Users/Marco/PredictionIO/vendors/spark-1.2.1/bin/spark-submit --master spark://Marcos-MacBook-Pro.local:7077 --driver-memory 2G --executor-memory 7GB --class io.prediction.workflow.CreateWorkflow --name PredictionIO Training: IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I 1601d4b44276e463819ccf16bcea2e968082ad77 () --jars file:/Users/Marco/.pio_store/engines/IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I/1601d4b44276e463819ccf16bcea2e968082ad77/semanticanalysis_2.10-1.0.jar,file:/Users/Marco/.pio_store/engines/IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I/1601d4b44276e463819ccf16bcea2e968082ad77/SemanticAnalysis-assembly-1.0-deps.jar --files /Users/Marco/PredictionIO/conf/log4j.properties,/Users/Marco/PredictionIO/vendors/hbase-0.98.11/conf/hbase-site.xml --driver-class-path /Users/Marco/PredictionIO/conf:/Users/Marco/PredictionIO/vendors/hbase-0.98.11/conf /Users/Marco/PredictionIO/lib/pio-assembly-0.9.1.jar --env PIO_STORAGE_SOURCES_HBASE_TYPE=hbase,PIO_ENV_LOADED=1,PIO_STORAGE_SOURCES_HBASE_HOSTS=0,PIO_STORAGE_REPOSITORIES_METADATA_NAME=predictionio_metadata,PIO_FS_BASEDIR=/Users/Marco/.pio_store,PIO_STORAGE_SOURCES_ELASTICSEARCH_HOSTS=localhost,PIO_STORAGE_SOURCES_HBASE_HOME=/Users/Marco/PredictionIO/vendors/hbase-0.98.11,PIO_HOME=/Users/Marco/PredictionIO,PIO_FS_ENGINESDIR=/Users/Marco/.pio_store/engines,PIO_STORAGE_SOURCES_HBASE_PORTS=0,PIO_STORAGE_SOURCES_ELASTICSEARCH_TYPE=elasticsearch,PIO_STORAGE_REPOSITORIES_METADATA_SOURCE=ELASTICSEARCH,PIO_STORAGE_REPOSITORIES_MODELDATA_SOURCE=LOCALFS,PIO_STORAGE_REPOSITORIES_EVENTDATA_NAME=predictionio_eventdata,PIO_STORAGE_SOURCES_ELASTICSEARCH_HOME=/Users/Marco/PredictionIO/vendors/elasticsearch-1.4.4,PIO_FS_TMPDIR=/Users/Marco/.pio_store/tmp,PIO_STORAGE_REPOSITORIES_MODELDATA_NAME=pio_,PIO_STORAGE_SOURCES_LOCALFS_HOSTS=/Users/Marco/.pio_store/models,PIO_STORAGE_REPOSITORIES_EVENTDATA_SOURCE=HBASE,PIO_CONF_DIR=/Users/Marco/PredictionIO/conf,PIO_STORAGE_SOURCES_LOCALFS_PORTS=0,PIO_STORAGE_SOURCES_ELASTICSEARCH_PORTS=9300,PIO_STORAGE_SOURCES_LOCALFS_TYPE=localfs --engine-id IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I --engine-version 1601d4b44276e463819ccf16bcea2e968082ad77 --engine-variant /Users/Marco/SemanticAnalysisRepo/SemanticAnalysis/engine.json --verbosity 0
2015-04-08 17:20:38,647 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-08 17:20:39,437 INFO  io.prediction.controller.Engine [main] - Extracting datasource params...
2015-04-08 17:20:39,524 INFO  io.prediction.workflow.WorkflowUtils$ [main] - No 'name' is found. Default empty String will be used.
2015-04-08 17:20:39,535 INFO  io.prediction.controller.Engine [main] - Datasource params: (,DataSourceParams(1))
2015-04-08 17:20:39,536 INFO  io.prediction.controller.Engine [main] - Extracting preparator params...
2015-04-08 17:20:39,537 INFO  io.prediction.controller.Engine [main] - Preparator params: (,Empty)
2015-04-08 17:20:39,542 INFO  io.prediction.controller.Engine [main] - Extracting serving params...
2015-04-08 17:20:39,542 INFO  io.prediction.controller.Engine [main] - Serving params: (,Empty)
2015-04-08 17:20:41,157 INFO  Remoting [sparkDriver-akka.actor.default-dispatcher-2] - Starting remoting
2015-04-08 17:20:41,338 INFO  Remoting [sparkDriver-akka.actor.default-dispatcher-2] - Remoting started; listening on addresses :[akka.tcp://sparkDriver@10.0.22.139:57063]
2015-04-08 17:20:47,055 INFO  io.prediction.tools.console.Console$ [main] - Using existing engine manifest JSON at /Users/Marco/SemanticAnalysisRepo/SemanticAnalysis/manifest.json
2015-04-08 17:20:48,634 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-08 17:20:48,744 INFO  io.prediction.tools.RunWorkflow$ [main] - Submission command: /Users/Marco/PredictionIO/vendors/spark-1.2.1/bin/spark-submit --master spark://Marcos-MacBook-Pro.local:7077 --driver-memory 2G --executor-memory 7G --class io.prediction.workflow.CreateWorkflow --name PredictionIO Training: IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I 1601d4b44276e463819ccf16bcea2e968082ad77 () --jars file:/Users/Marco/.pio_store/engines/IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I/1601d4b44276e463819ccf16bcea2e968082ad77/semanticanalysis_2.10-1.0.jar,file:/Users/Marco/.pio_store/engines/IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I/1601d4b44276e463819ccf16bcea2e968082ad77/SemanticAnalysis-assembly-1.0-deps.jar --files /Users/Marco/PredictionIO/conf/log4j.properties,/Users/Marco/PredictionIO/vendors/hbase-0.98.11/conf/hbase-site.xml --driver-class-path /Users/Marco/PredictionIO/conf:/Users/Marco/PredictionIO/vendors/hbase-0.98.11/conf /Users/Marco/PredictionIO/lib/pio-assembly-0.9.1.jar --env PIO_STORAGE_SOURCES_HBASE_TYPE=hbase,PIO_ENV_LOADED=1,PIO_STORAGE_SOURCES_HBASE_HOSTS=0,PIO_STORAGE_REPOSITORIES_METADATA_NAME=predictionio_metadata,PIO_FS_BASEDIR=/Users/Marco/.pio_store,PIO_STORAGE_SOURCES_ELASTICSEARCH_HOSTS=localhost,PIO_STORAGE_SOURCES_HBASE_HOME=/Users/Marco/PredictionIO/vendors/hbase-0.98.11,PIO_HOME=/Users/Marco/PredictionIO,PIO_FS_ENGINESDIR=/Users/Marco/.pio_store/engines,PIO_STORAGE_SOURCES_HBASE_PORTS=0,PIO_STORAGE_SOURCES_ELASTICSEARCH_TYPE=elasticsearch,PIO_STORAGE_REPOSITORIES_METADATA_SOURCE=ELASTICSEARCH,PIO_STORAGE_REPOSITORIES_MODELDATA_SOURCE=LOCALFS,PIO_STORAGE_REPOSITORIES_EVENTDATA_NAME=predictionio_eventdata,PIO_STORAGE_SOURCES_ELASTICSEARCH_HOME=/Users/Marco/PredictionIO/vendors/elasticsearch-1.4.4,PIO_FS_TMPDIR=/Users/Marco/.pio_store/tmp,PIO_STORAGE_REPOSITORIES_MODELDATA_NAME=pio_,PIO_STORAGE_SOURCES_LOCALFS_HOSTS=/Users/Marco/.pio_store/models,PIO_STORAGE_REPOSITORIES_EVENTDATA_SOURCE=HBASE,PIO_CONF_DIR=/Users/Marco/PredictionIO/conf,PIO_STORAGE_SOURCES_LOCALFS_PORTS=0,PIO_STORAGE_SOURCES_ELASTICSEARCH_PORTS=9300,PIO_STORAGE_SOURCES_LOCALFS_TYPE=localfs --engine-id IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I --engine-version 1601d4b44276e463819ccf16bcea2e968082ad77 --engine-variant /Users/Marco/SemanticAnalysisRepo/SemanticAnalysis/engine.json --verbosity 0
2015-04-08 17:20:50,490 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-08 17:20:51,295 INFO  io.prediction.controller.Engine [main] - Extracting datasource params...
2015-04-08 17:20:51,412 INFO  io.prediction.workflow.WorkflowUtils$ [main] - No 'name' is found. Default empty String will be used.
2015-04-08 17:20:51,426 INFO  io.prediction.controller.Engine [main] - Datasource params: (,DataSourceParams(1))
2015-04-08 17:20:51,426 INFO  io.prediction.controller.Engine [main] - Extracting preparator params...
2015-04-08 17:20:51,428 INFO  io.prediction.controller.Engine [main] - Preparator params: (,Empty)
2015-04-08 17:20:51,433 INFO  io.prediction.controller.Engine [main] - Extracting serving params...
2015-04-08 17:20:51,434 INFO  io.prediction.controller.Engine [main] - Serving params: (,Empty)
2015-04-08 17:20:53,071 INFO  Remoting [sparkDriver-akka.actor.default-dispatcher-3] - Starting remoting
2015-04-08 17:20:53,243 INFO  Remoting [sparkDriver-akka.actor.default-dispatcher-3] - Remoting started; listening on addresses :[akka.tcp://sparkDriver@10.0.22.139:57095]
2015-04-08 17:20:54,108 WARN  akka.remote.ReliableDeliverySupervisor [sparkDriver-akka.actor.default-dispatcher-2] - Association with remote system [akka.tcp://sparkMaster@Marcos-MacBook-Pro.local:7077] has failed, address is now gated for [5000] ms. Reason is: [Disassociated].
2015-04-08 17:21:13,958 WARN  akka.remote.ReliableDeliverySupervisor [sparkDriver-akka.actor.default-dispatcher-2] - Association with remote system [akka.tcp://sparkMaster@Marcos-MacBook-Pro.local:7077] has failed, address is now gated for [5000] ms. Reason is: [Disassociated].
2015-04-08 17:21:33,958 WARN  akka.remote.ReliableDeliverySupervisor [sparkDriver-akka.actor.default-dispatcher-4] - Association with remote system [akka.tcp://sparkMaster@Marcos-MacBook-Pro.local:7077] has failed, address is now gated for [5000] ms. Reason is: [Disassociated].
2015-04-08 17:21:53,942 ERROR org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend [sparkDriver-akka.actor.default-dispatcher-4] - Application has been killed. Reason: All masters are unresponsive! Giving up.
2015-04-08 17:21:53,942 WARN  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend [main] - Application ID is not initialized yet.
2015-04-08 17:21:53,944 ERROR org.apache.spark.scheduler.TaskSchedulerImpl [sparkDriver-akka.actor.default-dispatcher-4] - Exiting due to error from cluster scheduler: All masters are unresponsive! Giving up.
2015-04-08 17:22:22,637 INFO  io.prediction.tools.console.Console$ [main] - Using existing engine manifest JSON at /Users/Marco/SemanticAnalysisRepo/SemanticAnalysis/manifest.json
2015-04-08 17:22:24,318 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-08 17:22:24,426 INFO  io.prediction.tools.RunWorkflow$ [main] - Submission command: /Users/Marco/PredictionIO/vendors/spark-1.2.1/bin/spark-submit --master spark://Marcos-MacBook-Pro.local:7077 --class io.prediction.workflow.CreateWorkflow --name PredictionIO Training: IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I 1601d4b44276e463819ccf16bcea2e968082ad77 () --jars file:/Users/Marco/.pio_store/engines/IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I/1601d4b44276e463819ccf16bcea2e968082ad77/semanticanalysis_2.10-1.0.jar,file:/Users/Marco/.pio_store/engines/IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I/1601d4b44276e463819ccf16bcea2e968082ad77/SemanticAnalysis-assembly-1.0-deps.jar --files /Users/Marco/PredictionIO/conf/log4j.properties,/Users/Marco/PredictionIO/vendors/hbase-0.98.11/conf/hbase-site.xml --driver-class-path /Users/Marco/PredictionIO/conf:/Users/Marco/PredictionIO/vendors/hbase-0.98.11/conf /Users/Marco/PredictionIO/lib/pio-assembly-0.9.1.jar --env PIO_STORAGE_SOURCES_HBASE_TYPE=hbase,PIO_ENV_LOADED=1,PIO_STORAGE_SOURCES_HBASE_HOSTS=0,PIO_STORAGE_REPOSITORIES_METADATA_NAME=predictionio_metadata,PIO_FS_BASEDIR=/Users/Marco/.pio_store,PIO_STORAGE_SOURCES_ELASTICSEARCH_HOSTS=localhost,PIO_STORAGE_SOURCES_HBASE_HOME=/Users/Marco/PredictionIO/vendors/hbase-0.98.11,PIO_HOME=/Users/Marco/PredictionIO,PIO_FS_ENGINESDIR=/Users/Marco/.pio_store/engines,PIO_STORAGE_SOURCES_HBASE_PORTS=0,PIO_STORAGE_SOURCES_ELASTICSEARCH_TYPE=elasticsearch,PIO_STORAGE_REPOSITORIES_METADATA_SOURCE=ELASTICSEARCH,PIO_STORAGE_REPOSITORIES_MODELDATA_SOURCE=LOCALFS,PIO_STORAGE_REPOSITORIES_EVENTDATA_NAME=predictionio_eventdata,PIO_STORAGE_SOURCES_ELASTICSEARCH_HOME=/Users/Marco/PredictionIO/vendors/elasticsearch-1.4.4,PIO_FS_TMPDIR=/Users/Marco/.pio_store/tmp,PIO_STORAGE_REPOSITORIES_MODELDATA_NAME=pio_,PIO_STORAGE_SOURCES_LOCALFS_HOSTS=/Users/Marco/.pio_store/models,PIO_STORAGE_REPOSITORIES_EVENTDATA_SOURCE=HBASE,PIO_CONF_DIR=/Users/Marco/PredictionIO/conf,PIO_STORAGE_SOURCES_LOCALFS_PORTS=0,PIO_STORAGE_SOURCES_ELASTICSEARCH_PORTS=9300,PIO_STORAGE_SOURCES_LOCALFS_TYPE=localfs --engine-id IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I --engine-version 1601d4b44276e463819ccf16bcea2e968082ad77 --engine-variant /Users/Marco/SemanticAnalysisRepo/SemanticAnalysis/engine.json --verbosity 0
2015-04-08 17:22:26,176 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-08 17:22:26,951 INFO  io.prediction.controller.Engine [main] - Extracting datasource params...
2015-04-08 17:22:27,031 INFO  io.prediction.workflow.WorkflowUtils$ [main] - No 'name' is found. Default empty String will be used.
2015-04-08 17:22:27,043 INFO  io.prediction.controller.Engine [main] - Datasource params: (,DataSourceParams(1))
2015-04-08 17:22:27,043 INFO  io.prediction.controller.Engine [main] - Extracting preparator params...
2015-04-08 17:22:27,044 INFO  io.prediction.controller.Engine [main] - Preparator params: (,Empty)
2015-04-08 17:22:27,049 INFO  io.prediction.controller.Engine [main] - Extracting serving params...
2015-04-08 17:22:27,049 INFO  io.prediction.controller.Engine [main] - Serving params: (,Empty)
2015-04-08 17:22:28,646 INFO  Remoting [sparkDriver-akka.actor.default-dispatcher-4] - Starting remoting
2015-04-08 17:22:28,827 INFO  Remoting [sparkDriver-akka.actor.default-dispatcher-4] - Remoting started; listening on addresses :[akka.tcp://sparkDriver@10.0.22.139:57144]
2015-04-08 17:22:29,719 WARN  akka.remote.ReliableDeliverySupervisor [sparkDriver-akka.actor.default-dispatcher-2] - Association with remote system [akka.tcp://sparkMaster@Marcos-MacBook-Pro.local:7077] has failed, address is now gated for [5000] ms. Reason is: [Disassociated].
2015-04-08 17:22:49,559 WARN  akka.remote.ReliableDeliverySupervisor [sparkDriver-akka.actor.default-dispatcher-5] - Association with remote system [akka.tcp://sparkMaster@Marcos-MacBook-Pro.local:7077] has failed, address is now gated for [5000] ms. Reason is: [Disassociated].
2015-04-08 17:23:09,544 WARN  akka.remote.ReliableDeliverySupervisor [sparkDriver-akka.actor.default-dispatcher-15] - Association with remote system [akka.tcp://sparkMaster@Marcos-MacBook-Pro.local:7077] has failed, address is now gated for [5000] ms. Reason is: [Disassociated].
2015-04-08 17:26:57,726 INFO  io.prediction.tools.console.Console$ [main] - Using existing engine manifest JSON at /Users/Marco/SemanticAnalysisRepo/SemanticAnalysis/manifest.json
2015-04-08 17:26:59,347 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-08 17:26:59,468 INFO  io.prediction.tools.RunWorkflow$ [main] - Submission command: /Users/Marco/../../usr/local/Cellar/apache-spark/1.3.0//bin/spark-submit --master spark://Marcos-MacBook-Pro.local:7077 --class io.prediction.workflow.CreateWorkflow --name PredictionIO Training: IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I 1601d4b44276e463819ccf16bcea2e968082ad77 () --jars file:/Users/Marco/.pio_store/engines/IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I/1601d4b44276e463819ccf16bcea2e968082ad77/semanticanalysis_2.10-1.0.jar,file:/Users/Marco/.pio_store/engines/IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I/1601d4b44276e463819ccf16bcea2e968082ad77/SemanticAnalysis-assembly-1.0-deps.jar --files /Users/Marco/PredictionIO/conf/log4j.properties,/Users/Marco/PredictionIO/vendors/hbase-0.98.11/conf/hbase-site.xml --driver-class-path /Users/Marco/PredictionIO/conf:/Users/Marco/PredictionIO/vendors/hbase-0.98.11/conf /Users/Marco/PredictionIO/lib/pio-assembly-0.9.1.jar --env PIO_STORAGE_SOURCES_HBASE_TYPE=hbase,PIO_ENV_LOADED=1,PIO_STORAGE_SOURCES_HBASE_HOSTS=0,PIO_STORAGE_REPOSITORIES_METADATA_NAME=predictionio_metadata,PIO_FS_BASEDIR=/Users/Marco/.pio_store,PIO_STORAGE_SOURCES_ELASTICSEARCH_HOSTS=localhost,PIO_STORAGE_SOURCES_HBASE_HOME=/Users/Marco/PredictionIO/vendors/hbase-0.98.11,PIO_HOME=/Users/Marco/PredictionIO,PIO_FS_ENGINESDIR=/Users/Marco/.pio_store/engines,PIO_STORAGE_SOURCES_HBASE_PORTS=0,PIO_STORAGE_SOURCES_ELASTICSEARCH_TYPE=elasticsearch,PIO_STORAGE_REPOSITORIES_METADATA_SOURCE=ELASTICSEARCH,PIO_STORAGE_REPOSITORIES_MODELDATA_SOURCE=LOCALFS,PIO_STORAGE_REPOSITORIES_EVENTDATA_NAME=predictionio_eventdata,PIO_STORAGE_SOURCES_ELASTICSEARCH_HOME=/Users/Marco/PredictionIO/vendors/elasticsearch-1.4.4,PIO_FS_TMPDIR=/Users/Marco/.pio_store/tmp,PIO_STORAGE_REPOSITORIES_MODELDATA_NAME=pio_,PIO_STORAGE_SOURCES_LOCALFS_HOSTS=/Users/Marco/.pio_store/models,PIO_STORAGE_REPOSITORIES_EVENTDATA_SOURCE=HBASE,PIO_CONF_DIR=/Users/Marco/PredictionIO/conf,PIO_STORAGE_SOURCES_LOCALFS_PORTS=0,PIO_STORAGE_SOURCES_ELASTICSEARCH_PORTS=9300,PIO_STORAGE_SOURCES_LOCALFS_TYPE=localfs --engine-id IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I --engine-version 1601d4b44276e463819ccf16bcea2e968082ad77 --engine-variant /Users/Marco/SemanticAnalysisRepo/SemanticAnalysis/engine.json --verbosity 0
2015-04-08 17:27:01,260 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-08 17:27:02,231 INFO  io.prediction.controller.Engine [main] - Extracting datasource params...
2015-04-08 17:27:02,335 INFO  io.prediction.workflow.WorkflowUtils$ [main] - No 'name' is found. Default empty String will be used.
2015-04-08 17:27:02,347 INFO  io.prediction.controller.Engine [main] - Datasource params: (,DataSourceParams(1))
2015-04-08 17:27:02,347 INFO  io.prediction.controller.Engine [main] - Extracting preparator params...
2015-04-08 17:27:02,348 INFO  io.prediction.controller.Engine [main] - Preparator params: (,Empty)
2015-04-08 17:27:02,354 INFO  io.prediction.controller.Engine [main] - Extracting serving params...
2015-04-08 17:27:02,354 INFO  io.prediction.controller.Engine [main] - Serving params: (,Empty)
2015-04-08 17:27:03,909 INFO  Remoting [sparkDriver-akka.actor.default-dispatcher-4] - Starting remoting
2015-04-08 17:27:04,081 INFO  Remoting [sparkDriver-akka.actor.default-dispatcher-4] - Remoting started; listening on addresses :[akka.tcp://sparkDriver@10.0.22.139:57185]
2015-04-08 17:27:04,290 INFO  org.spark-project.jetty.server.Server [main] - jetty-8.y.z-SNAPSHOT
2015-04-08 17:27:04,310 INFO  org.spark-project.jetty.server.AbstractConnector [main] - Started SocketConnector@0.0.0.0:57186
2015-04-08 17:27:04,433 INFO  org.spark-project.jetty.server.Server [main] - jetty-8.y.z-SNAPSHOT
2015-04-08 17:27:04,447 INFO  org.spark-project.jetty.server.AbstractConnector [main] - Started SelectChannelConnector@0.0.0.0:4040
2015-04-08 17:27:05,538 INFO  io.prediction.controller.Engine$ [main] - EngineWorkflow.train
2015-04-08 17:27:05,539 INFO  io.prediction.controller.Engine$ [main] - DataSource: SemanticAnalysis.DataSource@7f0b93b4
2015-04-08 17:27:05,540 INFO  io.prediction.controller.Engine$ [main] - Preparator: SemanticAnalysis.Preparator@523a7801
2015-04-08 17:27:05,540 INFO  io.prediction.controller.Engine$ [main] - AlgorithmList: List(SemanticAnalysis.Algorithm@4f59a516)
2015-04-08 17:27:05,541 INFO  io.prediction.controller.Engine$ [main] - Data santiy check is on.
2015-04-08 17:27:12,202 INFO  io.prediction.controller.Engine$ [main] - SemanticAnalysis.TrainingData does not support data sanity check. Skipping check.
2015-04-08 17:27:12,203 INFO  io.prediction.controller.Engine$ [main] - SemanticAnalysis.PreparedData does not support data sanity check. Skipping check.
2015-04-08 17:27:12,324 WARN  org.apache.hadoop.hbase.mapreduce.TableInputFormatBase [main] - Cannot resolve the host name for /10.0.22.139 because of javax.naming.NameNotFoundException: DNS name not found [response code 3]; remaining name '139.22.0.10.in-addr.arpa'
2015-04-08 17:28:32,944 WARN  org.apache.spark.scheduler.TaskSetManager [task-result-getter-0] - Lost task 0.0 in stage 0.0 (TID 0, 10.0.22.139): java.lang.OutOfMemoryError: Java heap space
	at java.util.Arrays.copyOf(Arrays.java:3236)
	at java.io.ByteArrayOutputStream.grow(ByteArrayOutputStream.java:118)
	at java.io.ByteArrayOutputStream.ensureCapacity(ByteArrayOutputStream.java:93)
	at java.io.ByteArrayOutputStream.write(ByteArrayOutputStream.java:153)
	at java.io.ObjectOutputStream$BlockDataOutputStream.drain(ObjectOutputStream.java:1877)
	at java.io.ObjectOutputStream$BlockDataOutputStream.setBlockDataMode(ObjectOutputStream.java:1786)
	at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1189)
	at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:348)
	at org.apache.spark.serializer.JavaSerializationStream.writeObject(JavaSerializer.scala:44)
	at org.apache.spark.serializer.JavaSerializerInstance.serialize(JavaSerializer.scala:80)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

2015-04-08 17:28:33,375 ERROR org.apache.spark.scheduler.TaskSchedulerImpl [sparkDriver-akka.actor.default-dispatcher-4] - Lost executor 0 on 10.0.22.139: remote Akka client disassociated
2015-04-08 17:28:33,380 WARN  akka.remote.ReliableDeliverySupervisor [sparkDriver-akka.actor.default-dispatcher-2] - Association with remote system [akka.tcp://sparkExecutor@10.0.22.139:57194] has failed, address is now gated for [5000] ms. Reason is: [Disassociated].
2015-04-08 17:28:33,383 WARN  org.apache.spark.scheduler.TaskSetManager [sparkDriver-akka.actor.default-dispatcher-4] - Lost task 0.1 in stage 0.0 (TID 1, 10.0.22.139): ExecutorLostFailure (executor 0 lost)
2015-04-08 17:28:33,386 ERROR org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend [sparkDriver-akka.actor.default-dispatcher-4] - Asked to remove non-existent executor 0
2015-04-08 17:28:33,404 ERROR org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend [sparkDriver-akka.actor.default-dispatcher-2] - Asked to remove non-existent executor 0
2015-04-08 17:29:48,875 WARN  org.apache.spark.scheduler.TaskSetManager [task-result-getter-1] - Lost task 0.2 in stage 0.0 (TID 2, 10.0.22.139): java.lang.OutOfMemoryError: Java heap space
	at java.util.Arrays.copyOf(Arrays.java:3236)
	at java.io.ByteArrayOutputStream.grow(ByteArrayOutputStream.java:118)
	at java.io.ByteArrayOutputStream.ensureCapacity(ByteArrayOutputStream.java:93)
	at java.io.ByteArrayOutputStream.write(ByteArrayOutputStream.java:153)
	at java.io.ObjectOutputStream$BlockDataOutputStream.drain(ObjectOutputStream.java:1877)
	at java.io.ObjectOutputStream$BlockDataOutputStream.setBlockDataMode(ObjectOutputStream.java:1786)
	at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1189)
	at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:348)
	at org.apache.spark.serializer.JavaSerializationStream.writeObject(JavaSerializer.scala:44)
	at org.apache.spark.serializer.JavaSerializerInstance.serialize(JavaSerializer.scala:80)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

2015-04-08 17:29:49,265 WARN  akka.remote.ReliableDeliverySupervisor [sparkDriver-akka.actor.default-dispatcher-2] - Association with remote system [akka.tcp://sparkExecutor@10.0.22.139:57229] has failed, address is now gated for [5000] ms. Reason is: [Disassociated].
2015-04-08 17:29:49,264 ERROR org.apache.spark.scheduler.TaskSchedulerImpl [sparkDriver-akka.actor.default-dispatcher-3] - Lost executor 1 on 10.0.22.139: remote Akka client disassociated
2015-04-08 17:29:49,267 WARN  org.apache.spark.scheduler.TaskSetManager [sparkDriver-akka.actor.default-dispatcher-3] - Lost task 0.3 in stage 0.0 (TID 3, 10.0.22.139): ExecutorLostFailure (executor 1 lost)
2015-04-08 17:29:49,268 ERROR org.apache.spark.scheduler.TaskSetManager [sparkDriver-akka.actor.default-dispatcher-3] - Task 0 in stage 0.0 failed 4 times; aborting job
2015-04-08 17:29:49,275 ERROR org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend [sparkDriver-akka.actor.default-dispatcher-3] - Asked to remove non-existent executor 1
2015-04-08 17:29:49,275 ERROR org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend [sparkDriver-akka.actor.default-dispatcher-3] - Asked to remove non-existent executor 1
2015-04-08 17:29:49,307 INFO  org.spark-project.jetty.server.handler.ContextHandler [main] - stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
2015-04-08 17:29:49,307 INFO  org.spark-project.jetty.server.handler.ContextHandler [main] - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-04-08 17:29:49,307 INFO  org.spark-project.jetty.server.handler.ContextHandler [main] - stopped o.s.j.s.ServletContextHandler{/,null}
2015-04-08 17:29:49,307 INFO  org.spark-project.jetty.server.handler.ContextHandler [main] - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-04-08 17:29:49,307 INFO  org.spark-project.jetty.server.handler.ContextHandler [main] - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-04-08 17:29:49,308 INFO  org.spark-project.jetty.server.handler.ContextHandler [main] - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-04-08 17:29:49,308 INFO  org.spark-project.jetty.server.handler.ContextHandler [main] - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-04-08 17:29:49,308 INFO  org.spark-project.jetty.server.handler.ContextHandler [main] - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-04-08 17:29:49,308 INFO  org.spark-project.jetty.server.handler.ContextHandler [main] - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-04-08 17:29:49,308 INFO  org.spark-project.jetty.server.handler.ContextHandler [main] - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-04-08 17:29:49,308 INFO  org.spark-project.jetty.server.handler.ContextHandler [main] - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-04-08 17:29:49,308 INFO  org.spark-project.jetty.server.handler.ContextHandler [main] - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-04-08 17:29:49,308 INFO  org.spark-project.jetty.server.handler.ContextHandler [main] - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-04-08 17:29:49,308 INFO  org.spark-project.jetty.server.handler.ContextHandler [main] - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-04-08 17:29:49,308 INFO  org.spark-project.jetty.server.handler.ContextHandler [main] - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-04-08 17:29:49,309 INFO  org.spark-project.jetty.server.handler.ContextHandler [main] - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-04-08 17:29:49,309 INFO  org.spark-project.jetty.server.handler.ContextHandler [main] - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-04-08 17:29:49,309 INFO  org.spark-project.jetty.server.handler.ContextHandler [main] - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-04-08 17:29:49,309 INFO  org.spark-project.jetty.server.handler.ContextHandler [main] - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-04-08 17:29:49,309 INFO  org.spark-project.jetty.server.handler.ContextHandler [main] - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-04-08 17:29:49,309 INFO  org.spark-project.jetty.server.handler.ContextHandler [main] - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-04-08 17:29:49,309 INFO  org.spark-project.jetty.server.handler.ContextHandler [main] - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-04-08 17:29:49,309 INFO  org.spark-project.jetty.server.handler.ContextHandler [main] - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-04-08 17:29:49,309 INFO  org.spark-project.jetty.server.handler.ContextHandler [main] - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-04-08 17:38:03,079 INFO  io.prediction.tools.console.Console$ [main] - Using existing engine manifest JSON at /Users/Marco/SemanticAnalysisRepo/SemanticAnalysis/manifest.json
2015-04-08 17:38:04,780 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-08 17:38:04,900 INFO  io.prediction.tools.RunWorkflow$ [main] - Submission command: /Users/Marco/../../usr/local/Cellar/apache-spark/1.3.0//bin/spark-submit --class io.prediction.workflow.CreateWorkflow --name PredictionIO Training: IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I 1601d4b44276e463819ccf16bcea2e968082ad77 () --jars file:/Users/Marco/.pio_store/engines/IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I/1601d4b44276e463819ccf16bcea2e968082ad77/semanticanalysis_2.10-1.0.jar,file:/Users/Marco/.pio_store/engines/IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I/1601d4b44276e463819ccf16bcea2e968082ad77/SemanticAnalysis-assembly-1.0-deps.jar --files /Users/Marco/PredictionIO/conf/log4j.properties,/Users/Marco/PredictionIO/vendors/hbase-0.98.11/conf/hbase-site.xml --driver-class-path /Users/Marco/PredictionIO/conf:/Users/Marco/PredictionIO/vendors/hbase-0.98.11/conf /Users/Marco/PredictionIO/lib/pio-assembly-0.9.1.jar --env PIO_STORAGE_SOURCES_HBASE_TYPE=hbase,PIO_ENV_LOADED=1,PIO_STORAGE_SOURCES_HBASE_HOSTS=0,PIO_STORAGE_REPOSITORIES_METADATA_NAME=predictionio_metadata,PIO_FS_BASEDIR=/Users/Marco/.pio_store,PIO_STORAGE_SOURCES_ELASTICSEARCH_HOSTS=localhost,PIO_STORAGE_SOURCES_HBASE_HOME=/Users/Marco/PredictionIO/vendors/hbase-0.98.11,PIO_HOME=/Users/Marco/PredictionIO,PIO_FS_ENGINESDIR=/Users/Marco/.pio_store/engines,PIO_STORAGE_SOURCES_HBASE_PORTS=0,PIO_STORAGE_SOURCES_ELASTICSEARCH_TYPE=elasticsearch,PIO_STORAGE_REPOSITORIES_METADATA_SOURCE=ELASTICSEARCH,PIO_STORAGE_REPOSITORIES_MODELDATA_SOURCE=LOCALFS,PIO_STORAGE_REPOSITORIES_EVENTDATA_NAME=predictionio_eventdata,PIO_STORAGE_SOURCES_ELASTICSEARCH_HOME=/Users/Marco/PredictionIO/vendors/elasticsearch-1.4.4,PIO_FS_TMPDIR=/Users/Marco/.pio_store/tmp,PIO_STORAGE_REPOSITORIES_MODELDATA_NAME=pio_,PIO_STORAGE_SOURCES_LOCALFS_HOSTS=/Users/Marco/.pio_store/models,PIO_STORAGE_REPOSITORIES_EVENTDATA_SOURCE=HBASE,PIO_CONF_DIR=/Users/Marco/PredictionIO/conf,PIO_STORAGE_SOURCES_LOCALFS_PORTS=0,PIO_STORAGE_SOURCES_ELASTICSEARCH_PORTS=9300,PIO_STORAGE_SOURCES_LOCALFS_TYPE=localfs --engine-id IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I --engine-version 1601d4b44276e463819ccf16bcea2e968082ad77 --engine-variant /Users/Marco/SemanticAnalysisRepo/SemanticAnalysis/engine.json --verbosity 0
2015-04-08 17:38:06,719 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-08 17:38:07,549 INFO  io.prediction.controller.Engine [main] - Extracting datasource params...
2015-04-08 17:38:07,637 INFO  io.prediction.workflow.WorkflowUtils$ [main] - No 'name' is found. Default empty String will be used.
2015-04-08 17:38:07,648 INFO  io.prediction.controller.Engine [main] - Datasource params: (,DataSourceParams(1))
2015-04-08 17:38:07,648 INFO  io.prediction.controller.Engine [main] - Extracting preparator params...
2015-04-08 17:38:07,649 INFO  io.prediction.controller.Engine [main] - Preparator params: (,Empty)
2015-04-08 17:38:07,654 INFO  io.prediction.controller.Engine [main] - Extracting serving params...
2015-04-08 17:38:07,654 INFO  io.prediction.controller.Engine [main] - Serving params: (,Empty)
2015-04-08 17:38:09,241 INFO  Remoting [sparkDriver-akka.actor.default-dispatcher-2] - Starting remoting
2015-04-08 17:38:09,425 INFO  Remoting [sparkDriver-akka.actor.default-dispatcher-2] - Remoting started; listening on addresses :[akka.tcp://sparkDriver@10.0.22.139:57287]
2015-04-08 17:38:09,608 INFO  org.spark-project.jetty.server.Server [main] - jetty-8.y.z-SNAPSHOT
2015-04-08 17:38:09,629 INFO  org.spark-project.jetty.server.AbstractConnector [main] - Started SocketConnector@0.0.0.0:57288
2015-04-08 17:38:09,750 INFO  org.spark-project.jetty.server.Server [main] - jetty-8.y.z-SNAPSHOT
2015-04-08 17:38:09,760 INFO  org.spark-project.jetty.server.AbstractConnector [main] - Started SelectChannelConnector@0.0.0.0:4040
2015-04-08 17:38:10,447 INFO  io.prediction.controller.Engine$ [main] - EngineWorkflow.train
2015-04-08 17:38:10,448 INFO  io.prediction.controller.Engine$ [main] - DataSource: SemanticAnalysis.DataSource@5e593b08
2015-04-08 17:38:10,448 INFO  io.prediction.controller.Engine$ [main] - Preparator: SemanticAnalysis.Preparator@2ac519dc
2015-04-08 17:38:10,449 INFO  io.prediction.controller.Engine$ [main] - AlgorithmList: List(SemanticAnalysis.Algorithm@3ece79fe)
2015-04-08 17:38:10,449 INFO  io.prediction.controller.Engine$ [main] - Data santiy check is on.
2015-04-08 17:38:21,783 INFO  io.prediction.controller.Engine$ [main] - SemanticAnalysis.TrainingData does not support data sanity check. Skipping check.
2015-04-08 17:38:21,785 INFO  io.prediction.controller.Engine$ [main] - SemanticAnalysis.PreparedData does not support data sanity check. Skipping check.
2015-04-08 17:38:21,908 WARN  org.apache.hadoop.hbase.mapreduce.TableInputFormatBase [main] - Cannot resolve the host name for /10.0.22.139 because of javax.naming.NameNotFoundException: DNS name not found [response code 3]; remaining name '139.22.0.10.in-addr.arpa'
2015-04-08 17:39:25,753 ERROR org.apache.spark.executor.Executor [Executor task launch worker-0] - Exception in task 0.0 in stage 0.0 (TID 0)
java.lang.OutOfMemoryError: Java heap space
	at java.util.Arrays.copyOf(Arrays.java:3236)
	at java.io.ByteArrayOutputStream.grow(ByteArrayOutputStream.java:118)
	at java.io.ByteArrayOutputStream.ensureCapacity(ByteArrayOutputStream.java:93)
	at java.io.ByteArrayOutputStream.write(ByteArrayOutputStream.java:153)
	at java.io.ObjectOutputStream$BlockDataOutputStream.drain(ObjectOutputStream.java:1877)
	at java.io.ObjectOutputStream$BlockDataOutputStream.setBlockDataMode(ObjectOutputStream.java:1786)
	at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1189)
	at java.io.ObjectOutputStream.writeArray(ObjectOutputStream.java:1378)
	at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1174)
	at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:348)
	at org.apache.spark.serializer.JavaSerializationStream.writeObject(JavaSerializer.scala:44)
	at org.apache.spark.serializer.JavaSerializerInstance.serialize(JavaSerializer.scala:80)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-04-08 17:39:25,765 ERROR org.apache.spark.util.SparkUncaughtExceptionHandler [Executor task launch worker-0] - Uncaught exception in thread Thread[Executor task launch worker-0,5,main]
java.lang.OutOfMemoryError: Java heap space
	at java.util.Arrays.copyOf(Arrays.java:3236)
	at java.io.ByteArrayOutputStream.grow(ByteArrayOutputStream.java:118)
	at java.io.ByteArrayOutputStream.ensureCapacity(ByteArrayOutputStream.java:93)
	at java.io.ByteArrayOutputStream.write(ByteArrayOutputStream.java:153)
	at java.io.ObjectOutputStream$BlockDataOutputStream.drain(ObjectOutputStream.java:1877)
	at java.io.ObjectOutputStream$BlockDataOutputStream.setBlockDataMode(ObjectOutputStream.java:1786)
	at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1189)
	at java.io.ObjectOutputStream.writeArray(ObjectOutputStream.java:1378)
	at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1174)
	at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:348)
	at org.apache.spark.serializer.JavaSerializationStream.writeObject(JavaSerializer.scala:44)
	at org.apache.spark.serializer.JavaSerializerInstance.serialize(JavaSerializer.scala:80)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-04-08 17:39:25,774 WARN  org.apache.spark.scheduler.TaskSetManager [task-result-getter-0] - Lost task 0.0 in stage 0.0 (TID 0, localhost): java.lang.OutOfMemoryError: Java heap space
	at java.util.Arrays.copyOf(Arrays.java:3236)
	at java.io.ByteArrayOutputStream.grow(ByteArrayOutputStream.java:118)
	at java.io.ByteArrayOutputStream.ensureCapacity(ByteArrayOutputStream.java:93)
	at java.io.ByteArrayOutputStream.write(ByteArrayOutputStream.java:153)
	at java.io.ObjectOutputStream$BlockDataOutputStream.drain(ObjectOutputStream.java:1877)
	at java.io.ObjectOutputStream$BlockDataOutputStream.setBlockDataMode(ObjectOutputStream.java:1786)
	at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1189)
	at java.io.ObjectOutputStream.writeArray(ObjectOutputStream.java:1378)
	at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1174)
	at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:348)
	at org.apache.spark.serializer.JavaSerializationStream.writeObject(JavaSerializer.scala:44)
	at org.apache.spark.serializer.JavaSerializerInstance.serialize(JavaSerializer.scala:80)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

2015-04-08 17:39:25,778 ERROR org.apache.spark.scheduler.TaskSetManager [task-result-getter-0] - Task 0 in stage 0.0 failed 1 times; aborting job
2015-04-08 17:48:03,135 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-08 17:48:19,314 INFO  io.prediction.data.storage.hbase.HBLEvents [main] - The table predictionio_eventdata:events_3 doesn't exist yet. Creating now...
2015-04-08 17:48:24,725 INFO  io.prediction.tools.console.App$ [main] - Initialized Event Store for this app ID: 3.
2015-04-08 17:48:24,742 INFO  io.prediction.tools.console.App$ [main] - Created new app:
2015-04-08 17:48:24,742 INFO  io.prediction.tools.console.App$ [main] -       Name: TestApp3
2015-04-08 17:48:24,743 INFO  io.prediction.tools.console.App$ [main] -         ID: 3
2015-04-08 17:48:24,743 INFO  io.prediction.tools.console.App$ [main] - Access Key: VcclTlUqfD7nbqPCCQY9dsnQm3VhUtw4JyUlwBJaAtLraA2RQfaLWBUxofAPr0o9
2015-04-08 17:50:06,505 INFO  io.prediction.tools.console.Console$ [main] - Using existing engine manifest JSON at /Users/Marco/SemanticAnalysisRepo/SemanticAnalysis/manifest.json
2015-04-08 17:50:06,552 INFO  io.prediction.tools.console.Console$ [main] - Using command '/Users/Marco/PredictionIO/sbt/sbt' at the current working directory to build.
2015-04-08 17:50:06,553 INFO  io.prediction.tools.console.Console$ [main] - If the path above is incorrect, this process will fail.
2015-04-08 17:50:06,554 INFO  io.prediction.tools.console.Console$ [main] - Uber JAR disabled. Making sure lib/pio-assembly-0.9.1.jar is absent.
2015-04-08 17:50:06,557 INFO  io.prediction.tools.console.Console$ [main] - Going to run: /Users/Marco/PredictionIO/sbt/sbt  package assemblyPackageDependency
2015-04-08 17:50:20,495 INFO  io.prediction.tools.console.Console$ [main] - Build finished successfully.
2015-04-08 17:50:20,496 INFO  io.prediction.tools.console.Console$ [main] - Looking for an engine...
2015-04-08 17:50:20,504 INFO  io.prediction.tools.console.Console$ [main] - Found SemanticAnalysis-assembly-1.0-deps.jar
2015-04-08 17:50:20,505 INFO  io.prediction.tools.console.Console$ [main] - Found semanticanalysis_2.10-1.0.jar
2015-04-08 17:50:20,511 INFO  io.prediction.tools.console.Console$ [main] - HADOOP_CONF_DIR is not set. Assuming HDFS is unavailable.
2015-04-08 17:50:22,154 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-08 17:50:22,257 INFO  io.prediction.tools.RegisterEngine$ [main] - Copying file:/Users/Marco/SemanticAnalysisRepo/SemanticAnalysis/target/scala-2.10/SemanticAnalysis-assembly-1.0-deps.jar to file:/Users/Marco/.pio_store/engines/IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I/1601d4b44276e463819ccf16bcea2e968082ad77/SemanticAnalysis-assembly-1.0-deps.jar
2015-04-08 17:50:22,337 INFO  io.prediction.tools.RegisterEngine$ [main] - Copying file:/Users/Marco/SemanticAnalysisRepo/SemanticAnalysis/target/scala-2.10/semanticanalysis_2.10-1.0.jar to file:/Users/Marco/.pio_store/engines/IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I/1601d4b44276e463819ccf16bcea2e968082ad77/semanticanalysis_2.10-1.0.jar
2015-04-08 17:50:22,349 INFO  io.prediction.tools.RegisterEngine$ [main] - Registering engine IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I 1601d4b44276e463819ccf16bcea2e968082ad77
2015-04-08 17:50:22,370 INFO  io.prediction.tools.console.Console$ [main] - Your engine is ready for training.
2015-04-08 17:50:28,450 INFO  io.prediction.tools.console.Console$ [main] - Using existing engine manifest JSON at /Users/Marco/SemanticAnalysisRepo/SemanticAnalysis/manifest.json
2015-04-08 17:50:30,098 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-08 17:50:30,203 INFO  io.prediction.tools.RunWorkflow$ [main] - Submission command: /Users/Marco/../../usr/local/Cellar/apache-spark/1.3.0//bin/spark-submit --class io.prediction.workflow.CreateWorkflow --name PredictionIO Training: IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I 1601d4b44276e463819ccf16bcea2e968082ad77 () --jars file:/Users/Marco/.pio_store/engines/IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I/1601d4b44276e463819ccf16bcea2e968082ad77/semanticanalysis_2.10-1.0.jar,file:/Users/Marco/.pio_store/engines/IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I/1601d4b44276e463819ccf16bcea2e968082ad77/SemanticAnalysis-assembly-1.0-deps.jar --files /Users/Marco/PredictionIO/conf/log4j.properties,/Users/Marco/PredictionIO/vendors/hbase-0.98.11/conf/hbase-site.xml --driver-class-path /Users/Marco/PredictionIO/conf:/Users/Marco/PredictionIO/vendors/hbase-0.98.11/conf /Users/Marco/PredictionIO/lib/pio-assembly-0.9.1.jar --env PIO_STORAGE_SOURCES_HBASE_TYPE=hbase,PIO_ENV_LOADED=1,PIO_STORAGE_SOURCES_HBASE_HOSTS=0,PIO_STORAGE_REPOSITORIES_METADATA_NAME=predictionio_metadata,PIO_FS_BASEDIR=/Users/Marco/.pio_store,PIO_STORAGE_SOURCES_ELASTICSEARCH_HOSTS=localhost,PIO_STORAGE_SOURCES_HBASE_HOME=/Users/Marco/PredictionIO/vendors/hbase-0.98.11,PIO_HOME=/Users/Marco/PredictionIO,PIO_FS_ENGINESDIR=/Users/Marco/.pio_store/engines,PIO_STORAGE_SOURCES_HBASE_PORTS=0,PIO_STORAGE_SOURCES_ELASTICSEARCH_TYPE=elasticsearch,PIO_STORAGE_REPOSITORIES_METADATA_SOURCE=ELASTICSEARCH,PIO_STORAGE_REPOSITORIES_MODELDATA_SOURCE=LOCALFS,PIO_STORAGE_REPOSITORIES_EVENTDATA_NAME=predictionio_eventdata,PIO_STORAGE_SOURCES_ELASTICSEARCH_HOME=/Users/Marco/PredictionIO/vendors/elasticsearch-1.4.4,PIO_FS_TMPDIR=/Users/Marco/.pio_store/tmp,PIO_STORAGE_REPOSITORIES_MODELDATA_NAME=pio_,PIO_STORAGE_SOURCES_LOCALFS_HOSTS=/Users/Marco/.pio_store/models,PIO_STORAGE_REPOSITORIES_EVENTDATA_SOURCE=HBASE,PIO_CONF_DIR=/Users/Marco/PredictionIO/conf,PIO_STORAGE_SOURCES_LOCALFS_PORTS=0,PIO_STORAGE_SOURCES_ELASTICSEARCH_PORTS=9300,PIO_STORAGE_SOURCES_LOCALFS_TYPE=localfs --engine-id IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I --engine-version 1601d4b44276e463819ccf16bcea2e968082ad77 --engine-variant /Users/Marco/SemanticAnalysisRepo/SemanticAnalysis/engine.json --verbosity 0
2015-04-08 17:50:31,969 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-08 17:50:32,781 INFO  io.prediction.controller.Engine [main] - Extracting datasource params...
2015-04-08 17:50:32,874 INFO  io.prediction.workflow.WorkflowUtils$ [main] - No 'name' is found. Default empty String will be used.
2015-04-08 17:50:32,893 INFO  io.prediction.controller.Engine [main] - Datasource params: (,DataSourceParams(3))
2015-04-08 17:50:32,893 INFO  io.prediction.controller.Engine [main] - Extracting preparator params...
2015-04-08 17:50:32,895 INFO  io.prediction.controller.Engine [main] - Preparator params: (,Empty)
2015-04-08 17:50:32,901 INFO  io.prediction.controller.Engine [main] - Extracting serving params...
2015-04-08 17:50:32,902 INFO  io.prediction.controller.Engine [main] - Serving params: (,Empty)
2015-04-08 17:50:34,476 INFO  Remoting [sparkDriver-akka.actor.default-dispatcher-2] - Starting remoting
2015-04-08 17:50:34,643 INFO  Remoting [sparkDriver-akka.actor.default-dispatcher-3] - Remoting started; listening on addresses :[akka.tcp://sparkDriver@10.0.22.139:57629]
2015-04-08 17:50:34,821 INFO  org.spark-project.jetty.server.Server [main] - jetty-8.y.z-SNAPSHOT
2015-04-08 17:50:34,841 INFO  org.spark-project.jetty.server.AbstractConnector [main] - Started SocketConnector@0.0.0.0:57630
2015-04-08 17:50:34,960 INFO  org.spark-project.jetty.server.Server [main] - jetty-8.y.z-SNAPSHOT
2015-04-08 17:50:34,971 INFO  org.spark-project.jetty.server.AbstractConnector [main] - Started SelectChannelConnector@0.0.0.0:4040
2015-04-08 17:50:35,602 INFO  io.prediction.controller.Engine$ [main] - EngineWorkflow.train
2015-04-08 17:50:35,603 INFO  io.prediction.controller.Engine$ [main] - DataSource: SemanticAnalysis.DataSource@d13960e
2015-04-08 17:50:35,603 INFO  io.prediction.controller.Engine$ [main] - Preparator: SemanticAnalysis.Preparator@3946075
2015-04-08 17:50:35,603 INFO  io.prediction.controller.Engine$ [main] - AlgorithmList: List(SemanticAnalysis.Algorithm@3d53e6f7)
2015-04-08 17:50:35,604 INFO  io.prediction.controller.Engine$ [main] - Data santiy check is on.
2015-04-08 17:50:36,807 INFO  io.prediction.controller.Engine$ [main] - SemanticAnalysis.TrainingData does not support data sanity check. Skipping check.
2015-04-08 17:50:36,808 INFO  io.prediction.controller.Engine$ [main] - SemanticAnalysis.PreparedData does not support data sanity check. Skipping check.
2015-04-08 17:50:36,942 WARN  org.apache.hadoop.hbase.mapreduce.TableInputFormatBase [main] - Cannot resolve the host name for /10.0.22.139 because of javax.naming.NameNotFoundException: DNS name not found [response code 3]; remaining name '139.22.0.10.in-addr.arpa'
2015-04-08 17:50:40,479 INFO  io.prediction.controller.Engine$ [main] - SemanticAnalysis.Model does not support data sanity check. Skipping check.
2015-04-08 17:50:40,479 INFO  io.prediction.controller.Engine$ [main] - EngineWorkflow.train completed
2015-04-08 17:50:40,480 INFO  io.prediction.controller.Engine [main] - engineInstanceId=AUybqDNCi7z9HxmsiEkQ
2015-04-08 17:50:40,493 INFO  io.prediction.workflow.CoreWorkflow$ [main] - Inserting persistent model
2015-04-08 17:50:40,624 INFO  io.prediction.workflow.CoreWorkflow$ [main] - Updating engine instance
2015-04-08 17:50:40,638 INFO  io.prediction.workflow.CoreWorkflow$ [main] - Training completed successfully.
2015-04-08 17:50:40,653 INFO  org.spark-project.jetty.server.handler.ContextHandler [main] - stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
2015-04-08 17:50:40,654 INFO  org.spark-project.jetty.server.handler.ContextHandler [main] - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-04-08 17:50:40,654 INFO  org.spark-project.jetty.server.handler.ContextHandler [main] - stopped o.s.j.s.ServletContextHandler{/,null}
2015-04-08 17:50:40,654 INFO  org.spark-project.jetty.server.handler.ContextHandler [main] - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-04-08 17:50:40,654 INFO  org.spark-project.jetty.server.handler.ContextHandler [main] - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-04-08 17:50:40,654 INFO  org.spark-project.jetty.server.handler.ContextHandler [main] - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-04-08 17:50:40,654 INFO  org.spark-project.jetty.server.handler.ContextHandler [main] - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-04-08 17:50:40,655 INFO  org.spark-project.jetty.server.handler.ContextHandler [main] - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-04-08 17:50:40,655 INFO  org.spark-project.jetty.server.handler.ContextHandler [main] - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-04-08 17:50:40,655 INFO  org.spark-project.jetty.server.handler.ContextHandler [main] - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-04-08 17:50:40,655 INFO  org.spark-project.jetty.server.handler.ContextHandler [main] - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-04-08 17:50:40,655 INFO  org.spark-project.jetty.server.handler.ContextHandler [main] - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-04-08 17:50:40,655 INFO  org.spark-project.jetty.server.handler.ContextHandler [main] - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-04-08 17:50:40,655 INFO  org.spark-project.jetty.server.handler.ContextHandler [main] - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-04-08 17:50:40,655 INFO  org.spark-project.jetty.server.handler.ContextHandler [main] - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-04-08 17:50:40,656 INFO  org.spark-project.jetty.server.handler.ContextHandler [main] - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-04-08 17:50:40,656 INFO  org.spark-project.jetty.server.handler.ContextHandler [main] - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-04-08 17:50:40,656 INFO  org.spark-project.jetty.server.handler.ContextHandler [main] - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-04-08 17:50:40,656 INFO  org.spark-project.jetty.server.handler.ContextHandler [main] - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-04-08 17:50:40,656 INFO  org.spark-project.jetty.server.handler.ContextHandler [main] - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-04-08 17:50:40,656 INFO  org.spark-project.jetty.server.handler.ContextHandler [main] - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-04-08 17:50:40,656 INFO  org.spark-project.jetty.server.handler.ContextHandler [main] - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-04-08 17:50:40,656 INFO  org.spark-project.jetty.server.handler.ContextHandler [main] - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-04-08 17:50:40,657 INFO  org.spark-project.jetty.server.handler.ContextHandler [main] - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-04-08 17:51:16,048 INFO  io.prediction.tools.RunServer$ [main] - Submission command: /Users/Marco/../../usr/local/Cellar/apache-spark/1.3.0//bin/spark-submit --class io.prediction.workflow.CreateServer --name PredictionIO Engine Instance: AUybqDNCi7z9HxmsiEkQ --jars file:/Users/Marco/.pio_store/engines/IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I/1601d4b44276e463819ccf16bcea2e968082ad77/semanticanalysis_2.10-1.0.jar,file:/Users/Marco/.pio_store/engines/IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I/1601d4b44276e463819ccf16bcea2e968082ad77/SemanticAnalysis-assembly-1.0-deps.jar --files /Users/Marco/PredictionIO/conf/log4j.properties,/Users/Marco/PredictionIO/vendors/hbase-0.98.11/conf/hbase-site.xml --driver-class-path /Users/Marco/PredictionIO/conf:/Users/Marco/PredictionIO/vendors/hbase-0.98.11/conf /Users/Marco/PredictionIO/lib/pio-assembly-0.9.1.jar --engineInstanceId AUybqDNCi7z9HxmsiEkQ --ip localhost --port 8000 --event-server-ip localhost --event-server-port 7070
2015-04-08 17:51:19,790 WARN  io.prediction.workflow.WorkflowUtils$ [pio-server-akka.actor.default-dispatcher-5] - Non-empty parameters supplied to SemanticAnalysis.Preparator, but its constructor does not accept any arguments. Stubbing with empty parameters.
2015-04-08 17:51:19,796 WARN  io.prediction.workflow.WorkflowUtils$ [pio-server-akka.actor.default-dispatcher-5] - Non-empty parameters supplied to SemanticAnalysis.Serving, but its constructor does not accept any arguments. Stubbing with empty parameters.
2015-04-08 17:51:20,421 WARN  org.apache.hadoop.util.NativeCodeLoader [pio-server-akka.actor.default-dispatcher-5] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-08 17:51:20,609 INFO  Remoting [sparkDriver-akka.actor.default-dispatcher-2] - Starting remoting
2015-04-08 17:51:20,783 INFO  Remoting [sparkDriver-akka.actor.default-dispatcher-2] - Remoting started; listening on addresses :[akka.tcp://sparkDriver@10.0.22.139:57671]
2015-04-08 17:51:20,944 INFO  org.spark-project.jetty.server.Server [pio-server-akka.actor.default-dispatcher-5] - jetty-8.y.z-SNAPSHOT
2015-04-08 17:51:20,957 INFO  org.spark-project.jetty.server.AbstractConnector [pio-server-akka.actor.default-dispatcher-5] - Started SocketConnector@0.0.0.0:57672
2015-04-08 17:51:21,062 INFO  org.spark-project.jetty.server.Server [pio-server-akka.actor.default-dispatcher-5] - jetty-8.y.z-SNAPSHOT
2015-04-08 17:51:21,072 INFO  org.spark-project.jetty.server.AbstractConnector [pio-server-akka.actor.default-dispatcher-5] - Started SelectChannelConnector@0.0.0.0:4040
2015-04-08 17:51:21,711 INFO  io.prediction.controller.Engine [pio-server-akka.actor.default-dispatcher-5] - Using persisted model
2015-04-08 17:51:21,712 INFO  io.prediction.controller.Engine [pio-server-akka.actor.default-dispatcher-5] - Loaded model SemanticAnalysis.Model for algorithm SemanticAnalysis.Algorithm
2015-04-08 17:51:21,721 INFO  io.prediction.workflow.MasterActor [pio-server-akka.actor.default-dispatcher-2] - Undeploying any existing engine instance at http://localhost:8000
2015-04-08 17:51:21,734 WARN  io.prediction.workflow.MasterActor [pio-server-akka.actor.default-dispatcher-2] - Nothing at http://localhost:8000
2015-04-08 17:51:22,601 INFO  spray.can.server.HttpListener [pio-server-akka.actor.default-dispatcher-4] - Bound to localhost/127.0.0.1:8000
2015-04-08 17:51:22,602 INFO  io.prediction.workflow.MasterActor [pio-server-akka.actor.default-dispatcher-2] - Bind successful. Ready to serve.
2015-04-08 17:56:50,101 INFO  io.prediction.tools.RunServer$ [main] - Submission command: /Users/Marco/../../usr/local/Cellar/apache-spark/1.3.0//bin/spark-submit --class io.prediction.workflow.CreateServer --name PredictionIO Engine Instance: AUybqDNCi7z9HxmsiEkQ --jars file:/Users/Marco/.pio_store/engines/IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I/1601d4b44276e463819ccf16bcea2e968082ad77/semanticanalysis_2.10-1.0.jar,file:/Users/Marco/.pio_store/engines/IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I/1601d4b44276e463819ccf16bcea2e968082ad77/SemanticAnalysis-assembly-1.0-deps.jar --files /Users/Marco/PredictionIO/conf/log4j.properties,/Users/Marco/PredictionIO/vendors/hbase-0.98.11/conf/hbase-site.xml --driver-class-path /Users/Marco/PredictionIO/conf:/Users/Marco/PredictionIO/vendors/hbase-0.98.11/conf /Users/Marco/PredictionIO/lib/pio-assembly-0.9.1.jar --engineInstanceId AUybqDNCi7z9HxmsiEkQ --ip localhost --port 8000 --event-server-ip localhost --event-server-port 7070
2015-04-08 17:56:53,788 WARN  io.prediction.workflow.WorkflowUtils$ [pio-server-akka.actor.default-dispatcher-3] - Non-empty parameters supplied to SemanticAnalysis.Preparator, but its constructor does not accept any arguments. Stubbing with empty parameters.
2015-04-08 17:56:53,795 WARN  io.prediction.workflow.WorkflowUtils$ [pio-server-akka.actor.default-dispatcher-3] - Non-empty parameters supplied to SemanticAnalysis.Serving, but its constructor does not accept any arguments. Stubbing with empty parameters.
2015-04-08 17:56:54,462 WARN  org.apache.hadoop.util.NativeCodeLoader [pio-server-akka.actor.default-dispatcher-3] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-08 17:56:54,642 INFO  Remoting [sparkDriver-akka.actor.default-dispatcher-5] - Starting remoting
2015-04-08 17:56:54,808 INFO  Remoting [sparkDriver-akka.actor.default-dispatcher-5] - Remoting started; listening on addresses :[akka.tcp://sparkDriver@10.0.22.139:57726]
2015-04-08 17:56:54,969 INFO  org.spark-project.jetty.server.Server [pio-server-akka.actor.default-dispatcher-3] - jetty-8.y.z-SNAPSHOT
2015-04-08 17:56:54,982 INFO  org.spark-project.jetty.server.AbstractConnector [pio-server-akka.actor.default-dispatcher-3] - Started SocketConnector@0.0.0.0:57727
2015-04-08 17:56:55,083 INFO  org.spark-project.jetty.server.Server [pio-server-akka.actor.default-dispatcher-3] - jetty-8.y.z-SNAPSHOT
2015-04-08 17:56:55,092 INFO  org.spark-project.jetty.server.AbstractConnector [pio-server-akka.actor.default-dispatcher-3] - Started SelectChannelConnector@0.0.0.0:4040
2015-04-08 17:56:55,711 INFO  io.prediction.controller.Engine [pio-server-akka.actor.default-dispatcher-3] - Using persisted model
2015-04-08 17:56:55,712 INFO  io.prediction.controller.Engine [pio-server-akka.actor.default-dispatcher-3] - Loaded model SemanticAnalysis.Model for algorithm SemanticAnalysis.Algorithm
2015-04-08 17:56:55,722 INFO  io.prediction.workflow.MasterActor [pio-server-akka.actor.default-dispatcher-4] - Undeploying any existing engine instance at http://localhost:8000
2015-04-08 17:56:55,736 WARN  io.prediction.workflow.MasterActor [pio-server-akka.actor.default-dispatcher-4] - Nothing at http://localhost:8000
2015-04-08 17:56:56,597 INFO  spray.can.server.HttpListener [pio-server-akka.actor.default-dispatcher-4] - Bound to localhost/127.0.0.1:8000
2015-04-08 17:56:56,599 INFO  io.prediction.workflow.MasterActor [pio-server-akka.actor.default-dispatcher-3] - Bind successful. Ready to serve.
2015-04-08 17:59:25,437 INFO  io.prediction.tools.RunServer$ [main] - Submission command: /Users/Marco/../../usr/local/Cellar/apache-spark/1.3.0//bin/spark-submit --class io.prediction.workflow.CreateServer --name PredictionIO Engine Instance: AUybqDNCi7z9HxmsiEkQ --jars file:/Users/Marco/.pio_store/engines/IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I/1601d4b44276e463819ccf16bcea2e968082ad77/semanticanalysis_2.10-1.0.jar,file:/Users/Marco/.pio_store/engines/IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I/1601d4b44276e463819ccf16bcea2e968082ad77/SemanticAnalysis-assembly-1.0-deps.jar --files /Users/Marco/PredictionIO/conf/log4j.properties,/Users/Marco/PredictionIO/vendors/hbase-0.98.11/conf/hbase-site.xml --driver-class-path /Users/Marco/PredictionIO/conf:/Users/Marco/PredictionIO/vendors/hbase-0.98.11/conf /Users/Marco/PredictionIO/lib/pio-assembly-0.9.1.jar --engineInstanceId AUybqDNCi7z9HxmsiEkQ --ip localhost --port 8000 --event-server-ip localhost --event-server-port 7070
2015-04-08 17:59:29,184 WARN  io.prediction.workflow.WorkflowUtils$ [pio-server-akka.actor.default-dispatcher-2] - Non-empty parameters supplied to SemanticAnalysis.Preparator, but its constructor does not accept any arguments. Stubbing with empty parameters.
2015-04-08 17:59:29,190 WARN  io.prediction.workflow.WorkflowUtils$ [pio-server-akka.actor.default-dispatcher-2] - Non-empty parameters supplied to SemanticAnalysis.Serving, but its constructor does not accept any arguments. Stubbing with empty parameters.
2015-04-08 17:59:29,811 WARN  org.apache.hadoop.util.NativeCodeLoader [pio-server-akka.actor.default-dispatcher-2] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-08 17:59:29,985 INFO  Remoting [sparkDriver-akka.actor.default-dispatcher-5] - Starting remoting
2015-04-08 17:59:30,143 INFO  Remoting [sparkDriver-akka.actor.default-dispatcher-5] - Remoting started; listening on addresses :[akka.tcp://sparkDriver@10.0.22.139:57784]
2015-04-08 17:59:30,304 INFO  org.spark-project.jetty.server.Server [pio-server-akka.actor.default-dispatcher-2] - jetty-8.y.z-SNAPSHOT
2015-04-08 17:59:30,318 INFO  org.spark-project.jetty.server.AbstractConnector [pio-server-akka.actor.default-dispatcher-2] - Started SocketConnector@0.0.0.0:57785
2015-04-08 17:59:30,425 INFO  org.spark-project.jetty.server.Server [pio-server-akka.actor.default-dispatcher-2] - jetty-8.y.z-SNAPSHOT
2015-04-08 17:59:30,439 INFO  org.spark-project.jetty.server.AbstractConnector [pio-server-akka.actor.default-dispatcher-2] - Started SelectChannelConnector@0.0.0.0:4040
2015-04-08 17:59:31,070 INFO  io.prediction.controller.Engine [pio-server-akka.actor.default-dispatcher-2] - Using persisted model
2015-04-08 17:59:31,072 INFO  io.prediction.controller.Engine [pio-server-akka.actor.default-dispatcher-2] - Loaded model SemanticAnalysis.Model for algorithm SemanticAnalysis.Algorithm
2015-04-08 17:59:31,082 INFO  io.prediction.workflow.MasterActor [pio-server-akka.actor.default-dispatcher-3] - Undeploying any existing engine instance at http://localhost:8000
2015-04-08 17:59:31,097 WARN  io.prediction.workflow.MasterActor [pio-server-akka.actor.default-dispatcher-3] - Nothing at http://localhost:8000
2015-04-08 17:59:32,076 INFO  spray.can.server.HttpListener [pio-server-akka.actor.default-dispatcher-4] - Bound to localhost/127.0.0.1:8000
2015-04-08 17:59:32,077 INFO  io.prediction.workflow.MasterActor [pio-server-akka.actor.default-dispatcher-3] - Bind successful. Ready to serve.
2015-04-08 18:01:30,391 WARN  com.github.fommil.netlib.BLAS [ForkJoinPool-2-worker-7] - Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS
2015-04-08 18:01:30,392 WARN  com.github.fommil.netlib.BLAS [ForkJoinPool-2-worker-7] - Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS
2015-04-08 18:07:39,609 INFO  io.prediction.tools.console.Console$ [main] - Using existing engine manifest JSON at /Users/Marco/SemanticAnalysisRepo/SemanticAnalysis/manifest.json
2015-04-08 18:07:39,655 INFO  io.prediction.tools.console.Console$ [main] - Using command '/Users/Marco/PredictionIO/sbt/sbt' at the current working directory to build.
2015-04-08 18:07:39,655 INFO  io.prediction.tools.console.Console$ [main] - If the path above is incorrect, this process will fail.
2015-04-08 18:07:39,658 INFO  io.prediction.tools.console.Console$ [main] - Uber JAR disabled. Making sure lib/pio-assembly-0.9.1.jar is absent.
2015-04-08 18:07:39,659 INFO  io.prediction.tools.console.Console$ [main] - Going to run: /Users/Marco/PredictionIO/sbt/sbt  package assemblyPackageDependency
2015-04-08 18:07:49,400 INFO  io.prediction.tools.console.Console$ [main] - Build finished successfully.
2015-04-08 18:07:49,400 INFO  io.prediction.tools.console.Console$ [main] - Looking for an engine...
2015-04-08 18:07:49,430 INFO  io.prediction.tools.console.Console$ [main] - Found SemanticAnalysis-assembly-1.0-deps.jar
2015-04-08 18:07:49,430 INFO  io.prediction.tools.console.Console$ [main] - Found semanticanalysis_2.10-1.0.jar
2015-04-08 18:07:49,470 INFO  io.prediction.tools.console.Console$ [main] - HADOOP_CONF_DIR is not set. Assuming HDFS is unavailable.
2015-04-08 18:07:53,576 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-08 18:07:53,902 INFO  io.prediction.tools.RegisterEngine$ [main] - Copying file:/Users/Marco/SemanticAnalysisRepo/SemanticAnalysis/target/scala-2.10/SemanticAnalysis-assembly-1.0-deps.jar to file:/Users/Marco/.pio_store/engines/IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I/1601d4b44276e463819ccf16bcea2e968082ad77/SemanticAnalysis-assembly-1.0-deps.jar
2015-04-08 18:07:54,159 INFO  io.prediction.tools.RegisterEngine$ [main] - Copying file:/Users/Marco/SemanticAnalysisRepo/SemanticAnalysis/target/scala-2.10/semanticanalysis_2.10-1.0.jar to file:/Users/Marco/.pio_store/engines/IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I/1601d4b44276e463819ccf16bcea2e968082ad77/semanticanalysis_2.10-1.0.jar
2015-04-08 18:07:54,203 INFO  io.prediction.tools.RegisterEngine$ [main] - Registering engine IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I 1601d4b44276e463819ccf16bcea2e968082ad77
2015-04-08 18:07:54,305 INFO  io.prediction.tools.console.Console$ [main] - Your engine is ready for training.
2015-04-08 18:08:21,894 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-08 18:08:27,939 INFO  io.prediction.data.storage.hbase.HBLEvents [main] - The table predictionio_eventdata:events_4 doesn't exist yet. Creating now...
2015-04-08 18:08:33,358 INFO  io.prediction.tools.console.App$ [main] - Initialized Event Store for this app ID: 4.
2015-04-08 18:08:33,376 INFO  io.prediction.tools.console.App$ [main] - Created new app:
2015-04-08 18:08:33,377 INFO  io.prediction.tools.console.App$ [main] -       Name: TestApp50000
2015-04-08 18:08:33,377 INFO  io.prediction.tools.console.App$ [main] -         ID: 4
2015-04-08 18:08:33,378 INFO  io.prediction.tools.console.App$ [main] - Access Key: H3qQ0peaL3MRu289hZNVtHxS3jXlBC303l59CcqQi9DRU0LSWCPU3SCBIEgRGDpa
2015-04-08 18:13:45,572 INFO  io.prediction.tools.console.Console$ [main] - Using existing engine manifest JSON at /Users/Marco/SemanticAnalysisRepo/SemanticAnalysis/manifest.json
2015-04-08 18:13:45,618 INFO  io.prediction.tools.console.Console$ [main] - Using command '/Users/Marco/PredictionIO/sbt/sbt' at the current working directory to build.
2015-04-08 18:13:45,618 INFO  io.prediction.tools.console.Console$ [main] - If the path above is incorrect, this process will fail.
2015-04-08 18:13:45,619 INFO  io.prediction.tools.console.Console$ [main] - Uber JAR disabled. Making sure lib/pio-assembly-0.9.1.jar is absent.
2015-04-08 18:13:45,619 INFO  io.prediction.tools.console.Console$ [main] - Going to run: /Users/Marco/PredictionIO/sbt/sbt  package assemblyPackageDependency
2015-04-08 18:13:54,510 INFO  io.prediction.tools.console.Console$ [main] - Build finished successfully.
2015-04-08 18:13:54,510 INFO  io.prediction.tools.console.Console$ [main] - Looking for an engine...
2015-04-08 18:13:54,518 INFO  io.prediction.tools.console.Console$ [main] - Found SemanticAnalysis-assembly-1.0-deps.jar
2015-04-08 18:13:54,519 INFO  io.prediction.tools.console.Console$ [main] - Found semanticanalysis_2.10-1.0.jar
2015-04-08 18:13:54,526 INFO  io.prediction.tools.console.Console$ [main] - HADOOP_CONF_DIR is not set. Assuming HDFS is unavailable.
2015-04-08 18:13:56,237 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-08 18:13:56,341 INFO  io.prediction.tools.RegisterEngine$ [main] - Copying file:/Users/Marco/SemanticAnalysisRepo/SemanticAnalysis/target/scala-2.10/SemanticAnalysis-assembly-1.0-deps.jar to file:/Users/Marco/.pio_store/engines/IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I/1601d4b44276e463819ccf16bcea2e968082ad77/SemanticAnalysis-assembly-1.0-deps.jar
2015-04-08 18:13:56,421 INFO  io.prediction.tools.RegisterEngine$ [main] - Copying file:/Users/Marco/SemanticAnalysisRepo/SemanticAnalysis/target/scala-2.10/semanticanalysis_2.10-1.0.jar to file:/Users/Marco/.pio_store/engines/IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I/1601d4b44276e463819ccf16bcea2e968082ad77/semanticanalysis_2.10-1.0.jar
2015-04-08 18:13:56,434 INFO  io.prediction.tools.RegisterEngine$ [main] - Registering engine IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I 1601d4b44276e463819ccf16bcea2e968082ad77
2015-04-08 18:13:56,457 INFO  io.prediction.tools.console.Console$ [main] - Your engine is ready for training.
2015-04-08 18:14:04,774 INFO  io.prediction.tools.console.App$ [main] -                 Name |   ID |                                                       Access Key | Allowed Event(s)
2015-04-08 18:14:04,859 INFO  io.prediction.tools.console.App$ [main] -               MyApp1 |    2 | rhAkDKWBw3tkypnGYlnb4K5QQFDRotSOA0EAOyQCUUsfW4BDH7jlwj4dWzmZ15Lq | (all)
2015-04-08 18:14:04,868 INFO  io.prediction.tools.console.App$ [main] - SemAnalysisApp-Marco |    1 | Hw8uK9u8j3C3Tuvu9Ce1YNIjhggQnXXUyPzxdqyqKPgaiT2Dz444hrNrcz4Bg8qM | (all)
2015-04-08 18:14:04,887 INFO  io.prediction.tools.console.App$ [main] -             TestApp3 |    3 | VcclTlUqfD7nbqPCCQY9dsnQm3VhUtw4JyUlwBJaAtLraA2RQfaLWBUxofAPr0o9 | (all)
2015-04-08 18:14:04,906 INFO  io.prediction.tools.console.App$ [main] -         TestApp50000 |    4 | H3qQ0peaL3MRu289hZNVtHxS3jXlBC303l59CcqQi9DRU0LSWCPU3SCBIEgRGDpa | (all)
2015-04-08 18:14:04,907 INFO  io.prediction.tools.console.App$ [main] - Finished listing 4 app(s).
2015-04-08 18:14:31,758 INFO  io.prediction.tools.console.Console$ [main] - Using existing engine manifest JSON at /Users/Marco/SemanticAnalysisRepo/SemanticAnalysis/manifest.json
2015-04-08 18:14:31,810 INFO  io.prediction.tools.console.Console$ [main] - Using command '/Users/Marco/PredictionIO/sbt/sbt' at the current working directory to build.
2015-04-08 18:14:31,811 INFO  io.prediction.tools.console.Console$ [main] - If the path above is incorrect, this process will fail.
2015-04-08 18:14:31,813 INFO  io.prediction.tools.console.Console$ [main] - Uber JAR disabled. Making sure lib/pio-assembly-0.9.1.jar is absent.
2015-04-08 18:14:31,813 INFO  io.prediction.tools.console.Console$ [main] - Going to run: /Users/Marco/PredictionIO/sbt/sbt  package assemblyPackageDependency
2015-04-08 18:14:38,528 INFO  io.prediction.tools.console.Console$ [main] - Build finished successfully.
2015-04-08 18:14:38,529 INFO  io.prediction.tools.console.Console$ [main] - Looking for an engine...
2015-04-08 18:14:38,535 INFO  io.prediction.tools.console.Console$ [main] - Found SemanticAnalysis-assembly-1.0-deps.jar
2015-04-08 18:14:38,535 INFO  io.prediction.tools.console.Console$ [main] - Found semanticanalysis_2.10-1.0.jar
2015-04-08 18:14:38,543 INFO  io.prediction.tools.console.Console$ [main] - HADOOP_CONF_DIR is not set. Assuming HDFS is unavailable.
2015-04-08 18:14:40,178 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-08 18:14:40,292 INFO  io.prediction.tools.RegisterEngine$ [main] - Copying file:/Users/Marco/SemanticAnalysisRepo/SemanticAnalysis/target/scala-2.10/SemanticAnalysis-assembly-1.0-deps.jar to file:/Users/Marco/.pio_store/engines/IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I/1601d4b44276e463819ccf16bcea2e968082ad77/SemanticAnalysis-assembly-1.0-deps.jar
2015-04-08 18:14:40,366 INFO  io.prediction.tools.RegisterEngine$ [main] - Copying file:/Users/Marco/SemanticAnalysisRepo/SemanticAnalysis/target/scala-2.10/semanticanalysis_2.10-1.0.jar to file:/Users/Marco/.pio_store/engines/IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I/1601d4b44276e463819ccf16bcea2e968082ad77/semanticanalysis_2.10-1.0.jar
2015-04-08 18:14:40,381 INFO  io.prediction.tools.RegisterEngine$ [main] - Registering engine IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I 1601d4b44276e463819ccf16bcea2e968082ad77
2015-04-08 18:14:40,402 INFO  io.prediction.tools.console.Console$ [main] - Your engine is ready for training.
2015-04-08 18:14:43,863 INFO  io.prediction.tools.console.Console$ [main] - Using existing engine manifest JSON at /Users/Marco/SemanticAnalysisRepo/SemanticAnalysis/manifest.json
2015-04-08 18:14:45,559 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-08 18:14:45,685 INFO  io.prediction.tools.RunWorkflow$ [main] - Submission command: /Users/Marco/../../usr/local/Cellar/apache-spark/1.3.0//bin/spark-submit --class io.prediction.workflow.CreateWorkflow --name PredictionIO Training: IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I 1601d4b44276e463819ccf16bcea2e968082ad77 () --jars file:/Users/Marco/.pio_store/engines/IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I/1601d4b44276e463819ccf16bcea2e968082ad77/semanticanalysis_2.10-1.0.jar,file:/Users/Marco/.pio_store/engines/IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I/1601d4b44276e463819ccf16bcea2e968082ad77/SemanticAnalysis-assembly-1.0-deps.jar --files /Users/Marco/PredictionIO/conf/log4j.properties,/Users/Marco/PredictionIO/vendors/hbase-0.98.11/conf/hbase-site.xml --driver-class-path /Users/Marco/PredictionIO/conf:/Users/Marco/PredictionIO/vendors/hbase-0.98.11/conf /Users/Marco/PredictionIO/lib/pio-assembly-0.9.1.jar --env PIO_STORAGE_SOURCES_HBASE_TYPE=hbase,PIO_ENV_LOADED=1,PIO_STORAGE_SOURCES_HBASE_HOSTS=0,PIO_STORAGE_REPOSITORIES_METADATA_NAME=predictionio_metadata,PIO_FS_BASEDIR=/Users/Marco/.pio_store,PIO_STORAGE_SOURCES_ELASTICSEARCH_HOSTS=localhost,PIO_STORAGE_SOURCES_HBASE_HOME=/Users/Marco/PredictionIO/vendors/hbase-0.98.11,PIO_HOME=/Users/Marco/PredictionIO,PIO_FS_ENGINESDIR=/Users/Marco/.pio_store/engines,PIO_STORAGE_SOURCES_HBASE_PORTS=0,PIO_STORAGE_SOURCES_ELASTICSEARCH_TYPE=elasticsearch,PIO_STORAGE_REPOSITORIES_METADATA_SOURCE=ELASTICSEARCH,PIO_STORAGE_REPOSITORIES_MODELDATA_SOURCE=LOCALFS,PIO_STORAGE_REPOSITORIES_EVENTDATA_NAME=predictionio_eventdata,PIO_STORAGE_SOURCES_ELASTICSEARCH_HOME=/Users/Marco/PredictionIO/vendors/elasticsearch-1.4.4,PIO_FS_TMPDIR=/Users/Marco/.pio_store/tmp,PIO_STORAGE_REPOSITORIES_MODELDATA_NAME=pio_,PIO_STORAGE_SOURCES_LOCALFS_HOSTS=/Users/Marco/.pio_store/models,PIO_STORAGE_REPOSITORIES_EVENTDATA_SOURCE=HBASE,PIO_CONF_DIR=/Users/Marco/PredictionIO/conf,PIO_STORAGE_SOURCES_LOCALFS_PORTS=0,PIO_STORAGE_SOURCES_ELASTICSEARCH_PORTS=9300,PIO_STORAGE_SOURCES_LOCALFS_TYPE=localfs --engine-id IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I --engine-version 1601d4b44276e463819ccf16bcea2e968082ad77 --engine-variant /Users/Marco/SemanticAnalysisRepo/SemanticAnalysis/engine.json --verbosity 0
2015-04-08 18:14:47,539 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-08 18:14:48,390 INFO  io.prediction.controller.Engine [main] - Extracting datasource params...
2015-04-08 18:14:48,477 INFO  io.prediction.workflow.WorkflowUtils$ [main] - No 'name' is found. Default empty String will be used.
2015-04-08 18:14:48,489 INFO  io.prediction.controller.Engine [main] - Datasource params: (,DataSourceParams(4))
2015-04-08 18:14:48,490 INFO  io.prediction.controller.Engine [main] - Extracting preparator params...
2015-04-08 18:14:48,492 INFO  io.prediction.controller.Engine [main] - Preparator params: (,Empty)
2015-04-08 18:14:48,497 INFO  io.prediction.controller.Engine [main] - Extracting serving params...
2015-04-08 18:14:48,498 INFO  io.prediction.controller.Engine [main] - Serving params: (,Empty)
2015-04-08 18:14:50,076 INFO  Remoting [sparkDriver-akka.actor.default-dispatcher-3] - Starting remoting
2015-04-08 18:14:50,257 INFO  Remoting [sparkDriver-akka.actor.default-dispatcher-3] - Remoting started; listening on addresses :[akka.tcp://sparkDriver@10.0.22.139:57973]
2015-04-08 18:14:50,427 INFO  org.spark-project.jetty.server.Server [main] - jetty-8.y.z-SNAPSHOT
2015-04-08 18:14:50,443 INFO  org.spark-project.jetty.server.AbstractConnector [main] - Started SocketConnector@0.0.0.0:57974
2015-04-08 18:14:50,563 INFO  org.spark-project.jetty.server.Server [main] - jetty-8.y.z-SNAPSHOT
2015-04-08 18:14:50,575 INFO  org.spark-project.jetty.server.AbstractConnector [main] - Started SelectChannelConnector@0.0.0.0:4040
2015-04-08 18:14:51,317 INFO  io.prediction.controller.Engine$ [main] - EngineWorkflow.train
2015-04-08 18:14:51,318 INFO  io.prediction.controller.Engine$ [main] - DataSource: SemanticAnalysis.DataSource@d13960e
2015-04-08 18:14:51,319 INFO  io.prediction.controller.Engine$ [main] - Preparator: SemanticAnalysis.Preparator@3946075
2015-04-08 18:14:51,320 INFO  io.prediction.controller.Engine$ [main] - AlgorithmList: List(SemanticAnalysis.Algorithm@3d53e6f7)
2015-04-08 18:14:51,321 INFO  io.prediction.controller.Engine$ [main] - Data santiy check is on.
2015-04-08 18:14:52,521 INFO  io.prediction.controller.Engine$ [main] - SemanticAnalysis.TrainingData does not support data sanity check. Skipping check.
2015-04-08 18:14:52,522 INFO  io.prediction.controller.Engine$ [main] - SemanticAnalysis.PreparedData does not support data sanity check. Skipping check.
2015-04-08 18:14:52,659 WARN  org.apache.hadoop.hbase.mapreduce.TableInputFormatBase [main] - Cannot resolve the host name for /10.0.22.139 because of javax.naming.NameNotFoundException: DNS name not found [response code 3]; remaining name '139.22.0.10.in-addr.arpa'
2015-04-08 18:14:59,355 INFO  org.spark-project.jetty.server.handler.ContextHandler [main] - stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
2015-04-08 18:14:59,355 INFO  org.spark-project.jetty.server.handler.ContextHandler [main] - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-04-08 18:14:59,355 INFO  org.spark-project.jetty.server.handler.ContextHandler [main] - stopped o.s.j.s.ServletContextHandler{/,null}
2015-04-08 18:14:59,356 INFO  org.spark-project.jetty.server.handler.ContextHandler [main] - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-04-08 18:14:59,356 INFO  org.spark-project.jetty.server.handler.ContextHandler [main] - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-04-08 18:14:59,356 INFO  org.spark-project.jetty.server.handler.ContextHandler [main] - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-04-08 18:14:59,356 INFO  org.spark-project.jetty.server.handler.ContextHandler [main] - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-04-08 18:14:59,356 INFO  org.spark-project.jetty.server.handler.ContextHandler [main] - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-04-08 18:14:59,356 INFO  org.spark-project.jetty.server.handler.ContextHandler [main] - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-04-08 18:14:59,356 INFO  org.spark-project.jetty.server.handler.ContextHandler [main] - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-04-08 18:14:59,356 INFO  org.spark-project.jetty.server.handler.ContextHandler [main] - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-04-08 18:14:59,356 INFO  org.spark-project.jetty.server.handler.ContextHandler [main] - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-04-08 18:14:59,356 INFO  org.spark-project.jetty.server.handler.ContextHandler [main] - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-04-08 18:14:59,357 INFO  org.spark-project.jetty.server.handler.ContextHandler [main] - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-04-08 18:14:59,357 INFO  org.spark-project.jetty.server.handler.ContextHandler [main] - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-04-08 18:14:59,357 INFO  org.spark-project.jetty.server.handler.ContextHandler [main] - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-04-08 18:14:59,357 INFO  org.spark-project.jetty.server.handler.ContextHandler [main] - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-04-08 18:14:59,357 INFO  org.spark-project.jetty.server.handler.ContextHandler [main] - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-04-08 18:14:59,357 INFO  org.spark-project.jetty.server.handler.ContextHandler [main] - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-04-08 18:14:59,358 INFO  org.spark-project.jetty.server.handler.ContextHandler [main] - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-04-08 18:14:59,358 INFO  org.spark-project.jetty.server.handler.ContextHandler [main] - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-04-08 18:14:59,358 INFO  org.spark-project.jetty.server.handler.ContextHandler [main] - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-04-08 18:14:59,358 INFO  org.spark-project.jetty.server.handler.ContextHandler [main] - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-04-08 18:14:59,359 INFO  org.spark-project.jetty.server.handler.ContextHandler [main] - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-04-08 18:21:15,873 INFO  io.prediction.tools.console.Console$ [main] - Using existing engine manifest JSON at /Users/Marco/SemanticAnalysisRepo/SemanticAnalysis/manifest.json
2015-04-08 18:21:16,109 INFO  io.prediction.tools.console.Console$ [main] - Using command '/Users/Marco/PredictionIO/sbt/sbt' at the current working directory to build.
2015-04-08 18:21:16,113 INFO  io.prediction.tools.console.Console$ [main] - If the path above is incorrect, this process will fail.
2015-04-08 18:21:16,117 INFO  io.prediction.tools.console.Console$ [main] - Uber JAR disabled. Making sure lib/pio-assembly-0.9.1.jar is absent.
2015-04-08 18:21:16,119 INFO  io.prediction.tools.console.Console$ [main] - Going to run: /Users/Marco/PredictionIO/sbt/sbt  package assemblyPackageDependency
2015-04-08 18:22:03,770 INFO  io.prediction.tools.console.Console$ [main] - Build finished successfully.
2015-04-08 18:22:03,772 INFO  io.prediction.tools.console.Console$ [main] - Looking for an engine...
2015-04-08 18:22:03,801 INFO  io.prediction.tools.console.Console$ [main] - Found SemanticAnalysis-assembly-1.0-deps.jar
2015-04-08 18:22:03,801 INFO  io.prediction.tools.console.Console$ [main] - Found semanticanalysis_2.10-1.0.jar
2015-04-08 18:22:03,835 INFO  io.prediction.tools.console.Console$ [main] - HADOOP_CONF_DIR is not set. Assuming HDFS is unavailable.
2015-04-08 18:22:09,459 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-08 18:22:09,800 INFO  io.prediction.tools.RegisterEngine$ [main] - Copying file:/Users/Marco/SemanticAnalysisRepo/SemanticAnalysis/target/scala-2.10/SemanticAnalysis-assembly-1.0-deps.jar to file:/Users/Marco/.pio_store/engines/IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I/1601d4b44276e463819ccf16bcea2e968082ad77/SemanticAnalysis-assembly-1.0-deps.jar
2015-04-08 18:22:10,040 INFO  io.prediction.tools.RegisterEngine$ [main] - Copying file:/Users/Marco/SemanticAnalysisRepo/SemanticAnalysis/target/scala-2.10/semanticanalysis_2.10-1.0.jar to file:/Users/Marco/.pio_store/engines/IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I/1601d4b44276e463819ccf16bcea2e968082ad77/semanticanalysis_2.10-1.0.jar
2015-04-08 18:22:10,104 INFO  io.prediction.tools.RegisterEngine$ [main] - Registering engine IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I 1601d4b44276e463819ccf16bcea2e968082ad77
2015-04-08 18:22:10,206 INFO  io.prediction.tools.console.Console$ [main] - Your engine is ready for training.
2015-04-08 18:22:15,836 INFO  io.prediction.tools.console.Console$ [main] - Using existing engine manifest JSON at /Users/Marco/SemanticAnalysisRepo/SemanticAnalysis/manifest.json
2015-04-08 18:22:21,636 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-08 18:22:22,008 INFO  io.prediction.tools.RunWorkflow$ [main] - Submission command: /Users/Marco/../../usr/local/Cellar/apache-spark/1.3.0//bin/spark-submit --class io.prediction.workflow.CreateWorkflow --name PredictionIO Training: IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I 1601d4b44276e463819ccf16bcea2e968082ad77 () --jars file:/Users/Marco/.pio_store/engines/IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I/1601d4b44276e463819ccf16bcea2e968082ad77/semanticanalysis_2.10-1.0.jar,file:/Users/Marco/.pio_store/engines/IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I/1601d4b44276e463819ccf16bcea2e968082ad77/SemanticAnalysis-assembly-1.0-deps.jar --files /Users/Marco/PredictionIO/conf/log4j.properties,/Users/Marco/PredictionIO/vendors/hbase-0.98.11/conf/hbase-site.xml --driver-class-path /Users/Marco/PredictionIO/conf:/Users/Marco/PredictionIO/vendors/hbase-0.98.11/conf /Users/Marco/PredictionIO/lib/pio-assembly-0.9.1.jar --env PIO_STORAGE_SOURCES_HBASE_TYPE=hbase,PIO_ENV_LOADED=1,PIO_STORAGE_SOURCES_HBASE_HOSTS=0,PIO_STORAGE_REPOSITORIES_METADATA_NAME=predictionio_metadata,PIO_FS_BASEDIR=/Users/Marco/.pio_store,PIO_STORAGE_SOURCES_ELASTICSEARCH_HOSTS=localhost,PIO_STORAGE_SOURCES_HBASE_HOME=/Users/Marco/PredictionIO/vendors/hbase-0.98.11,PIO_HOME=/Users/Marco/PredictionIO,PIO_FS_ENGINESDIR=/Users/Marco/.pio_store/engines,PIO_STORAGE_SOURCES_HBASE_PORTS=0,PIO_STORAGE_SOURCES_ELASTICSEARCH_TYPE=elasticsearch,PIO_STORAGE_REPOSITORIES_METADATA_SOURCE=ELASTICSEARCH,PIO_STORAGE_REPOSITORIES_MODELDATA_SOURCE=LOCALFS,PIO_STORAGE_REPOSITORIES_EVENTDATA_NAME=predictionio_eventdata,PIO_STORAGE_SOURCES_ELASTICSEARCH_HOME=/Users/Marco/PredictionIO/vendors/elasticsearch-1.4.4,PIO_FS_TMPDIR=/Users/Marco/.pio_store/tmp,PIO_STORAGE_REPOSITORIES_MODELDATA_NAME=pio_,PIO_STORAGE_SOURCES_LOCALFS_HOSTS=/Users/Marco/.pio_store/models,PIO_STORAGE_REPOSITORIES_EVENTDATA_SOURCE=HBASE,PIO_CONF_DIR=/Users/Marco/PredictionIO/conf,PIO_STORAGE_SOURCES_LOCALFS_PORTS=0,PIO_STORAGE_SOURCES_ELASTICSEARCH_PORTS=9300,PIO_STORAGE_SOURCES_LOCALFS_TYPE=localfs --engine-id IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I --engine-version 1601d4b44276e463819ccf16bcea2e968082ad77 --engine-variant /Users/Marco/SemanticAnalysisRepo/SemanticAnalysis/engine.json --verbosity 0
2015-04-08 18:22:28,075 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-08 18:22:30,911 INFO  io.prediction.controller.Engine [main] - Extracting datasource params...
2015-04-08 18:22:31,154 INFO  io.prediction.workflow.WorkflowUtils$ [main] - No 'name' is found. Default empty String will be used.
2015-04-08 18:22:31,192 INFO  io.prediction.controller.Engine [main] - Datasource params: (,DataSourceParams(4))
2015-04-08 18:22:31,193 INFO  io.prediction.controller.Engine [main] - Extracting preparator params...
2015-04-08 18:22:31,200 INFO  io.prediction.controller.Engine [main] - Preparator params: (,Empty)
2015-04-08 18:22:31,220 INFO  io.prediction.controller.Engine [main] - Extracting serving params...
2015-04-08 18:22:31,222 INFO  io.prediction.controller.Engine [main] - Serving params: (,Empty)
2015-04-08 18:22:36,905 INFO  Remoting [sparkDriver-akka.actor.default-dispatcher-3] - Starting remoting
2015-04-08 18:22:37,481 INFO  Remoting [sparkDriver-akka.actor.default-dispatcher-3] - Remoting started; listening on addresses :[akka.tcp://sparkDriver@10.0.22.139:58088]
2015-04-08 18:22:38,032 INFO  org.spark-project.jetty.server.Server [main] - jetty-8.y.z-SNAPSHOT
2015-04-08 18:22:38,105 INFO  org.spark-project.jetty.server.AbstractConnector [main] - Started SocketConnector@0.0.0.0:58089
2015-04-08 18:22:38,476 INFO  org.spark-project.jetty.server.Server [main] - jetty-8.y.z-SNAPSHOT
2015-04-08 18:22:38,517 INFO  org.spark-project.jetty.server.AbstractConnector [main] - Started SelectChannelConnector@0.0.0.0:4040
2015-04-08 18:22:40,822 INFO  io.prediction.controller.Engine$ [main] - EngineWorkflow.train
2015-04-08 18:22:40,825 INFO  io.prediction.controller.Engine$ [main] - DataSource: SemanticAnalysis.DataSource@5403799b
2015-04-08 18:22:40,827 INFO  io.prediction.controller.Engine$ [main] - Preparator: SemanticAnalysis.Preparator@4293e066
2015-04-08 18:22:40,829 INFO  io.prediction.controller.Engine$ [main] - AlgorithmList: List(SemanticAnalysis.Algorithm@5e593b08)
2015-04-08 18:22:40,830 INFO  io.prediction.controller.Engine$ [main] - Data santiy check is on.
2015-04-08 18:22:44,397 INFO  io.prediction.controller.Engine$ [main] - SemanticAnalysis.TrainingData does not support data sanity check. Skipping check.
2015-04-08 18:22:44,401 INFO  io.prediction.controller.Engine$ [main] - SemanticAnalysis.PreparedData does not support data sanity check. Skipping check.
2015-04-08 18:22:44,767 WARN  org.apache.hadoop.hbase.mapreduce.TableInputFormatBase [main] - Cannot resolve the host name for /10.0.22.139 because of javax.naming.NameNotFoundException: DNS name not found [response code 3]; remaining name '139.22.0.10.in-addr.arpa'
2015-04-08 18:24:19,925 WARN  org.apache.hadoop.hbase.client.ScannerCallable [Executor task launch worker-0] - Ignore, probably already closed
org.apache.hadoop.hbase.ipc.RemoteWithExtrasException(org.apache.hadoop.hbase.UnknownScannerException): org.apache.hadoop.hbase.UnknownScannerException: Name: 59, already closed?
	at org.apache.hadoop.hbase.regionserver.HRegionServer.scan(HRegionServer.java:3183)
	at org.apache.hadoop.hbase.protobuf.generated.ClientProtos$ClientService$2.callBlockingMethod(ClientProtos.java:30808)
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:2029)
	at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:107)
	at org.apache.hadoop.hbase.ipc.RpcExecutor.consumerLoop(RpcExecutor.java:130)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$1.run(RpcExecutor.java:107)
	at java.lang.Thread.run(Thread.java:695)

	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1457)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1661)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1719)
	at org.apache.hadoop.hbase.protobuf.generated.ClientProtos$ClientService$BlockingStub.scan(ClientProtos.java:29990)
	at org.apache.hadoop.hbase.client.ScannerCallable.close(ScannerCallable.java:291)
	at org.apache.hadoop.hbase.client.ScannerCallable.call(ScannerCallable.java:160)
	at org.apache.hadoop.hbase.client.ScannerCallable.call(ScannerCallable.java:59)
	at org.apache.hadoop.hbase.client.RpcRetryingCaller.callWithRetries(RpcRetryingCaller.java:114)
	at org.apache.hadoop.hbase.client.RpcRetryingCaller.callWithRetries(RpcRetryingCaller.java:90)
	at org.apache.hadoop.hbase.client.ClientScanner.close(ClientScanner.java:450)
	at org.apache.hadoop.hbase.mapreduce.TableRecordReaderImpl.restart(TableRecordReaderImpl.java:88)
	at org.apache.hadoop.hbase.mapreduce.TableRecordReaderImpl.nextKeyValue(TableRecordReaderImpl.java:229)
	at org.apache.hadoop.hbase.mapreduce.TableRecordReader.nextKeyValue(TableRecordReader.java:138)
	at org.apache.spark.rdd.NewHadoopRDD$$anon$1.hasNext(NewHadoopRDD.scala:143)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:39)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:327)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:327)
	at scala.collection.Iterator$$anon$14.hasNext(Iterator.scala:388)
	at scala.collection.Iterator$$anon$14.hasNext(Iterator.scala:388)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:327)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:327)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:202)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:56)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:68)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:64)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:203)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-04-08 18:25:25,021 WARN  org.apache.hadoop.hbase.client.ScannerCallable [Executor task launch worker-0] - Ignore, probably already closed
org.apache.hadoop.hbase.ipc.RemoteWithExtrasException(org.apache.hadoop.hbase.UnknownScannerException): org.apache.hadoop.hbase.UnknownScannerException: Name: 60, already closed?
	at org.apache.hadoop.hbase.regionserver.HRegionServer.scan(HRegionServer.java:3183)
	at org.apache.hadoop.hbase.protobuf.generated.ClientProtos$ClientService$2.callBlockingMethod(ClientProtos.java:30808)
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:2029)
	at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:107)
	at org.apache.hadoop.hbase.ipc.RpcExecutor.consumerLoop(RpcExecutor.java:130)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$1.run(RpcExecutor.java:107)
	at java.lang.Thread.run(Thread.java:695)

	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1457)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1661)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1719)
	at org.apache.hadoop.hbase.protobuf.generated.ClientProtos$ClientService$BlockingStub.scan(ClientProtos.java:29990)
	at org.apache.hadoop.hbase.client.ScannerCallable.close(ScannerCallable.java:291)
	at org.apache.hadoop.hbase.client.ScannerCallable.call(ScannerCallable.java:160)
	at org.apache.hadoop.hbase.client.ScannerCallable.call(ScannerCallable.java:59)
	at org.apache.hadoop.hbase.client.RpcRetryingCaller.callWithRetries(RpcRetryingCaller.java:114)
	at org.apache.hadoop.hbase.client.RpcRetryingCaller.callWithRetries(RpcRetryingCaller.java:90)
	at org.apache.hadoop.hbase.client.ClientScanner.close(ClientScanner.java:450)
	at org.apache.hadoop.hbase.mapreduce.TableRecordReaderImpl.restart(TableRecordReaderImpl.java:88)
	at org.apache.hadoop.hbase.mapreduce.TableRecordReaderImpl.nextKeyValue(TableRecordReaderImpl.java:229)
	at org.apache.hadoop.hbase.mapreduce.TableRecordReader.nextKeyValue(TableRecordReader.java:138)
	at org.apache.spark.rdd.NewHadoopRDD$$anon$1.hasNext(NewHadoopRDD.scala:143)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:39)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:327)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:327)
	at scala.collection.Iterator$$anon$14.hasNext(Iterator.scala:388)
	at scala.collection.Iterator$$anon$14.hasNext(Iterator.scala:388)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:327)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:327)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:202)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:56)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:68)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:64)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:203)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-04-08 18:26:30,614 WARN  org.apache.hadoop.hbase.client.ScannerCallable [Executor task launch worker-0] - Ignore, probably already closed
org.apache.hadoop.hbase.ipc.RemoteWithExtrasException(org.apache.hadoop.hbase.UnknownScannerException): org.apache.hadoop.hbase.UnknownScannerException: Name: 61, already closed?
	at org.apache.hadoop.hbase.regionserver.HRegionServer.scan(HRegionServer.java:3183)
	at org.apache.hadoop.hbase.protobuf.generated.ClientProtos$ClientService$2.callBlockingMethod(ClientProtos.java:30808)
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:2029)
	at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:107)
	at org.apache.hadoop.hbase.ipc.RpcExecutor.consumerLoop(RpcExecutor.java:130)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$1.run(RpcExecutor.java:107)
	at java.lang.Thread.run(Thread.java:695)

	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1457)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1661)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1719)
	at org.apache.hadoop.hbase.protobuf.generated.ClientProtos$ClientService$BlockingStub.scan(ClientProtos.java:29990)
	at org.apache.hadoop.hbase.client.ScannerCallable.close(ScannerCallable.java:291)
	at org.apache.hadoop.hbase.client.ScannerCallable.call(ScannerCallable.java:160)
	at org.apache.hadoop.hbase.client.ScannerCallable.call(ScannerCallable.java:59)
	at org.apache.hadoop.hbase.client.RpcRetryingCaller.callWithRetries(RpcRetryingCaller.java:114)
	at org.apache.hadoop.hbase.client.RpcRetryingCaller.callWithRetries(RpcRetryingCaller.java:90)
	at org.apache.hadoop.hbase.client.ClientScanner.close(ClientScanner.java:450)
	at org.apache.hadoop.hbase.mapreduce.TableRecordReaderImpl.restart(TableRecordReaderImpl.java:88)
	at org.apache.hadoop.hbase.mapreduce.TableRecordReaderImpl.nextKeyValue(TableRecordReaderImpl.java:229)
	at org.apache.hadoop.hbase.mapreduce.TableRecordReader.nextKeyValue(TableRecordReader.java:138)
	at org.apache.spark.rdd.NewHadoopRDD$$anon$1.hasNext(NewHadoopRDD.scala:143)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:39)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:327)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:327)
	at scala.collection.Iterator$$anon$14.hasNext(Iterator.scala:388)
	at scala.collection.Iterator$$anon$14.hasNext(Iterator.scala:388)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:327)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:327)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:202)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:56)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:68)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:64)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:203)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-04-08 18:55:23,782 INFO  io.prediction.controller.Engine$ [main] - SemanticAnalysis.Model does not support data sanity check. Skipping check.
2015-04-08 18:55:23,783 INFO  io.prediction.controller.Engine$ [main] - EngineWorkflow.train completed
2015-04-08 18:55:23,784 INFO  io.prediction.controller.Engine [main] - engineInstanceId=AUybxYNRi7z9HxmsiEkS
2015-04-08 18:55:23,797 INFO  io.prediction.workflow.CoreWorkflow$ [main] - Inserting persistent model
2015-04-08 18:55:24,395 INFO  io.prediction.workflow.CoreWorkflow$ [main] - Updating engine instance
2015-04-08 18:55:24,417 INFO  io.prediction.workflow.CoreWorkflow$ [main] - Training completed successfully.
2015-04-08 18:55:24,433 INFO  org.spark-project.jetty.server.handler.ContextHandler [main] - stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
2015-04-08 18:55:24,433 INFO  org.spark-project.jetty.server.handler.ContextHandler [main] - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-04-08 18:55:24,433 INFO  org.spark-project.jetty.server.handler.ContextHandler [main] - stopped o.s.j.s.ServletContextHandler{/,null}
2015-04-08 18:55:24,433 INFO  org.spark-project.jetty.server.handler.ContextHandler [main] - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-04-08 18:55:24,433 INFO  org.spark-project.jetty.server.handler.ContextHandler [main] - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-04-08 18:55:24,434 INFO  org.spark-project.jetty.server.handler.ContextHandler [main] - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-04-08 18:55:24,434 INFO  org.spark-project.jetty.server.handler.ContextHandler [main] - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-04-08 18:55:24,434 INFO  org.spark-project.jetty.server.handler.ContextHandler [main] - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-04-08 18:55:24,434 INFO  org.spark-project.jetty.server.handler.ContextHandler [main] - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-04-08 18:55:24,434 INFO  org.spark-project.jetty.server.handler.ContextHandler [main] - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-04-08 18:55:24,434 INFO  org.spark-project.jetty.server.handler.ContextHandler [main] - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-04-08 18:55:24,434 INFO  org.spark-project.jetty.server.handler.ContextHandler [main] - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-04-08 18:55:24,434 INFO  org.spark-project.jetty.server.handler.ContextHandler [main] - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-04-08 18:55:24,435 INFO  org.spark-project.jetty.server.handler.ContextHandler [main] - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-04-08 18:55:24,435 INFO  org.spark-project.jetty.server.handler.ContextHandler [main] - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-04-08 18:55:24,435 INFO  org.spark-project.jetty.server.handler.ContextHandler [main] - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-04-08 18:55:24,435 INFO  org.spark-project.jetty.server.handler.ContextHandler [main] - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-04-08 18:55:24,435 INFO  org.spark-project.jetty.server.handler.ContextHandler [main] - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-04-08 18:55:24,435 INFO  org.spark-project.jetty.server.handler.ContextHandler [main] - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-04-08 18:55:24,435 INFO  org.spark-project.jetty.server.handler.ContextHandler [main] - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-04-08 18:55:24,435 INFO  org.spark-project.jetty.server.handler.ContextHandler [main] - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-04-08 18:55:24,436 INFO  org.spark-project.jetty.server.handler.ContextHandler [main] - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-04-08 18:55:24,436 INFO  org.spark-project.jetty.server.handler.ContextHandler [main] - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-04-08 18:55:24,436 INFO  org.spark-project.jetty.server.handler.ContextHandler [main] - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-04-09 10:35:21,292 INFO  io.prediction.tools.console.Console$ [main] - Using existing engine manifest JSON at /Users/Marco/SemanticAnalysisRepo/SemanticAnalysis/manifest.json
2015-04-09 10:35:21,345 INFO  io.prediction.tools.console.Console$ [main] - Using command '/Users/Marco/PredictionIO/sbt/sbt' at the current working directory to build.
2015-04-09 10:35:21,346 INFO  io.prediction.tools.console.Console$ [main] - If the path above is incorrect, this process will fail.
2015-04-09 10:35:21,349 INFO  io.prediction.tools.console.Console$ [main] - Uber JAR disabled. Making sure lib/pio-assembly-0.9.1.jar is absent.
2015-04-09 10:35:21,350 INFO  io.prediction.tools.console.Console$ [main] - Going to run: /Users/Marco/PredictionIO/sbt/sbt  package assemblyPackageDependency
2015-04-09 10:35:36,686 INFO  io.prediction.tools.console.Console$ [main] - Build finished successfully.
2015-04-09 10:35:36,687 INFO  io.prediction.tools.console.Console$ [main] - Looking for an engine...
2015-04-09 10:35:36,696 INFO  io.prediction.tools.console.Console$ [main] - Found SemanticAnalysis-assembly-1.0-deps.jar
2015-04-09 10:35:36,696 INFO  io.prediction.tools.console.Console$ [main] - Found semanticanalysis_2.10-1.0.jar
2015-04-09 10:35:36,708 INFO  io.prediction.tools.console.Console$ [main] - HADOOP_CONF_DIR is not set. Assuming HDFS is unavailable.
2015-04-09 10:35:38,841 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-09 10:35:38,969 INFO  io.prediction.tools.RegisterEngine$ [main] - Copying file:/Users/Marco/SemanticAnalysisRepo/SemanticAnalysis/target/scala-2.10/SemanticAnalysis-assembly-1.0-deps.jar to file:/Users/Marco/.pio_store/engines/IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I/1601d4b44276e463819ccf16bcea2e968082ad77/SemanticAnalysis-assembly-1.0-deps.jar
2015-04-09 10:35:39,052 INFO  io.prediction.tools.RegisterEngine$ [main] - Copying file:/Users/Marco/SemanticAnalysisRepo/SemanticAnalysis/target/scala-2.10/semanticanalysis_2.10-1.0.jar to file:/Users/Marco/.pio_store/engines/IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I/1601d4b44276e463819ccf16bcea2e968082ad77/semanticanalysis_2.10-1.0.jar
2015-04-09 10:35:39,071 INFO  io.prediction.tools.RegisterEngine$ [main] - Registering engine IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I 1601d4b44276e463819ccf16bcea2e968082ad77
2015-04-09 10:35:39,115 INFO  io.prediction.tools.console.Console$ [main] - Your engine is ready for training.
2015-04-09 10:35:43,392 INFO  io.prediction.tools.console.Console$ [main] - Using existing engine manifest JSON at /Users/Marco/SemanticAnalysisRepo/SemanticAnalysis/manifest.json
2015-04-09 10:35:45,105 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-09 10:35:45,293 INFO  io.prediction.tools.RunWorkflow$ [main] - Submission command: /Users/Marco/../../usr/local/Cellar/apache-spark/1.3.0//bin/spark-submit --class io.prediction.workflow.CreateWorkflow --name PredictionIO Training: IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I 1601d4b44276e463819ccf16bcea2e968082ad77 () --jars file:/Users/Marco/.pio_store/engines/IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I/1601d4b44276e463819ccf16bcea2e968082ad77/semanticanalysis_2.10-1.0.jar,file:/Users/Marco/.pio_store/engines/IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I/1601d4b44276e463819ccf16bcea2e968082ad77/SemanticAnalysis-assembly-1.0-deps.jar --files /Users/Marco/PredictionIO/conf/log4j.properties,/Users/Marco/PredictionIO/vendors/hbase-0.98.11/conf/hbase-site.xml --driver-class-path /Users/Marco/PredictionIO/conf:/Users/Marco/PredictionIO/vendors/hbase-0.98.11/conf /Users/Marco/PredictionIO/lib/pio-assembly-0.9.1.jar --env PIO_STORAGE_SOURCES_HBASE_TYPE=hbase,PIO_ENV_LOADED=1,PIO_STORAGE_SOURCES_HBASE_HOSTS=0,PIO_STORAGE_REPOSITORIES_METADATA_NAME=predictionio_metadata,PIO_FS_BASEDIR=/Users/Marco/.pio_store,PIO_STORAGE_SOURCES_ELASTICSEARCH_HOSTS=localhost,PIO_STORAGE_SOURCES_HBASE_HOME=/Users/Marco/PredictionIO/vendors/hbase-0.98.11,PIO_HOME=/Users/Marco/PredictionIO,PIO_FS_ENGINESDIR=/Users/Marco/.pio_store/engines,PIO_STORAGE_SOURCES_HBASE_PORTS=0,PIO_STORAGE_SOURCES_ELASTICSEARCH_TYPE=elasticsearch,PIO_STORAGE_REPOSITORIES_METADATA_SOURCE=ELASTICSEARCH,PIO_STORAGE_REPOSITORIES_MODELDATA_SOURCE=LOCALFS,PIO_STORAGE_REPOSITORIES_EVENTDATA_NAME=predictionio_eventdata,PIO_STORAGE_SOURCES_ELASTICSEARCH_HOME=/Users/Marco/PredictionIO/vendors/elasticsearch-1.4.4,PIO_FS_TMPDIR=/Users/Marco/.pio_store/tmp,PIO_STORAGE_REPOSITORIES_MODELDATA_NAME=pio_,PIO_STORAGE_SOURCES_LOCALFS_HOSTS=/Users/Marco/.pio_store/models,PIO_STORAGE_REPOSITORIES_EVENTDATA_SOURCE=HBASE,PIO_CONF_DIR=/Users/Marco/PredictionIO/conf,PIO_STORAGE_SOURCES_LOCALFS_PORTS=0,PIO_STORAGE_SOURCES_ELASTICSEARCH_PORTS=9300,PIO_STORAGE_SOURCES_LOCALFS_TYPE=localfs --engine-id IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I --engine-version 1601d4b44276e463819ccf16bcea2e968082ad77 --engine-variant /Users/Marco/SemanticAnalysisRepo/SemanticAnalysis/engine.json --verbosity 0
2015-04-09 10:35:47,399 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-09 10:35:48,440 INFO  io.prediction.controller.Engine [main] - Extracting datasource params...
2015-04-09 10:35:48,559 INFO  io.prediction.workflow.WorkflowUtils$ [main] - No 'name' is found. Default empty String will be used.
2015-04-09 10:35:48,573 INFO  io.prediction.controller.Engine [main] - Datasource params: (,DataSourceParams(4))
2015-04-09 10:35:48,574 INFO  io.prediction.controller.Engine [main] - Extracting preparator params...
2015-04-09 10:35:48,575 INFO  io.prediction.controller.Engine [main] - Preparator params: (,Empty)
2015-04-09 10:35:48,582 INFO  io.prediction.controller.Engine [main] - Extracting serving params...
2015-04-09 10:35:48,582 INFO  io.prediction.controller.Engine [main] - Serving params: (,Empty)
2015-04-09 10:35:50,432 INFO  Remoting [sparkDriver-akka.actor.default-dispatcher-5] - Starting remoting
2015-04-09 10:35:50,658 INFO  Remoting [sparkDriver-akka.actor.default-dispatcher-5] - Remoting started; listening on addresses :[akka.tcp://sparkDriver@calvisitor-10-105-138-218.calvisitor.1918.berkeley.edu:59249]
2015-04-09 10:35:50,888 INFO  org.spark-project.jetty.server.Server [main] - jetty-8.y.z-SNAPSHOT
2015-04-09 10:35:50,913 INFO  org.spark-project.jetty.server.AbstractConnector [main] - Started SocketConnector@0.0.0.0:59250
2015-04-09 10:35:51,069 INFO  org.spark-project.jetty.server.Server [main] - jetty-8.y.z-SNAPSHOT
2015-04-09 10:35:51,083 INFO  org.spark-project.jetty.server.AbstractConnector [main] - Started SelectChannelConnector@0.0.0.0:4040
2015-04-09 10:35:52,235 INFO  io.prediction.controller.Engine$ [main] - EngineWorkflow.train
2015-04-09 10:35:52,236 INFO  io.prediction.controller.Engine$ [main] - DataSource: SemanticAnalysis.DataSource@5e593b08
2015-04-09 10:35:52,236 INFO  io.prediction.controller.Engine$ [main] - Preparator: SemanticAnalysis.Preparator@2ac519dc
2015-04-09 10:35:52,237 INFO  io.prediction.controller.Engine$ [main] - AlgorithmList: List(SemanticAnalysis.Algorithm@3ece79fe)
2015-04-09 10:35:52,237 INFO  io.prediction.controller.Engine$ [main] - Data santiy check is on.
2015-04-09 10:35:57,732 ERROR org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper [main] - ZooKeeper exists failed after 1 attempts
2015-04-09 10:35:57,734 ERROR org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher [main] - hconnection-0x55acec99, quorum=localhost:2181, baseZNode=/hbase Received unexpected KeeperException, re-throwing exception
org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss for /hbase/hbaseid
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:99)
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:51)
	at org.apache.zookeeper.ZooKeeper.exists(ZooKeeper.java:1041)
	at org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper.exists(RecoverableZooKeeper.java:199)
	at org.apache.hadoop.hbase.zookeeper.ZKUtil.checkExists(ZKUtil.java:479)
	at org.apache.hadoop.hbase.zookeeper.ZKClusterId.readClusterIdZNode(ZKClusterId.java:65)
	at org.apache.hadoop.hbase.client.ZooKeeperRegistry.getClusterId(ZooKeeperRegistry.java:83)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.retrieveClusterId(HConnectionManager.java:852)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.<init>(HConnectionManager.java:657)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at org.apache.hadoop.hbase.client.HConnectionManager.createConnection(HConnectionManager.java:409)
	at org.apache.hadoop.hbase.client.HConnectionManager.createConnection(HConnectionManager.java:388)
	at org.apache.hadoop.hbase.client.HConnectionManager.getConnection(HConnectionManager.java:269)
	at org.apache.hadoop.hbase.client.HBaseAdmin.checkHBaseAvailable(HBaseAdmin.java:2338)
	at io.prediction.data.storage.hbase.StorageClient.<init>(StorageClient.scala:50)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at io.prediction.data.storage.Storage$.getClient(Storage.scala:149)
	at io.prediction.data.storage.Storage$.io$prediction$data$storage$Storage$$updateS2CM(Storage.scala:73)
	at io.prediction.data.storage.Storage$$anonfun$sourcesToClientMeta$1.apply(Storage.scala:88)
	at io.prediction.data.storage.Storage$$anonfun$sourcesToClientMeta$1.apply(Storage.scala:88)
	at scala.collection.mutable.MapLike$class.getOrElseUpdate(MapLike.scala:189)
	at scala.collection.mutable.AbstractMap.getOrElseUpdate(Map.scala:91)
	at io.prediction.data.storage.Storage$.sourcesToClientMeta(Storage.scala:88)
	at io.prediction.data.storage.Storage$.getDataObject(Storage.scala:181)
	at io.prediction.data.storage.Storage$.getPDataObject(Storage.scala:222)
	at io.prediction.data.storage.Storage$.getPDataObject(Storage.scala:173)
	at io.prediction.data.storage.Storage$.getPEvents(Storage.scala:280)
	at SemanticAnalysis.DataSource.readTraining(DataSource.scala:20)
	at SemanticAnalysis.DataSource.readTraining(DataSource.scala:11)
	at io.prediction.controller.PDataSource.readTrainingBase(DataSource.scala:41)
	at io.prediction.controller.Engine$.train(Engine.scala:518)
	at io.prediction.controller.Engine.train(Engine.scala:147)
	at io.prediction.workflow.CoreWorkflow$.runTrain(CoreWorkflow.scala:61)
	at io.prediction.workflow.CreateWorkflow$.main(CreateWorkflow.scala:258)
	at io.prediction.workflow.CreateWorkflow.main(CreateWorkflow.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:569)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:166)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:189)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:110)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
2015-04-09 10:35:57,737 WARN  org.apache.hadoop.hbase.client.ZooKeeperRegistry [main] - Can't retrieve clusterId from Zookeeper
org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss for /hbase/hbaseid
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:99)
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:51)
	at org.apache.zookeeper.ZooKeeper.exists(ZooKeeper.java:1041)
	at org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper.exists(RecoverableZooKeeper.java:199)
	at org.apache.hadoop.hbase.zookeeper.ZKUtil.checkExists(ZKUtil.java:479)
	at org.apache.hadoop.hbase.zookeeper.ZKClusterId.readClusterIdZNode(ZKClusterId.java:65)
	at org.apache.hadoop.hbase.client.ZooKeeperRegistry.getClusterId(ZooKeeperRegistry.java:83)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.retrieveClusterId(HConnectionManager.java:852)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.<init>(HConnectionManager.java:657)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at org.apache.hadoop.hbase.client.HConnectionManager.createConnection(HConnectionManager.java:409)
	at org.apache.hadoop.hbase.client.HConnectionManager.createConnection(HConnectionManager.java:388)
	at org.apache.hadoop.hbase.client.HConnectionManager.getConnection(HConnectionManager.java:269)
	at org.apache.hadoop.hbase.client.HBaseAdmin.checkHBaseAvailable(HBaseAdmin.java:2338)
	at io.prediction.data.storage.hbase.StorageClient.<init>(StorageClient.scala:50)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at io.prediction.data.storage.Storage$.getClient(Storage.scala:149)
	at io.prediction.data.storage.Storage$.io$prediction$data$storage$Storage$$updateS2CM(Storage.scala:73)
	at io.prediction.data.storage.Storage$$anonfun$sourcesToClientMeta$1.apply(Storage.scala:88)
	at io.prediction.data.storage.Storage$$anonfun$sourcesToClientMeta$1.apply(Storage.scala:88)
	at scala.collection.mutable.MapLike$class.getOrElseUpdate(MapLike.scala:189)
	at scala.collection.mutable.AbstractMap.getOrElseUpdate(Map.scala:91)
	at io.prediction.data.storage.Storage$.sourcesToClientMeta(Storage.scala:88)
	at io.prediction.data.storage.Storage$.getDataObject(Storage.scala:181)
	at io.prediction.data.storage.Storage$.getPDataObject(Storage.scala:222)
	at io.prediction.data.storage.Storage$.getPDataObject(Storage.scala:173)
	at io.prediction.data.storage.Storage$.getPEvents(Storage.scala:280)
	at SemanticAnalysis.DataSource.readTraining(DataSource.scala:20)
	at SemanticAnalysis.DataSource.readTraining(DataSource.scala:11)
	at io.prediction.controller.PDataSource.readTrainingBase(DataSource.scala:41)
	at io.prediction.controller.Engine$.train(Engine.scala:518)
	at io.prediction.controller.Engine.train(Engine.scala:147)
	at io.prediction.workflow.CoreWorkflow$.runTrain(CoreWorkflow.scala:61)
	at io.prediction.workflow.CreateWorkflow$.main(CreateWorkflow.scala:258)
	at io.prediction.workflow.CreateWorkflow.main(CreateWorkflow.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:569)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:166)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:189)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:110)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
2015-04-09 10:35:58,937 ERROR io.prediction.data.storage.hbase.StorageClient [main] - Cannot connect to ZooKeeper (ZooKeeper ensemble: localhost). Please make sure that the configuration is pointing at the correct ZooKeeper ensemble. By default, HBase manages its own ZooKeeper, so if you have not configured HBase to use an external ZooKeeper, that means your HBase is not started or configured properly.
2015-04-09 10:35:58,946 ERROR io.prediction.data.storage.Storage$ [main] - Error initializing storage client for source HBASE
2015-04-09 10:35:58,947 ERROR io.prediction.data.storage.Storage$ [main] - Can't connect to ZooKeeper
2015-04-09 10:35:58,948 ERROR io.prediction.controller.Engine$ [main] - Error occured reading from data source. (Reason: Data source HBASE was not properly initialized.) Please see the log for debugging details.
io.prediction.data.storage.StorageClientException: Data source HBASE was not properly initialized.
	at io.prediction.data.storage.Storage$$anonfun$9.apply(Storage.scala:182)
	at io.prediction.data.storage.Storage$$anonfun$9.apply(Storage.scala:182)
	at scala.Option.getOrElse(Option.scala:120)
	at io.prediction.data.storage.Storage$.getDataObject(Storage.scala:181)
	at io.prediction.data.storage.Storage$.getPDataObject(Storage.scala:222)
	at io.prediction.data.storage.Storage$.getPDataObject(Storage.scala:173)
	at io.prediction.data.storage.Storage$.getPEvents(Storage.scala:280)
	at SemanticAnalysis.DataSource.readTraining(DataSource.scala:20)
	at SemanticAnalysis.DataSource.readTraining(DataSource.scala:11)
	at io.prediction.controller.PDataSource.readTrainingBase(DataSource.scala:41)
	at io.prediction.controller.Engine$.train(Engine.scala:518)
	at io.prediction.controller.Engine.train(Engine.scala:147)
	at io.prediction.workflow.CoreWorkflow$.runTrain(CoreWorkflow.scala:61)
	at io.prediction.workflow.CreateWorkflow$.main(CreateWorkflow.scala:258)
	at io.prediction.workflow.CreateWorkflow.main(CreateWorkflow.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:569)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:166)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:189)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:110)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
2015-04-09 10:44:31,911 INFO  io.prediction.tools.console.App$ [main] -                 Name |   ID |                                                       Access Key | Allowed Event(s)
2015-04-09 10:44:31,979 INFO  io.prediction.tools.console.App$ [main] -               MyApp1 |    2 | rhAkDKWBw3tkypnGYlnb4K5QQFDRotSOA0EAOyQCUUsfW4BDH7jlwj4dWzmZ15Lq | (all)
2015-04-09 10:44:31,986 INFO  io.prediction.tools.console.App$ [main] - SemAnalysisApp-Marco |    1 | Hw8uK9u8j3C3Tuvu9Ce1YNIjhggQnXXUyPzxdqyqKPgaiT2Dz444hrNrcz4Bg8qM | (all)
2015-04-09 10:44:31,994 INFO  io.prediction.tools.console.App$ [main] -             TestApp3 |    3 | VcclTlUqfD7nbqPCCQY9dsnQm3VhUtw4JyUlwBJaAtLraA2RQfaLWBUxofAPr0o9 | (all)
2015-04-09 10:44:32,001 INFO  io.prediction.tools.console.App$ [main] -         TestApp50000 |    4 | H3qQ0peaL3MRu289hZNVtHxS3jXlBC303l59CcqQi9DRU0LSWCPU3SCBIEgRGDpa | (all)
2015-04-09 10:44:32,002 INFO  io.prediction.tools.console.App$ [main] - Finished listing 4 app(s).
2015-04-09 10:44:55,724 INFO  io.prediction.tools.console.App$ [main] - The following app will be deleted. Are you sure?
2015-04-09 10:44:55,726 INFO  io.prediction.tools.console.App$ [main] -     App Name: MyApp1
2015-04-09 10:44:55,727 INFO  io.prediction.tools.console.App$ [main] -       App ID: 2
2015-04-09 10:44:55,727 INFO  io.prediction.tools.console.App$ [main] -  Description: None
2015-04-09 10:45:01,314 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-09 10:45:06,816 ERROR org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper [main] - ZooKeeper exists failed after 1 attempts
2015-04-09 10:45:06,817 ERROR org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher [main] - hconnection-0x4beeb0e, quorum=localhost:2181, baseZNode=/hbase Received unexpected KeeperException, re-throwing exception
org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss for /hbase/hbaseid
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:99)
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:51)
	at org.apache.zookeeper.ZooKeeper.exists(ZooKeeper.java:1045)
	at org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper.exists(RecoverableZooKeeper.java:199)
	at org.apache.hadoop.hbase.zookeeper.ZKUtil.checkExists(ZKUtil.java:479)
	at org.apache.hadoop.hbase.zookeeper.ZKClusterId.readClusterIdZNode(ZKClusterId.java:65)
	at org.apache.hadoop.hbase.client.ZooKeeperRegistry.getClusterId(ZooKeeperRegistry.java:83)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.retrieveClusterId(HConnectionManager.java:852)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.<init>(HConnectionManager.java:657)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at org.apache.hadoop.hbase.client.HConnectionManager.createConnection(HConnectionManager.java:409)
	at org.apache.hadoop.hbase.client.HConnectionManager.createConnection(HConnectionManager.java:388)
	at org.apache.hadoop.hbase.client.HConnectionManager.getConnection(HConnectionManager.java:269)
	at org.apache.hadoop.hbase.client.HBaseAdmin.checkHBaseAvailable(HBaseAdmin.java:2338)
	at io.prediction.data.storage.hbase.StorageClient.<init>(StorageClient.scala:50)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at io.prediction.data.storage.Storage$.getClient(Storage.scala:149)
	at io.prediction.data.storage.Storage$.io$prediction$data$storage$Storage$$updateS2CM(Storage.scala:73)
	at io.prediction.data.storage.Storage$$anonfun$sourcesToClientMeta$1.apply(Storage.scala:88)
	at io.prediction.data.storage.Storage$$anonfun$sourcesToClientMeta$1.apply(Storage.scala:88)
	at scala.collection.mutable.MapLike$class.getOrElseUpdate(MapLike.scala:189)
	at scala.collection.mutable.AbstractMap.getOrElseUpdate(Map.scala:91)
	at io.prediction.data.storage.Storage$.sourcesToClientMeta(Storage.scala:88)
	at io.prediction.data.storage.Storage$.getDataObject(Storage.scala:181)
	at io.prediction.data.storage.Storage$.getDataObject(Storage.scala:166)
	at io.prediction.data.storage.Storage$.getLEvents(Storage.scala:274)
	at io.prediction.tools.console.App$$anonfun$delete$2.apply(App.scala:109)
	at io.prediction.tools.console.App$$anonfun$delete$2.apply(App.scala:101)
	at scala.Option.map(Option.scala:145)
	at io.prediction.tools.console.App$.delete(App.scala:101)
	at io.prediction.tools.console.Console$$anonfun$main$1.apply(Console.scala:624)
	at io.prediction.tools.console.Console$$anonfun$main$1.apply(Console.scala:577)
	at scala.Option.map(Option.scala:145)
	at io.prediction.tools.console.Console$.main(Console.scala:577)
	at io.prediction.tools.console.Console.main(Console.scala)
2015-04-09 10:45:06,822 WARN  org.apache.hadoop.hbase.client.ZooKeeperRegistry [main] - Can't retrieve clusterId from Zookeeper
org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss for /hbase/hbaseid
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:99)
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:51)
	at org.apache.zookeeper.ZooKeeper.exists(ZooKeeper.java:1045)
	at org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper.exists(RecoverableZooKeeper.java:199)
	at org.apache.hadoop.hbase.zookeeper.ZKUtil.checkExists(ZKUtil.java:479)
	at org.apache.hadoop.hbase.zookeeper.ZKClusterId.readClusterIdZNode(ZKClusterId.java:65)
	at org.apache.hadoop.hbase.client.ZooKeeperRegistry.getClusterId(ZooKeeperRegistry.java:83)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.retrieveClusterId(HConnectionManager.java:852)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.<init>(HConnectionManager.java:657)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at org.apache.hadoop.hbase.client.HConnectionManager.createConnection(HConnectionManager.java:409)
	at org.apache.hadoop.hbase.client.HConnectionManager.createConnection(HConnectionManager.java:388)
	at org.apache.hadoop.hbase.client.HConnectionManager.getConnection(HConnectionManager.java:269)
	at org.apache.hadoop.hbase.client.HBaseAdmin.checkHBaseAvailable(HBaseAdmin.java:2338)
	at io.prediction.data.storage.hbase.StorageClient.<init>(StorageClient.scala:50)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at io.prediction.data.storage.Storage$.getClient(Storage.scala:149)
	at io.prediction.data.storage.Storage$.io$prediction$data$storage$Storage$$updateS2CM(Storage.scala:73)
	at io.prediction.data.storage.Storage$$anonfun$sourcesToClientMeta$1.apply(Storage.scala:88)
	at io.prediction.data.storage.Storage$$anonfun$sourcesToClientMeta$1.apply(Storage.scala:88)
	at scala.collection.mutable.MapLike$class.getOrElseUpdate(MapLike.scala:189)
	at scala.collection.mutable.AbstractMap.getOrElseUpdate(Map.scala:91)
	at io.prediction.data.storage.Storage$.sourcesToClientMeta(Storage.scala:88)
	at io.prediction.data.storage.Storage$.getDataObject(Storage.scala:181)
	at io.prediction.data.storage.Storage$.getDataObject(Storage.scala:166)
	at io.prediction.data.storage.Storage$.getLEvents(Storage.scala:274)
	at io.prediction.tools.console.App$$anonfun$delete$2.apply(App.scala:109)
	at io.prediction.tools.console.App$$anonfun$delete$2.apply(App.scala:101)
	at scala.Option.map(Option.scala:145)
	at io.prediction.tools.console.App$.delete(App.scala:101)
	at io.prediction.tools.console.Console$$anonfun$main$1.apply(Console.scala:624)
	at io.prediction.tools.console.Console$$anonfun$main$1.apply(Console.scala:577)
	at scala.Option.map(Option.scala:145)
	at io.prediction.tools.console.Console$.main(Console.scala:577)
	at io.prediction.tools.console.Console.main(Console.scala)
2015-04-09 10:45:08,020 ERROR io.prediction.data.storage.hbase.StorageClient [main] - Cannot connect to ZooKeeper (ZooKeeper ensemble: localhost). Please make sure that the configuration is pointing at the correct ZooKeeper ensemble. By default, HBase manages its own ZooKeeper, so if you have not configured HBase to use an external ZooKeeper, that means your HBase is not started or configured properly.
2015-04-09 10:45:08,028 ERROR io.prediction.data.storage.Storage$ [main] - Error initializing storage client for source HBASE
2015-04-09 10:45:08,028 ERROR io.prediction.data.storage.Storage$ [main] - Can't connect to ZooKeeper
2015-04-09 10:45:45,082 INFO  io.prediction.tools.console.Console$ [main] - Creating Event Server at 0.0.0.0:7070
2015-04-09 10:45:46,348 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-09 10:45:48,821 INFO  spray.can.server.HttpListener [EventServerSystem-akka.actor.default-dispatcher-3] - Bound to /0.0.0.0:7070
2015-04-09 10:45:48,822 INFO  io.prediction.data.api.EventServerActor [EventServerSystem-akka.actor.default-dispatcher-3] - Bound received. EventServer is ready.
2015-04-09 10:45:56,684 INFO  io.prediction.tools.console.App$ [main] - The following app will be deleted. Are you sure?
2015-04-09 10:45:56,686 INFO  io.prediction.tools.console.App$ [main] -     App Name: MyApp1
2015-04-09 10:45:56,687 INFO  io.prediction.tools.console.App$ [main] -       App ID: 2
2015-04-09 10:45:56,687 INFO  io.prediction.tools.console.App$ [main] -  Description: None
2015-04-09 10:45:58,528 INFO  io.prediction.tools.console.App$ [main] - Aborted.
2015-04-09 10:46:07,922 INFO  io.prediction.tools.console.App$ [main] -                 Name |   ID |                                                       Access Key | Allowed Event(s)
2015-04-09 10:46:08,016 INFO  io.prediction.tools.console.App$ [main] -               MyApp1 |    2 | rhAkDKWBw3tkypnGYlnb4K5QQFDRotSOA0EAOyQCUUsfW4BDH7jlwj4dWzmZ15Lq | (all)
2015-04-09 10:46:08,031 INFO  io.prediction.tools.console.App$ [main] - SemAnalysisApp-Marco |    1 | Hw8uK9u8j3C3Tuvu9Ce1YNIjhggQnXXUyPzxdqyqKPgaiT2Dz444hrNrcz4Bg8qM | (all)
2015-04-09 10:46:08,040 INFO  io.prediction.tools.console.App$ [main] -             TestApp3 |    3 | VcclTlUqfD7nbqPCCQY9dsnQm3VhUtw4JyUlwBJaAtLraA2RQfaLWBUxofAPr0o9 | (all)
2015-04-09 10:46:08,057 INFO  io.prediction.tools.console.App$ [main] -         TestApp50000 |    4 | H3qQ0peaL3MRu289hZNVtHxS3jXlBC303l59CcqQi9DRU0LSWCPU3SCBIEgRGDpa | (all)
2015-04-09 10:46:08,058 INFO  io.prediction.tools.console.App$ [main] - Finished listing 4 app(s).
2015-04-09 10:46:20,869 ERROR io.prediction.tools.console.App$ [main] - App TeestApp3 does not exist. Aborting.
2015-04-09 10:46:28,144 INFO  io.prediction.tools.console.App$ [main] - The following app will be deleted. Are you sure?
2015-04-09 10:46:28,146 INFO  io.prediction.tools.console.App$ [main] -     App Name: TestApp3
2015-04-09 10:46:28,147 INFO  io.prediction.tools.console.App$ [main] -       App ID: 3
2015-04-09 10:46:28,147 INFO  io.prediction.tools.console.App$ [main] -  Description: None
2015-04-09 10:46:29,945 INFO  io.prediction.tools.console.App$ [main] - Aborted.
2015-04-09 10:46:43,650 INFO  io.prediction.tools.console.App$ [main] -                 Name |   ID |                                                       Access Key | Allowed Event(s)
2015-04-09 10:46:43,698 INFO  io.prediction.tools.console.App$ [main] -               MyApp1 |    2 | rhAkDKWBw3tkypnGYlnb4K5QQFDRotSOA0EAOyQCUUsfW4BDH7jlwj4dWzmZ15Lq | (all)
2015-04-09 10:46:43,715 INFO  io.prediction.tools.console.App$ [main] - SemAnalysisApp-Marco |    1 | Hw8uK9u8j3C3Tuvu9Ce1YNIjhggQnXXUyPzxdqyqKPgaiT2Dz444hrNrcz4Bg8qM | (all)
2015-04-09 10:46:43,726 INFO  io.prediction.tools.console.App$ [main] -             TestApp3 |    3 | VcclTlUqfD7nbqPCCQY9dsnQm3VhUtw4JyUlwBJaAtLraA2RQfaLWBUxofAPr0o9 | (all)
2015-04-09 10:46:43,737 INFO  io.prediction.tools.console.App$ [main] -         TestApp50000 |    4 | H3qQ0peaL3MRu289hZNVtHxS3jXlBC303l59CcqQi9DRU0LSWCPU3SCBIEgRGDpa | (all)
2015-04-09 10:46:43,738 INFO  io.prediction.tools.console.App$ [main] - Finished listing 4 app(s).
2015-04-09 10:47:15,720 INFO  io.prediction.tools.console.App$ [main] - The data of the following app will be deleted. Are you sure?
2015-04-09 10:47:15,722 INFO  io.prediction.tools.console.App$ [main] -     App Name: SemAnalysisApp-Marco
2015-04-09 10:47:15,722 INFO  io.prediction.tools.console.App$ [main] -       App ID: 1
2015-04-09 10:47:15,723 INFO  io.prediction.tools.console.App$ [main] -  Description: None
2015-04-09 10:47:18,190 INFO  io.prediction.tools.console.App$ [main] - Aborted.
2015-04-09 10:47:35,799 INFO  io.prediction.tools.console.App$ [main] - The data of the following app will be deleted. Are you sure?
2015-04-09 10:47:35,800 INFO  io.prediction.tools.console.App$ [main] -     App Name: SemAnalysisApp-Marco
2015-04-09 10:47:35,801 INFO  io.prediction.tools.console.App$ [main] -       App ID: 1
2015-04-09 10:47:35,801 INFO  io.prediction.tools.console.App$ [main] -  Description: None
2015-04-09 10:47:39,748 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-09 10:47:40,768 INFO  io.prediction.data.storage.hbase.HBLEvents [main] - Removing table predictionio_eventdata:events_1...
2015-04-09 10:47:46,167 INFO  io.prediction.tools.console.App$ [main] - Removed Event Store for this app ID: 1
2015-04-09 10:47:46,320 INFO  io.prediction.data.storage.hbase.HBLEvents [main] - The table predictionio_eventdata:events_1 doesn't exist yet. Creating now...
2015-04-09 10:47:46,652 INFO  io.prediction.tools.console.App$ [main] - Initialized Event Store for this app ID: 1.
2015-04-09 10:47:46,755 INFO  io.prediction.tools.console.App$ [main] - Done.
2015-04-09 10:48:05,025 INFO  io.prediction.tools.console.App$ [main] - The following app will be deleted. Are you sure?
2015-04-09 10:48:05,027 INFO  io.prediction.tools.console.App$ [main] -     App Name: MyApp1
2015-04-09 10:48:05,028 INFO  io.prediction.tools.console.App$ [main] -       App ID: 2
2015-04-09 10:48:05,029 INFO  io.prediction.tools.console.App$ [main] -  Description: None
2015-04-09 10:48:06,977 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-09 10:48:07,972 INFO  io.prediction.data.storage.hbase.HBLEvents [main] - Removing table predictionio_eventdata:events_2...
2015-04-09 10:48:13,304 INFO  io.prediction.tools.console.App$ [main] - Removed Event Store for this app ID: 2
2015-04-09 10:48:13,341 INFO  io.prediction.tools.console.App$ [main] - Deleted app MyApp1.
2015-04-09 10:48:13,444 INFO  io.prediction.tools.console.App$ [main] - Done.
2015-04-09 10:48:24,979 INFO  io.prediction.tools.console.App$ [main] - The following app will be deleted. Are you sure?
2015-04-09 10:48:24,981 INFO  io.prediction.tools.console.App$ [main] -     App Name: TestApp3
2015-04-09 10:48:24,981 INFO  io.prediction.tools.console.App$ [main] -       App ID: 3
2015-04-09 10:48:24,982 INFO  io.prediction.tools.console.App$ [main] -  Description: None
2015-04-09 10:48:27,791 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-09 10:48:38,908 INFO  io.prediction.data.storage.hbase.HBLEvents [main] - Removing table predictionio_eventdata:events_3...
2015-04-09 10:48:44,858 INFO  io.prediction.tools.console.App$ [main] - Removed Event Store for this app ID: 3
2015-04-09 10:48:44,868 INFO  io.prediction.tools.console.App$ [main] - Deleted app TestApp3.
2015-04-09 10:48:44,971 INFO  io.prediction.tools.console.App$ [main] - Done.
2015-04-09 10:48:59,082 INFO  io.prediction.tools.console.App$ [main] -                 Name |   ID |                                                       Access Key | Allowed Event(s)
2015-04-09 10:48:59,142 INFO  io.prediction.tools.console.App$ [main] - SemAnalysisApp-Marco |    1 | Hw8uK9u8j3C3Tuvu9Ce1YNIjhggQnXXUyPzxdqyqKPgaiT2Dz444hrNrcz4Bg8qM | (all)
2015-04-09 10:48:59,160 INFO  io.prediction.tools.console.App$ [main] -         TestApp50000 |    4 | H3qQ0peaL3MRu289hZNVtHxS3jXlBC303l59CcqQi9DRU0LSWCPU3SCBIEgRGDpa | (all)
2015-04-09 10:48:59,161 INFO  io.prediction.tools.console.App$ [main] - Finished listing 2 app(s).
2015-04-09 10:49:14,253 INFO  io.prediction.tools.console.App$ [main] - The following app will be deleted. Are you sure?
2015-04-09 10:49:14,255 INFO  io.prediction.tools.console.App$ [main] -     App Name: TestApp50000
2015-04-09 10:49:14,255 INFO  io.prediction.tools.console.App$ [main] -       App ID: 4
2015-04-09 10:49:14,256 INFO  io.prediction.tools.console.App$ [main] -  Description: None
2015-04-09 10:49:15,755 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-09 10:49:26,719 INFO  io.prediction.data.storage.hbase.HBLEvents [main] - Removing table predictionio_eventdata:events_4...
2015-04-09 10:49:32,074 INFO  io.prediction.tools.console.App$ [main] - Removed Event Store for this app ID: 4
2015-04-09 10:49:32,082 INFO  io.prediction.tools.console.App$ [main] - Deleted app TestApp50000.
2015-04-09 10:49:32,193 INFO  io.prediction.tools.console.App$ [main] - Done.
2015-04-09 10:49:47,662 INFO  io.prediction.tools.console.App$ [main] -                 Name |   ID |                                                       Access Key | Allowed Event(s)
2015-04-09 10:49:47,726 INFO  io.prediction.tools.console.App$ [main] - SemAnalysisApp-Marco |    1 | Hw8uK9u8j3C3Tuvu9Ce1YNIjhggQnXXUyPzxdqyqKPgaiT2Dz444hrNrcz4Bg8qM | (all)
2015-04-09 10:49:47,728 INFO  io.prediction.tools.console.App$ [main] - Finished listing 1 app(s).
2015-04-09 10:53:55,890 INFO  io.prediction.tools.console.Console$ [main] - Using existing engine manifest JSON at /Users/Marco/SemanticAnalysisRepo/SemanticAnalysis/manifest.json
2015-04-09 10:53:55,934 INFO  io.prediction.tools.console.Console$ [main] - Using command '/Users/Marco/PredictionIO/sbt/sbt' at the current working directory to build.
2015-04-09 10:53:55,935 INFO  io.prediction.tools.console.Console$ [main] - If the path above is incorrect, this process will fail.
2015-04-09 10:53:55,936 INFO  io.prediction.tools.console.Console$ [main] - Uber JAR disabled. Making sure lib/pio-assembly-0.9.1.jar is absent.
2015-04-09 10:53:55,937 INFO  io.prediction.tools.console.Console$ [main] - Going to run: /Users/Marco/PredictionIO/sbt/sbt  package assemblyPackageDependency
2015-04-09 10:54:06,032 INFO  io.prediction.tools.console.Console$ [main] - Build finished successfully.
2015-04-09 10:54:06,033 INFO  io.prediction.tools.console.Console$ [main] - Looking for an engine...
2015-04-09 10:54:06,041 INFO  io.prediction.tools.console.Console$ [main] - Found SemanticAnalysis-assembly-1.0-deps.jar
2015-04-09 10:54:06,041 INFO  io.prediction.tools.console.Console$ [main] - Found semanticanalysis_2.10-1.0.jar
2015-04-09 10:54:06,049 INFO  io.prediction.tools.console.Console$ [main] - HADOOP_CONF_DIR is not set. Assuming HDFS is unavailable.
2015-04-09 10:54:07,613 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-09 10:54:07,723 INFO  io.prediction.tools.RegisterEngine$ [main] - Copying file:/Users/Marco/SemanticAnalysisRepo/SemanticAnalysis/target/scala-2.10/SemanticAnalysis-assembly-1.0-deps.jar to file:/Users/Marco/.pio_store/engines/IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I/1601d4b44276e463819ccf16bcea2e968082ad77/SemanticAnalysis-assembly-1.0-deps.jar
2015-04-09 10:54:07,801 INFO  io.prediction.tools.RegisterEngine$ [main] - Copying file:/Users/Marco/SemanticAnalysisRepo/SemanticAnalysis/target/scala-2.10/semanticanalysis_2.10-1.0.jar to file:/Users/Marco/.pio_store/engines/IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I/1601d4b44276e463819ccf16bcea2e968082ad77/semanticanalysis_2.10-1.0.jar
2015-04-09 10:54:07,821 INFO  io.prediction.tools.RegisterEngine$ [main] - Registering engine IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I 1601d4b44276e463819ccf16bcea2e968082ad77
2015-04-09 10:54:07,907 INFO  io.prediction.tools.console.Console$ [main] - Your engine is ready for training.
2015-04-09 10:54:12,235 INFO  io.prediction.tools.console.Console$ [main] - Using existing engine manifest JSON at /Users/Marco/SemanticAnalysisRepo/SemanticAnalysis/manifest.json
2015-04-09 10:54:13,892 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-09 10:54:14,017 INFO  io.prediction.tools.RunWorkflow$ [main] - Submission command: /Users/Marco/../../usr/local/Cellar/apache-spark/1.3.0//bin/spark-submit --class io.prediction.workflow.CreateWorkflow --name PredictionIO Training: IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I 1601d4b44276e463819ccf16bcea2e968082ad77 () --jars file:/Users/Marco/.pio_store/engines/IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I/1601d4b44276e463819ccf16bcea2e968082ad77/semanticanalysis_2.10-1.0.jar,file:/Users/Marco/.pio_store/engines/IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I/1601d4b44276e463819ccf16bcea2e968082ad77/SemanticAnalysis-assembly-1.0-deps.jar --files /Users/Marco/PredictionIO/conf/log4j.properties,/Users/Marco/PredictionIO/vendors/hbase-0.98.11/conf/hbase-site.xml --driver-class-path /Users/Marco/PredictionIO/conf:/Users/Marco/PredictionIO/vendors/hbase-0.98.11/conf /Users/Marco/PredictionIO/lib/pio-assembly-0.9.1.jar --env PIO_STORAGE_SOURCES_HBASE_TYPE=hbase,PIO_ENV_LOADED=1,PIO_STORAGE_SOURCES_HBASE_HOSTS=0,PIO_STORAGE_REPOSITORIES_METADATA_NAME=predictionio_metadata,PIO_FS_BASEDIR=/Users/Marco/.pio_store,PIO_STORAGE_SOURCES_ELASTICSEARCH_HOSTS=localhost,PIO_STORAGE_SOURCES_HBASE_HOME=/Users/Marco/PredictionIO/vendors/hbase-0.98.11,PIO_HOME=/Users/Marco/PredictionIO,PIO_FS_ENGINESDIR=/Users/Marco/.pio_store/engines,PIO_STORAGE_SOURCES_HBASE_PORTS=0,PIO_STORAGE_SOURCES_ELASTICSEARCH_TYPE=elasticsearch,PIO_STORAGE_REPOSITORIES_METADATA_SOURCE=ELASTICSEARCH,PIO_STORAGE_REPOSITORIES_MODELDATA_SOURCE=LOCALFS,PIO_STORAGE_REPOSITORIES_EVENTDATA_NAME=predictionio_eventdata,PIO_STORAGE_SOURCES_ELASTICSEARCH_HOME=/Users/Marco/PredictionIO/vendors/elasticsearch-1.4.4,PIO_FS_TMPDIR=/Users/Marco/.pio_store/tmp,PIO_STORAGE_REPOSITORIES_MODELDATA_NAME=pio_,PIO_STORAGE_SOURCES_LOCALFS_HOSTS=/Users/Marco/.pio_store/models,PIO_STORAGE_REPOSITORIES_EVENTDATA_SOURCE=HBASE,PIO_CONF_DIR=/Users/Marco/PredictionIO/conf,PIO_STORAGE_SOURCES_LOCALFS_PORTS=0,PIO_STORAGE_SOURCES_ELASTICSEARCH_PORTS=9300,PIO_STORAGE_SOURCES_LOCALFS_TYPE=localfs --engine-id IJjuFmMq3lb3rFbdKypPLDzeurFCpa7I --engine-version 1601d4b44276e463819ccf16bcea2e968082ad77 --engine-variant /Users/Marco/SemanticAnalysisRepo/SemanticAnalysis/engine.json --verbosity 0
2015-04-09 10:54:16,034 WARN  org.apache.hadoop.util.NativeCodeLoader [main] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-04-09 10:54:17,045 INFO  io.prediction.controller.Engine [main] - Extracting datasource params...
2015-04-09 10:54:17,152 INFO  io.prediction.workflow.WorkflowUtils$ [main] - No 'name' is found. Default empty String will be used.
2015-04-09 10:54:17,166 INFO  io.prediction.controller.Engine [main] - Datasource params: (,DataSourceParams(1))
2015-04-09 10:54:17,166 INFO  io.prediction.controller.Engine [main] - Extracting preparator params...
2015-04-09 10:54:17,168 INFO  io.prediction.controller.Engine [main] - Preparator params: (,Empty)
2015-04-09 10:54:17,173 INFO  io.prediction.controller.Engine [main] - Extracting serving params...
2015-04-09 10:54:17,174 INFO  io.prediction.controller.Engine [main] - Serving params: (,Empty)
2015-04-09 10:54:18,986 INFO  Remoting [sparkDriver-akka.actor.default-dispatcher-3] - Starting remoting
2015-04-09 10:54:19,210 INFO  Remoting [sparkDriver-akka.actor.default-dispatcher-2] - Remoting started; listening on addresses :[akka.tcp://sparkDriver@calvisitor-10-105-138-218.calvisitor.1918.berkeley.edu:59728]
2015-04-09 10:54:19,421 INFO  org.spark-project.jetty.server.Server [main] - jetty-8.y.z-SNAPSHOT
2015-04-09 10:54:19,449 INFO  org.spark-project.jetty.server.AbstractConnector [main] - Started SocketConnector@0.0.0.0:59729
2015-04-09 10:54:19,608 INFO  org.spark-project.jetty.server.Server [main] - jetty-8.y.z-SNAPSHOT
2015-04-09 10:54:19,624 INFO  org.spark-project.jetty.server.AbstractConnector [main] - Started SelectChannelConnector@0.0.0.0:4040
2015-04-09 10:54:20,765 INFO  io.prediction.controller.Engine$ [main] - EngineWorkflow.train
2015-04-09 10:54:20,766 INFO  io.prediction.controller.Engine$ [main] - DataSource: SemanticAnalysis.DataSource@5e593b08
2015-04-09 10:54:20,767 INFO  io.prediction.controller.Engine$ [main] - Preparator: SemanticAnalysis.Preparator@2ac519dc
2015-04-09 10:54:20,767 INFO  io.prediction.controller.Engine$ [main] - AlgorithmList: List(SemanticAnalysis.Algorithm@3ece79fe)
2015-04-09 10:54:20,768 INFO  io.prediction.controller.Engine$ [main] - Data santiy check is on.
2015-04-09 10:54:32,252 INFO  io.prediction.controller.Engine$ [main] - SemanticAnalysis.TrainingData does not support data sanity check. Skipping check.
2015-04-09 10:54:32,253 INFO  io.prediction.controller.Engine$ [main] - SemanticAnalysis.PreparedData does not support data sanity check. Skipping check.
