if (method[['laplacian']] == 'sym') {
U = apply(U, 1, function(x) {x/sqrt(sum(x^2))})
}
return(kmeans(U, k)$cluster)
}
k = 5
graph_methods = list(epsilon = epsilonGraph, knn = knnGraph, full = function(S, a, b) {S})
method = c(graph = 'knn', laplacian = 'rw')
W = graph_methods[[method[['graph']]]](rf, 100, 'or')
L = getLaplacian(W, method[['laplacian']])
U = eigen(L)
M = length(unique(U$values))
U = U$vectors[,which(U$values %in% unique(U$values)[(M - min(k, M) + 1) : M])]
X = spectralClustering(rf, 5, method = list(graph = 'full', laplacian = 'sym'), args = c(0.1, F))
rfProximity = function(data, ntree, parallel = FALSE, njobs = 4) {
if (parallel) {
ntree = floor(ntree / njobs)
registerDoParallel(cores = detectCores())
rf = foreach(ntree=rep(ntree, njobs), proximity = rep(T, njobs),
.combine=combine, .multicombine=TRUE,
.packages='randomForest') %dopar% {
randomForest(x = data, ntree=ntree, proximity = proximity)
}
return(rf$proximity)
}
return(randomForest(x = data, ntree = ntree, proximity = TRUE)$proximity)
}
epsilonGraph = function(S, epsilon, weighted = FALSE) {
f = function(x) {apply(x, c(1, 2), function(x) {as.integer(x < 1 & x > 1 - epsilon)})}
if (weighted) {
return(S * f(S))
}
return(f(S))
}
getKNN = function(S, k) {t(apply(S, 2, function(x) {order(1 - x)[2 : (k + 1)]}))}
knnGraph = function(S, k, method = 'or') {
n = ncol(S)
neighbors = getKNN(S, k)
gen_op = function(x) {apply(x, 1, function(x) {as.integer((1 : n) %in% x)})}
f = function(mod_op, P = S, N = neighbors, g = gen_op) {P * mod_op(g(N), t(g(N)))}
if (method == 'or'){
return(f(mod_op = pmax))
}
return(f(mod_op = pmin))
}
degreeMatrix = function(W) {
return(diag(rowSums(W)))
}
getLaplacian = function(W, method = 'unnormalized') {
D = degreeMatrix(W)
L = D - W
if (method == 'unnormalized'){
return(L)
}
D = apply(D, c(1, 2), function(x) {ifelse(x == 0, 0, 1 / x)})
if (method == 'sym') {
f = function(x) {apply(x , c(1, 2), sqrt)}
return(f(D) %*% L %*% f(D))
}
return(D %*% L)
}
x = createClusterData(5, 100, 15)
createClusterData = function(clusterNum, clusterSize, dimension, unifSize = 100){
x = vector("list", length = clusterNum)
for (i in 1 : clusterNum) {
x[[i]] = matrix(c(runif(clusterSize, -unifSize/2, unifSize/2),
runif(clusterSize, 0, unifSize), rep(i, clusterSize)),
ncol = 3, byrow = FALSE)
}
x = t(data.frame(lapply(x, function(y) {apply(y, 1, function(z) {c(rnorm(dimension, z[1], z[2]), z[3])})})))
rownames(x) = NULL
return(x[sample(1:nrow(x), nrow(x)),])
}
x = createClusterData(5, 100, 15)
test_x = x[, -ncol(x)]
rf = rfProximity(test_x, 1000, TRUE)
W1 = epsilonGraph(rf, 0.5)
W2 = knnGraph(rf, 25)
L11 = getLaplacian(W1, 'sym')
L12 = getLaplacian(W1, 'unnormalized')
init(c('randomForest', 'foreach', 'doParallel', 'rARPACK'))
k = 5
y = eigs_sym(W1, k, which = "SM")
y = eigs_sym(L11, k, which = "SM")
y = eigs(L11, k, which = "SM")
View(`L11`)
View(`L12`)
L11 = getLaplacian(rf, 'sym')
View(`L11`)
L12 = getLaplacian(rf, 'unnormalized')
y = eigs(L11, k, which = "SM")
names(y)
y$values
y$vectors
1e-5
y = eigs(L11, k, which = "SM", tol = 10^(-5))
y$values
y$vectors
y = eigs(L11, k, which = "SM", tol = 10^(-2))
y = eigs(L11, k, which = "SM", tol = 10^(-2))
y$values
data(iris)
mean_class_estimate = function(data, response, class_) {
data = data[which(data[,response] == class_),-response]
return(apply(data, 2, mean))
}
pooled_covariance_estimate = function(data, response) {
classes = unique(data[, response])
output = diag(rep(0, ncol(data) - 1))
for (class_ in classes) {
class_mean = mean_class_estimate(data, response, class_)
for (i in which(data[,response] == class_)) {
dummy = as.matrix(data[i, -response] - class_mean)
output = output + (dummy %x% t(dummy))
}
}
}
pooled_covariance_estimate(iris, 5)
pooled_covariance_estimate = function(data, response) {
classes = unique(data[, response])
output = diag(rep(0, ncol(data) - 1))
for (class_ in classes) {
class_mean = mean_class_estimate(data, response, class_)
for (i in which(data[,response] == class_)) {
dummy = as.matrix(data[i, -response] - class_mean)
output = output + (dummy %x% t(dummy))
}
}
return(output)
}
pooled_covariance_estimate(iris, 5)
pooled_covariance_estimate = function(data, response) {
classes = unique(data[, response])
output = diag(rep(0, ncol(data) - 1))
for (class_ in classes) {
class_mean = mean_class_estimate(data, response, class_)
for (i in which(data[,response] == class_)) {
dummy = as.matrix(data[i, -response] - class_mean)
output = output + (dummy %x% t(dummy))
}
}
return(output * (1 / (nrow(data) - length(classes))))
}
pooled_covariance_estimate(iris, 5)
library("MASS", lib.loc="/Library/Frameworks/R.framework/Versions/3.1/Resources/library")
require(MASS)
ginv(pooled_covariance_estimate(iris, 5))
ginv(pooled_covariance_estimate(iris, 5)) %*% pooled_covariance_estimate(iris, 5)
pooled_covariance_estimate = function(data, response) {
classes = unique(data[, response])
output = diag(rep(0, ncol(data) - 1))
for (class_ in classes) {
print(class_)
class_mean = mean_class_estimate(data, response, class_)
for (i in which(data[,response] == class_)) {
print(i)
dummy = as.matrix(data[i, -response] - class_mean)
output = output + (dummy %x% t(dummy))
}
}
return(output * (1 / (nrow(data) - length(classes))))
}
pooled_covariance_estimate(iris, 5)
lda_discriminant = function(data, response, class_){
require(MASS)
class_mean = matrix(mean_class_estimate(data, response, class_), ncol = 1)
class_prior = length(which(data[,response] == class_)) / nrow(data)
covariance_inv = ginv(pooled_covariance_estimate(data, response))
f = function(x) {
x = matrix(x, ncol = 1)
output = (-1 / 2) * (t(class_mean) * covariance_inv * class_mean)
output = output + t(x) * (covariance_inv * class_mean)
return(output + log(class_prior))
}
return(f)
}
data(iris)
iris[, 5] = levels(iris[, 5])[iris[, 5]]
iris[,5]
class(iris[,5])
lda_discriminant(iris, 5, 'virginica')
lda_discriminant = function(data, response, class_){
require(MASS)
class_mean = matrix(mean_class_estimate(data, response, class_), ncol = 1)
class_prior = length(which(data[, response] == class_)) / nrow(data)
covariance_inv = ginv(pooled_covariance_estimate(data, response))
f = function(x) {
x = matrix(x, ncol = 1)
output = (-1 / 2) * (t(class_mean) * covariance_inv * class_mean)
output = output + t(x) * (covariance_inv * class_mean)
return(output + log(class_prior))
}
return(f)
}
lda_discriminant(iris, 5, 'virginica')
mean_class_estimate = function(data, response, class_) {
data = data[which(data[, response] == class_), -response]
return(apply(data, 2, mean))
}
pooled_covariance_estimate = function(data, response) {
classes = unique(data[, response])
output = diag(rep(0, ncol(data) - 1))
for (class_ in classes) {
class_mean = mean_class_estimate(data, response, class_)
for (i in which(data[, response] == class_)) {
dummy = as.matrix(data[i, -response] - class_mean)
output = output + (dummy %x% t(dummy))
}
}
return(output * (1 / (nrow(data) - length(classes))))
}
lda_discriminant = function(data, response, class_){
require(MASS)
class_mean = matrix(mean_class_estimate(data, response, class_), ncol = 1)
class_prior = length(which(data[, response] == class_)) / nrow(data)
covariance_inv = ginv(pooled_covariance_estimate(data, response))
f = function(x) {
x = matrix(x, ncol = 1)
output = (-1 / 2) * (t(class_mean) * covariance_inv * class_mean)
output = output + t(x) * (covariance_inv * class_mean)
return(output + log(class_prior))
}
return(f)
}
lda_discriminant(iris, 5, 'virginica')
lda_discriminant(iris, 5, 'virginica')(iris[133, -5])
matrix(mean_class_estimate(iris, 5, 'virginica'), ncol = 1)
matrix(iris[133, -5], ncol = 1)
class_mean = matrix(mean_class_estimate(iris, 5, 'virginica'), ncol = 1)
require(MASS)
class_prior = length(which(iris[, 5] == 'virginica')) / nrow(iris)
covariance_inv = ginv(pooled_covariance_estimate(data, response))
covariance_inv = ginv(pooled_covariance_estimate(iris, 5))
x = matrix(iris[133, -5], ncol = 1)
t(class_mean)
output = (-1 / 2) * (t(class_mean) * covariance_inv * class_mean)
t(class_mean)
covariance_inv
t(class_mean) * covariance_inv
covariance_inv * class_mean
covariance_inv %*% class_mean
lda_discriminant = function(data, response, class_){
require(MASS)
class_mean = matrix(mean_class_estimate(data, response, class_), ncol = 1)
class_prior = length(which(data[, response] == class_)) / nrow(data)
covariance_inv = ginv(pooled_covariance_estimate(data, response))
f = function(x) {
x = matrix(x, ncol = 1)
output = (-1 / 2) * (t(class_mean) %*% covariance_inv %*% class_mean)
output = output + (t(x) %*% covariance_inv %*% class_mean)
return(output + log(class_prior))
}
return(f)
}
lda_discriminant(iris, 5, 'virginica')(iris[133, -5])
output = (-1 / 2) * (t(class_mean) %*% covariance_inv %*% class_mean)
x = iris[133, -5]
zz = iris[133, -5]
class_mean = matrix(mean_class_estimate(iris, 5, 'virginica'), ncol = 1)
class_prior = length(which(iris[, 5] == 'virginica')) / nrow(iris)
covariance_inv = ginv(pooled_covariance_estimate(iris, 5))
x = matrix(zz, ncol = 1)
output = (-1 / 2) * (t(class_mean) %*% covariance_inv %*% class_mean)
(t(x) %*% covariance_inv %*% class_mean)
t(x)
class(x)
class(x[1,])
class(zz)
as.numeric(zz)
x = matrix(as.numeric(zz), ncol = 1)
t(x)
t(x) %*% covariance_inv
zz
lda_discriminant = function(data, response, class_){
require(MASS)
class_mean = matrix(mean_class_estimate(data, response, class_), ncol = 1)
class_prior = length(which(data[, response] == class_)) / nrow(data)
covariance_inv = ginv(pooled_covariance_estimate(data, response))
f = function(x) {
x = matrix(as.numeric(x), ncol = 1)
output = (-1 / 2) * (t(class_mean) %*% covariance_inv %*% class_mean)
output = output + (t(x) %*% covariance_inv %*% class_mean)
return(output + log(class_prior))
}
return(f)
}
lda_discriminant(iris, 5, 'virginica')(iris[133, -5])
unique(iris[,5])
lda_discriminant(iris, 5, 'setosa')(iris[133, -5])
lda_discriminant(iris, 5, 'versicolor')(iris[133, -5])
c(sum, mean)
class(c(sum, mean))
T | F
F | T
generate_discriminants = function(data, response) {
classes = unique(data[, response])
output = vector('list', length(classes))
for (i in 1 : length(classes)) {
output[[i]] = c(classes[i], lda_discriminant(data, response, classes[i]))
}
return(output)
}
lda_classify(x, discriminant_list) {
class_ = discriminant_list[[1]][1]
for (i in 2 : length(discriminant_list)) {
if (discriminant_list[[i]][2](x) > discriminant_list[[i - 1]][2](x)) {
class_ = discriminant_list[[i]][1]
}
}
return(class_)
}
lda_classify = function(x, discriminant_list) {
class_ = discriminant_list[[1]][1]
for (i in 2 : length(discriminant_list)) {
if (discriminant_list[[i]][2](x) > discriminant_list[[i - 1]][2](x)) {
class_ = discriminant_list[[i]][1]
}
}
return(class_)
}
poo = generate_discriminants(iris, 5)
lda_classify(iris[123, -5], poo)
poo[[1]]
generate_discriminants = function(data, response) {
classes = unique(data[, response])
output = vector('list', length(classes))
for (i in 1 : length(classes)) {
output[[i]] = list(classes[i], lda_discriminant(data, response, classes[i]))
}
return(output)
}
lda_classify = function(x, discriminant_list) {
class_ = discriminant_list[[1]][1]
for (i in 2 : length(discriminant_list)) {
if (discriminant_list[[i]][2](x) > discriminant_list[[i - 1]][2](x)) {
class_ = discriminant_list[[i]][1]
}
}
return(class_)
}
poo = generate_discriminants(iris, 5)
lda_classify(iris[123, -5], poo)
lda_classify = function(x, discriminant_list) {
class_ = discriminant_list[[1]][[1]]
for (i in 2 : length(discriminant_list)) {
if (discriminant_list[[i]][[2]](x) > discriminant_list[[i - 1]][[2]](x)) {
class_ = discriminant_list[[i]][[1]]
}
}
return(class_)
}
lda_classify(iris[123, -5], poo)
iris[123,]
6e+00
6e+01
6e-01
6e-100
data(sage)
data(Sage)
library(MCMCPack)
library(MCMCpack)
plot(function(x) {dinvgamma(x, 1, 10000)})
plot(function(x) {dinvgamma(x, 1, 1000)})
plot(function(x) dinvgamma(x, 1, 1000))
plot(function(x) dinvgamma(x, 1, 10000))
f = function(x) {return(dinvgamma(x, 1, 1000))}
plot(f)
f = Vectorize(f)
plot(f)
plot(dinvgamma)
plot(dinvgamma, list = [shape = 1])
plot(function(x) dinvgamma(x, 1, 1000))
dinvgamma(1, 1, 1000)
dinvgamma(0.8, 1, 1000)
dinvgamma(0.8, 1, 100)
library("XML", lib.loc="/Library/Frameworks/R.framework/Versions/3.1/Resources/library")
x = getURL('https://www.google.com/maps/search/finance/@37.7403262,-122.4427498,12z/data=!3m1!4b1')
library("RCurl", lib.loc="/Library/Frameworks/R.framework/Versions/3.1/Resources/library")
x = getURL('https://www.google.com/maps/search/finance/@37.7403262,-122.4427498,12z/data=!3m1!4b1')
x
x[2]
156061/4
156061/8
15061/4
156061/4
count_data = read.csv('poop.txt')
count_data = read.table('poop.txt', sep = ', ')
156060/8
130000 / 5
count_data = read.csv('train_data/trainaa')
library("MASS", lib.loc="/Library/Frameworks/R.framework/Versions/3.1/Resources/library")
f = Vectorize(function(x) {rgamma(x, shape = 1)})
plot(f)
f = Vectorize(function(x) {dgamma(x, shape = 1)})
f = Vectorize(function(x) {dgamma(x, shape = 1)})
plot(f)
f = Vectorize(function(x) {dgamma(x, shape = 2, rate = 2)})
plot(f)
f = Vectorize(function(x) {dgamma(x, shape = 1.5, rate = 1.5)})
f = Vectorize(function(x){dgamma(x, 0.9, 0.9)})
plot(f)
f = Vectorize(function(x){dgamma(x, 1.1, 1.1)})
plot(f)
f = Vectorize(function(x){dgamma(x, 2, 2)})
plot(f)
f = Vectorize(function(x){dgamma(x, 3, 3)})
plot(f)
f = Vectorize(function(x){dgamma(x, 1.5, 1.5)})
plot(f)
f = Vectorize(function(x){dgamma(x, 1.05, 1.05)})
plot(f)
f = Vectorize(function(x){dgamma(x, 1.75, 1.75)})
plot(f)
f = Vectorize(function(x){dgamma(x, 2, 2)})
plot(f)
f = Vectorize(function(x){dgamma(x, shape = 2, scale = 2)})
plot(f)
f = Vectorize(function(x){dgamma(x, shape = 1, scale = 1)})
plot(f)
f = Vectorize(function(x){dgamma(x, shape = 1.5, scale = 1.5)})
plot(f)
f = Vectorize(function(x){dgamma(x, shape = 1.5, scale = 1/1.5)})
plot(f)
f = Vectorize(function(x){dgamma(x, shape = 1/1.5, scale = 1.5)})
plot(f)
f = Vectorize(function(x){dgamma(x, shape = 2, scale = 1/2)})
plot(f)
f = Vectorize(function(x){dgamma(x, shape = 1.5, scale = 1/1.5)})
plot(f)
f = Vectorize(function(x){dgamma(x, shape = 1.5, scale = 1/1.5)})
plot(f)
f = Vectorize(function(x){dgamma(x, shape = 1/1.5, scale = 1.5)})
plot(f)
f = Vectorize(function(x){dgamma(x, 2, 2)})
plot(f)
shape, rate  = 3, 2
f = Vectorize(function(x){dgamma(x, 3, 2)})
plot(f)
plot(f, xlim =c(0, 100))
f = Vectorize(function(x){dgamma(x, 2, 1)})
plot(f, xlim =c(0, 100))
f = Vectorize(function(x){dgamma(x, 2, 0.5)})
plot(f, xlim =c(0, 100))
f = Vectorize(function(x){dgamma(x, 2, 0.0.1)})
f = Vectorize(function(x){dgamma(x, 2, 0.1)})
plot(f, xlim =c(0, 100))
f = Vectorize(function(x){dgamma(x, 2, 0.05)})
plot(f, xlim =c(0, 100))
f = Vectorize(function(x){dgamma(x, 2, 1)})
plot(f, xlim =c(0, 100))
f = Vectorize(function(x){dgamma(x, 1.25, .25)})
plot(f, xlim =c(0, 100))
plot(f, xlim =c(0, 1000))
plot(f, xlim =c(0, 100))
plot(f, xlim =c(0, 20))
f = Vectorize(function(x){dgamma(x, 11/10, 1/10)})
plot(f, xlim =c(0, 20))
f = Vectorize(function(x){dgamma(x, 1.25, .25)})
plot(f, xlim =c(0, 20))
f = Vectorize(function(x){dgamma(x, 11/10, 1/10)})
plot(f, xlim =c(0, 20))
f = Vectorize(function(x){dgamma(x, 105/10, 5/100)})
plot(f, xlim =c(0, 20))
f = Vectorize(function(x){dgamma(x, 11/10, 1/10)})
plot(f, xlim =c(0, 20))
N = 1000
index = 1:N
subset_sizes = [200, 100, 150, 150, 300]
K = length(subset_sizes)
subsets = vector('list', length = K)
for (i in 1:K) {
subset = sample(index, size)
subsets[[i]] = subset
index = index[which(!(index %in% subset))]
}
N = 1000
index = 1:N
subset_sizes = c(200, 100, 150, 150, 300)
K = length(subset_sizes)
subsets = vector('list', length = K)
for (i in 1:K) {
subset = sample(index, size)
subsets[[i]] = subset
index = index[which(!(index %in% subset))]
}
N = 1000
index = 1:N
subset_sizes = c(200, 100, 150, 150, 300)
K = length(subset_sizes)
subsets = vector('list', length = K)
for (i in 1:K) {
subset = sample(index, subset_sizes[i])
subsets[[i]] = subset
index = index[which(!(index %in% subset))]
}
subsets
setwd('~/SemanticAnalysisRepo')
setwd('~/SemanticAnalysisRepo/SampleModel')
x = read.table('alpha_sample.txt')
View(x)
x = read.table('alpha_sample.txt')
hist(x[,1])
plot(x = x[,1], y = x[,2])
lines(x = x[,1], y = x[,2])
lines(x = 1: 200, y = x[,1])
lines(x = 1: 200, y = x[,1])
plot(x = x[,1], y = x[,2])
lines(x = 1: 200, y = x[,1])
line(x = 1: 200, y = x[,1])
lines(x = 1: 200, y = x[,1])
plot(x = 1:200, y = x[,1])
lines(x = 1: 200, y = x[,1])
